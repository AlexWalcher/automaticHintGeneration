{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cxaEE5DFfr_v",
        "WckjgVs-fZto",
        "s5rwSDisuN9s",
        "du5Un8VufnlG",
        "_lhmuuUNQ__8",
        "0Yf6Fi_34ye5",
        "0LORwHLog-t_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e3077fda0c04e998d6f9b190a313af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79fa7dc445054f369713c7528985cb76",
              "IPY_MODEL_b029e29145154c0598c20da2623c665f",
              "IPY_MODEL_c95671b034ff496eb12ebcf4782d9793"
            ],
            "layout": "IPY_MODEL_6cbba4313638449db761910c45ec2525"
          }
        },
        "79fa7dc445054f369713c7528985cb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02e3efe5f28490c934c8c2bcb11b19c",
            "placeholder": "​",
            "style": "IPY_MODEL_889c3e14ec7d41f59d430025e0732af6",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b029e29145154c0598c20da2623c665f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fece28c7ddaf4c838a8dc2a927ae25ac",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_963ca057072c4a098844321143faaf4b",
            "value": 28
          }
        },
        "c95671b034ff496eb12ebcf4782d9793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0fa0d1042c84e63bf099a6addfb1bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_a9d81e17e4734513927d47e195ca2dcd",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.32kB/s]"
          }
        },
        "6cbba4313638449db761910c45ec2525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02e3efe5f28490c934c8c2bcb11b19c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "889c3e14ec7d41f59d430025e0732af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fece28c7ddaf4c838a8dc2a927ae25ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963ca057072c4a098844321143faaf4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0fa0d1042c84e63bf099a6addfb1bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d81e17e4734513927d47e195ca2dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a268c928ee064ed98e6f20d101889bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c59ec4e2f2ce4f29b9b645d1efde7279",
              "IPY_MODEL_ff1716c02b5c426d9d5d470519d0ea2a",
              "IPY_MODEL_c76bc47d703d45b3bc98bf6726ec740f"
            ],
            "layout": "IPY_MODEL_4df2ba959d1b444f8174dee4c7e6e73b"
          }
        },
        "c59ec4e2f2ce4f29b9b645d1efde7279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91968fc50c0148b5bca69031bb3a40f5",
            "placeholder": "​",
            "style": "IPY_MODEL_2b1a5d1c0bb644a7af051cd760d1a180",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ff1716c02b5c426d9d5d470519d0ea2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83bb5190e2e34e8c96c8c5692cbacd55",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a07fa7f665a643d2a33706ac68c8cbb6",
            "value": 570
          }
        },
        "c76bc47d703d45b3bc98bf6726ec740f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d132b8194ca645fd9f61cc9190b1fa6b",
            "placeholder": "​",
            "style": "IPY_MODEL_97effe0b3bf94cf6ba8d18fef5f0e2ed",
            "value": " 570/570 [00:00&lt;00:00, 33.5kB/s]"
          }
        },
        "4df2ba959d1b444f8174dee4c7e6e73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91968fc50c0148b5bca69031bb3a40f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b1a5d1c0bb644a7af051cd760d1a180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83bb5190e2e34e8c96c8c5692cbacd55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07fa7f665a643d2a33706ac68c8cbb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d132b8194ca645fd9f61cc9190b1fa6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97effe0b3bf94cf6ba8d18fef5f0e2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3939f16a072641069cf5f1b5aab86e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c50061a3b13420ba8b83c32a77fa8b5",
              "IPY_MODEL_977d87520d90447fa6f7a15d619497c3",
              "IPY_MODEL_3c5e148e4bd84114afd916fc171b86c9"
            ],
            "layout": "IPY_MODEL_615fc8c6dd3d47e8b293959c87d07a70"
          }
        },
        "9c50061a3b13420ba8b83c32a77fa8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6235fad7c774de8817f7d3f1ad19a68",
            "placeholder": "​",
            "style": "IPY_MODEL_d0977afc41194db4a37eac80944f9b53",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "977d87520d90447fa6f7a15d619497c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29d49b5e0fee46d7921f3f18bb3e6873",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d2fb06ff0b24129a0c5cfe6cc4821b5",
            "value": 231508
          }
        },
        "3c5e148e4bd84114afd916fc171b86c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a251d6ef16e430db0a4f98d05b3ae82",
            "placeholder": "​",
            "style": "IPY_MODEL_63588c2bc1304c52a4c4dc3e87f1456c",
            "value": " 232k/232k [00:00&lt;00:00, 1.67MB/s]"
          }
        },
        "615fc8c6dd3d47e8b293959c87d07a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6235fad7c774de8817f7d3f1ad19a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0977afc41194db4a37eac80944f9b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29d49b5e0fee46d7921f3f18bb3e6873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d2fb06ff0b24129a0c5cfe6cc4821b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a251d6ef16e430db0a4f98d05b3ae82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63588c2bc1304c52a4c4dc3e87f1456c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9527f5a524034758823b4455dcc90f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7575367af58a4014b01a07b9587f1060",
              "IPY_MODEL_0267a16c127841aab94cf55aa0ed3b06",
              "IPY_MODEL_3c285f23ac6c4e7c8bab966ba204f70f"
            ],
            "layout": "IPY_MODEL_508c7cd9977745b1b9c0066e9cd5a324"
          }
        },
        "7575367af58a4014b01a07b9587f1060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62df688f73e342ea91c90ba60e7de0d5",
            "placeholder": "​",
            "style": "IPY_MODEL_f4366d4710664b4ebc7b605a7ffab843",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "0267a16c127841aab94cf55aa0ed3b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f2c3ee80a3f471fb43e2fc3e9bb2353",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2c6cccfa142400c92da839baf6f9a2e",
            "value": 466062
          }
        },
        "3c285f23ac6c4e7c8bab966ba204f70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5bd3b23166b4117821715483aa9134b",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe044079d3148928bf88683f4583869",
            "value": " 466k/466k [00:00&lt;00:00, 2.24MB/s]"
          }
        },
        "508c7cd9977745b1b9c0066e9cd5a324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62df688f73e342ea91c90ba60e7de0d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4366d4710664b4ebc7b605a7ffab843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f2c3ee80a3f471fb43e2fc3e9bb2353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c6cccfa142400c92da839baf6f9a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5bd3b23166b4117821715483aa9134b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe044079d3148928bf88683f4583869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32e0944bde7748b38d7442810185e759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4178e384b5a647598c9f247b1938509c",
              "IPY_MODEL_3ac4808ffa9a4d52b7cd911001d6aa63",
              "IPY_MODEL_b73602400b7b47539b57e50241da7254"
            ],
            "layout": "IPY_MODEL_59b40b3c97c04c439790cdff390d8122"
          }
        },
        "4178e384b5a647598c9f247b1938509c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5c74df62ca04d529e5e32bb2d9d2248",
            "placeholder": "​",
            "style": "IPY_MODEL_d75c7489403c49688965ad2a4a2e90b4",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "3ac4808ffa9a4d52b7cd911001d6aa63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc8c5a11ffdb40ef9e8e9e99dd004f48",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_999bda6f524245a1bff9aabbc5c97e30",
            "value": 440473133
          }
        },
        "b73602400b7b47539b57e50241da7254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc961e4c0bc74d3b8b896903d8a4a7b6",
            "placeholder": "​",
            "style": "IPY_MODEL_3251ff0b4b7442269ebcaa72d5f82fcb",
            "value": " 440M/440M [00:03&lt;00:00, 146MB/s]"
          }
        },
        "59b40b3c97c04c439790cdff390d8122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c74df62ca04d529e5e32bb2d9d2248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75c7489403c49688965ad2a4a2e90b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc8c5a11ffdb40ef9e8e9e99dd004f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999bda6f524245a1bff9aabbc5c97e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc961e4c0bc74d3b8b896903d8a4a7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3251ff0b4b7442269ebcaa72d5f82fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexWalcher/optimizationOfHintGeneration/blob/Test/optimizationOfHintGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##How to use:\n",
        "1. Run **All imports**\n",
        "2. Run **Load File**\n",
        "3. Run **New prediction method for years** or any of the **Old predictions methods**"
      ],
      "metadata": {
        "id": "sdufKBvPeQbe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5rwSDisuN9s"
      },
      "source": [
        "# **All imports**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%rm -r optimizationOfHintGeneration\n",
        "!git clone https://github.com/AlexWalcher/optimizationOfHintGeneration.git\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "b_jGbTrbz8x2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68447cf-6030-493b-f2c5-14cb208109b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "rm: cannot remove 'optimizationOfHintGeneration': No such file or directory\n",
            "Cloning into 'optimizationOfHintGeneration'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 120 (delta 11), reused 0 (delta 0), pack-reused 85\u001b[K\n",
            "Receiving objects: 100% (120/120), 7.20 MiB | 11.50 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update \n",
        "!apt-get install firefox\n",
        "!apt install firefox-geckodriver"
      ],
      "metadata": {
        "id": "98Zh7IC7mSWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5fbd3b-0a5d-4799-9157-0bdcb8afc322"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.9.1-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.26.15)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2022.12.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9 (from trio~=0.17->selenium)\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, async-generator, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed async-generator-1.10 h11-0.14.0 outcome-1.2.0 selenium-4.9.1 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,010 kB]\n",
            "Hit:12 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,048 kB]\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,570 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,680 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,158 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,212 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,343 kB]\n",
            "Fetched 13.4 MB in 7s (1,788 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libdbus-glib-1-2 libdbusmenu-glib4 libdbusmenu-gtk3-4 libxtst6\n",
            "  xul-ext-ubufox\n",
            "Suggested packages:\n",
            "  fonts-lyx\n",
            "The following NEW packages will be installed:\n",
            "  firefox libdbus-glib-1-2 libdbusmenu-glib4 libdbusmenu-gtk3-4 libxtst6\n",
            "  xul-ext-ubufox\n",
            "0 upgraded, 6 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 60.9 MB of archives.\n",
            "After this operation, 244 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbus-glib-1-2 amd64 0.110-5fakssync1 [59.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 firefox amd64 112.0.2+build1-0ubuntu0.20.04.1 [60.7 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbusmenu-glib4 amd64 16.04.1+18.10.20180917-0ubuntu6 [41.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbusmenu-gtk3-4 amd64 16.04.1+18.10.20180917-0ubuntu6 [27.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 xul-ext-ubufox all 3.4-0ubuntu1.17.10.1 [3,320 B]\n",
            "Fetched 60.9 MB in 2s (27.0 MB/s)\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libdbus-glib-1-2_0.110-5fakssync1_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../1-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package firefox.\n",
            "Preparing to unpack .../2-firefox_112.0.2+build1-0ubuntu0.20.04.1_amd64.deb ...\n",
            "Unpacking firefox (112.0.2+build1-0ubuntu0.20.04.1) ...\n",
            "Selecting previously unselected package libdbusmenu-glib4:amd64.\n",
            "Preparing to unpack .../3-libdbusmenu-glib4_16.04.1+18.10.20180917-0ubuntu6_amd64.deb ...\n",
            "Unpacking libdbusmenu-glib4:amd64 (16.04.1+18.10.20180917-0ubuntu6) ...\n",
            "Selecting previously unselected package libdbusmenu-gtk3-4:amd64.\n",
            "Preparing to unpack .../4-libdbusmenu-gtk3-4_16.04.1+18.10.20180917-0ubuntu6_amd64.deb ...\n",
            "Unpacking libdbusmenu-gtk3-4:amd64 (16.04.1+18.10.20180917-0ubuntu6) ...\n",
            "Selecting previously unselected package xul-ext-ubufox.\n",
            "Preparing to unpack .../5-xul-ext-ubufox_3.4-0ubuntu1.17.10.1_all.deb ...\n",
            "Unpacking xul-ext-ubufox (3.4-0ubuntu1.17.10.1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Setting up libdbusmenu-glib4:amd64 (16.04.1+18.10.20180917-0ubuntu6) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\n",
            "Setting up xul-ext-ubufox (3.4-0ubuntu1.17.10.1) ...\n",
            "Setting up libdbusmenu-gtk3-4:amd64 (16.04.1+18.10.20180917-0ubuntu6) ...\n",
            "Setting up firefox (112.0.2+build1-0ubuntu0.20.04.1) ...\n",
            "update-alternatives: using /usr/bin/firefox to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/firefox to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "Please restart all running instances of firefox, or you will experience problems.\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  firefox-geckodriver\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 1,277 kB of archives.\n",
            "After this operation, 4,431 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 firefox-geckodriver amd64 112.0.2+build1-0ubuntu0.20.04.1 [1,277 kB]\n",
            "Fetched 1,277 kB in 1s (1,634 kB/s)\n",
            "Selecting previously unselected package firefox-geckodriver.\n",
            "(Reading database ... 122645 files and directories currently installed.)\n",
            "Preparing to unpack .../firefox-geckodriver_112.0.2+build1-0ubuntu0.20.04.1_amd64.deb ...\n",
            "Unpacking firefox-geckodriver (112.0.2+build1-0ubuntu0.20.04.1) ...\n",
            "Setting up firefox-geckodriver (112.0.2+build1-0ubuntu0.20.04.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__DepwTLww00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96c0798-3d96-41bc-e13e-58472e09d431"
      },
      "source": [
        "!pip install sparqlwrapper"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sparqlwrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting rdflib>=6.1.1 (from sparqlwrapper)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib>=6.1.1->sparqlwrapper)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=6.1.1->sparqlwrapper) (3.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->sparqlwrapper) (1.16.0)\n",
            "Installing collected packages: isodate, rdflib, sparqlwrapper\n",
            "Successfully installed isodate-0.6.1 rdflib-6.3.2 sparqlwrapper-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pageviewapi"
      ],
      "metadata": {
        "id": "66w0wd3eu-_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9b4730-5ea3-4498-cba7-b771c536a599"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pageviewapi\n",
            "  Downloading pageviewapi-0.4.0-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pageviewapi) (2.27.1)\n",
            "Collecting attrdict (from pageviewapi)\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from attrdict->pageviewapi) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pageviewapi) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pageviewapi) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pageviewapi) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pageviewapi) (3.4)\n",
            "Installing collected packages: attrdict, pageviewapi\n",
            "Successfully installed attrdict-2.0.1 pageviewapi-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "LMeyegyfgdd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee07ffe4-ec23-426b-c4a6-a210fea34be3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.29.0-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=e89de88e1496ec07a9b75a082b11bb8fd04e6f73ddc1c34d4dff0881af5d3bf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.14.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.29.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "_KjIV0guhBIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a28de2-d565-473d-e1c7-7efb2b0f55e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=41220591e63ed0e051c29989da7cdef77cfb0ecea72490a384225684881ebb70\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COpv1aim8jLJ"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth',1000)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7j16mqC9L83"
      },
      "source": [
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "n07hKh23g9dG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from bs4 import BeautifulSoup, NavigableString, Tag"
      ],
      "metadata": {
        "id": "PyfC4F2Ya6sh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "pQIQvzqoaqbS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFQ0BQ8dnv50"
      },
      "source": [
        "import wikipedia"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "-6NVlM8dhEdI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT41X2h85r7j"
      },
      "source": [
        "#!pip install -U pip setuptools wheel\n",
        "#!pip install -U spacy\n",
        "#!python -m spacy download en_core_web_sm\n",
        "#!python -m spacy link en_core_web_sm en\n",
        "import spacy"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new imports\n",
        "\n",
        "import time\n",
        "import requests\n",
        "import re\n",
        "import difflib\n",
        "import pprint\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "chGS_8doxwwE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3KDOw-yx4JR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b065038d-8456-42f9-b5a7-1fa5a2bdce28"
      },
      "source": [
        "#import collections.abc as collections\n",
        "#from collections import Mapping\n",
        "\n",
        "!pip install Wikipedia-API\n",
        "import wikipediaapi\n",
        "\n",
        "!pip install git+https://github.com/Commonists/pageview-api.git\n",
        "#import pageviewapi"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Wikipedia-API\n",
            "  Downloading Wikipedia_API-0.5.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Wikipedia-API) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Wikipedia-API) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Wikipedia-API) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->Wikipedia-API) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Wikipedia-API) (3.4)\n",
            "Installing collected packages: Wikipedia-API\n",
            "Successfully installed Wikipedia-API-0.5.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/Commonists/pageview-api.git\n",
            "  Cloning https://github.com/Commonists/pageview-api.git to /tmp/pip-req-build-tg5c6x5p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Commonists/pageview-api.git /tmp/pip-req-build-tg5c6x5p\n",
            "  Resolved https://github.com/Commonists/pageview-api.git to commit 39e8b3c3c82f64a500e3dd4f306451c81c7e31b7\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load File**"
      ],
      "metadata": {
        "id": "WckjgVs-fZto"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K8U-ZpsRss_"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.ExcelFile(\"./optimizationOfHintGeneration/testSet.xlsx\").parse(\"Sheet1\")\n",
        "x = []\n",
        "x.append(df[\"Answer\"])\n",
        "\n",
        "dataPerson = []\n",
        "dataYear = []\n",
        "dataLocation = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if(row[\"Category\"] == \"Person\"):\n",
        "    dataPerson.append([row[\"Question\"], row[\"Answer\"]])\n",
        "  elif(row[\"Category\"] == \"Year\"):\n",
        "    dataYear.append([row[\"Question\"], row[\"Answer\"]])\n",
        "  elif(row[\"Category\"] == \"Location\"):\n",
        "    dataLocation.append([row[\"Question\"], row[\"Answer\"]])\n",
        "\n",
        "person_df = pd.DataFrame(dataPerson, columns=[\"Question\", \"Answer\"])\n",
        "year_df = pd.DataFrame(dataYear, columns=[\"Question\", \"Answer\"])\n",
        "location_df = pd.DataFrame(dataLocation, columns=[\"Question\", \"Answer\"])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New prediction method for years**"
      ],
      "metadata": {
        "id": "mKh1YgDQt3BC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dictionary for thumbcaption part of a year\n",
        "\n"
      ],
      "metadata": {
        "id": "oq8Zj9_w-aS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_table_info(url):\n",
        "    \"\"\"\n",
        "    Given a URL, this function opens the url and retrieves the information stored in a table.\n",
        "    \"\"\"\n",
        "    options = webdriver.FirefoxOptions()\n",
        "    #options.headless = True\n",
        "    options.add_argument('--headless')\n",
        "\n",
        "    driver = webdriver.Firefox(options=options)\n",
        "    driver.get(url)\n",
        "    time.sleep(5) # Wait for the page to load completely\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    driver.quit()\n",
        "    table = soup.find('table')\n",
        "    rows = table.find_all('tr')\n",
        "    headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
        "    data = []\n",
        "    for row in rows[1:]:\n",
        "        data.append([cell.text.strip() for cell in row.find_all('td')])\n",
        "    return (headers, data)\n",
        "\n",
        "def get_table_info_requests(url):\n",
        "    \"\"\"\n",
        "    Given a URL, this function opens the url and retrieves the information stored in a table.\n",
        "    \"\"\"\n",
        "    headers = []\n",
        "    data = []\n",
        "\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    table = soup.find('table')\n",
        "    rows = table.find_all('tr')\n",
        "    headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
        "    data = []\n",
        "    for row in rows[1:]:\n",
        "        data.append([cell.text.strip() for cell in row.find_all('td')])\n",
        "    return (headers, data)\n",
        "\n",
        "\n",
        "def get_links_in_section(wikipedia_url, section_heading):\n",
        "    \"\"\"\n",
        "    Given a Wikipedia URL, and a section of this article, returns an array of dictionaries containing the href, title, and description of each link on that section of the page.\n",
        "    \"\"\"\n",
        "    response = requests.get(wikipedia_url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    section = soup.find('span', {'id': section_heading})\n",
        "    if section is None:\n",
        "        return None\n",
        "    section_content = section.parent.find_next_sibling('ul')\n",
        "    if section_content is None:\n",
        "        return None\n",
        "    links = []\n",
        "    for item in section_content.find_all('li'):\n",
        "        link = item.find('a')\n",
        "        if link is not None and link.has_attr('href') and link['href'].startswith('/wiki/'):\n",
        "            title = link.get('title', '')\n",
        "            description = item.text.strip()\n",
        "            url = f\"https://en.wikipedia.org{link['href']}\"\n",
        "            links.append({'title': title, 'description': description, 'url': url})\n",
        "    print(links)\n",
        "    return links\n",
        "\n",
        "\n",
        "def get_links_in_section_with_sublinks(wikipedia_url, section_title):\n",
        "    \"\"\"\n",
        "    Given a Wikipedia URL, and a section of this article, returns an array of dictionaries containing the href, title, and description of each link  with its sublinks as well.\n",
        "    \"\"\"\n",
        "    response = requests.get(wikipedia_url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        section_heading = soup.find('span', {'id': section_title})\n",
        "        if section_heading is None:\n",
        "            return None\n",
        "        section = section_heading.parent\n",
        "        section_content = section.find_next_sibling('ul')\n",
        "        if section_content is None:\n",
        "            return None\n",
        "        links = []\n",
        "        for item in section_content.find_all('li'):\n",
        "            link = item.find('a')\n",
        "            if link is not None:\n",
        "                link_title = link.get('title')\n",
        "                link_url = 'https://en.wikipedia.org' + link.get('href')\n",
        "                link_description = item.text.replace(link_title, '').strip()\n",
        "                links.append({'title': link_title, 'url': link_url, 'description': link_description})\n",
        "                for sublink in item.find_all('a', href=True, recursive=False):\n",
        "                    sublink_title = sublink.get('title')\n",
        "                    sublink_url = 'https://en.wikipedia.org' + sublink.get('href')\n",
        "                    sublink_description = sublink.parent.text.replace(sublink_title, '').replace(link_title, '').strip()\n",
        "                    links.append({'title': sublink_title, 'url': sublink_url, 'description': sublink_description})\n",
        "        return links\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\"\"\"\n",
        "Returns all backlinks located in the thumbcaption section\n",
        "\"\"\"\n",
        "def get_wikipedia_backlinks_thumbcaption(url):\n",
        "    # Load the Wikipedia page HTML\n",
        "    page_html = requests.get(url).text\n",
        "    soup = BeautifulSoup(page_html, 'html.parser')\n",
        "\n",
        "    # Find the image caption on the page\n",
        "    caption = soup.find('div', class_='thumbcaption')\n",
        "\n",
        "    if caption is not None:\n",
        "      # Extract the caption text and any backlinks\n",
        "      backlink_sentences = {}\n",
        "      sentences = caption.text.strip().split('.')\n",
        "      for sentence in sentences:\n",
        "        links = caption.find_all('a', href=True, string=re.compile(sentence))\n",
        "        if len(links) > 0:\n",
        "            backlinks = []\n",
        "            for link in links:\n",
        "                backlink_url = 'https://en.wikipedia.org' + link['href']\n",
        "                backlink_title = link.get('title', '')\n",
        "                backlinks.append((backlink_url, backlink_title))\n",
        "            backlink_sentences[sentence] = backlinks\n",
        "    return backlink_sentences\n",
        "\n",
        "\"\"\"\n",
        "This function correctly prunes the links to only include the string after the last / character\n",
        "\"\"\"\n",
        "def prune_links(links):\n",
        "    pruned_links = []\n",
        "    for url, title in links:\n",
        "        pruned_url = url.split('/')[-1]\n",
        "        pruned_links.append((pruned_url, title))\n",
        "    return pruned_links\n",
        "\n",
        "\"\"\"\n",
        "This function first initializes an empty list combined_list that will hold the combined strings. Then, it uses a for loop to iterate through the input list in increments of 10 tuples at a time.\n",
        "For each sub-list of up to 10 tuples, it uses the list comprehension and join() method as before to combine the first elements of each tuple into a single string separated by '|'. \n",
        "Finally, the function appends each combined string to the combined_list and returns it at the end.\n",
        "\"\"\"\n",
        "def combine_first_elements(my_list):\n",
        "    combined_list = []\n",
        "    num_tuples = len(my_list)\n",
        "    for i in range(0, num_tuples, 10):\n",
        "        sub_list = my_list[i:i+10]\n",
        "        combined_str = '|'.join([tup[0] for tup in sub_list])\n",
        "        combined_list.append(combined_str)\n",
        "    return combined_list\n",
        "\n",
        "\"\"\"\n",
        "This function first initializes an empty list url_list that will hold the modified URLs. Then, it uses a for loop to iterate through each combined string in the input list. \n",
        "For each combined string, it concatenates the base URL with a forward slash and the combined string, and appends the resulting URL to the url_list. Finally, the function returns the url_list at the end.\n",
        "\"\"\"\n",
        "def add_combined_strings_to_url(base_url, combined_strings):\n",
        "    url_list = []\n",
        "    for string in combined_strings:\n",
        "        url_list.append(base_url + '/' + string)\n",
        "    return url_list\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This will output a list of all the sentences in the thumbcaption, split by ';'.\n",
        "\"\"\"\n",
        "def get_thumbcaption_sentences(url):\n",
        "    # Get the HTML content of the page\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "    # Find the thumbcaption element\n",
        "    thumbcaption = soup.find('div', class_='thumbcaption')\n",
        "\n",
        "    # Get all the sentences in the thumbcaption\n",
        "    sentences = thumbcaption.text.split('; ')\n",
        "\n",
        "    return sentences\n",
        "\n",
        "\"\"\"\n",
        "This function converts a list into a dict in the way that is needed.\n",
        "\"\"\"\n",
        "def list_to_dict(lst):\n",
        "    result = {}\n",
        "    for sublist in lst:\n",
        "        if len(sublist) >= 4:\n",
        "            key = sublist[1]\n",
        "            value = int(sublist[3].replace(',', ''))\n",
        "            result[key] = value\n",
        "    return result\n",
        "\n",
        "\"\"\"\n",
        "This function takes a list of links, opens each link to get the data, discards the header and converts the data into a dictionary using the list_to_dict() function, \n",
        "and then updates a combined dictionary with the resulting dictionary from each link. Finally, it returns the combined dictionary.\n",
        "\"\"\"\n",
        "def combine_dicts_from_links(link_list):\n",
        "    combined_dict = {}\n",
        "    for link in link_list:\n",
        "        header, data = get_table_info(link)\n",
        "        #print(data)\n",
        "        link_dict = list_to_dict(data)\n",
        "        combined_dict.update(link_dict)\n",
        "    return combined_dict\n",
        "\n",
        "\"\"\"\n",
        "This sorts the items in the dictionary based on the integer value of the second element in each key-value tuple (i.e. item[1]), in descending order (reverse=True).\n",
        "\"\"\"\n",
        "def sort_dict_desc(d):\n",
        "    return {k: v for k, v in sorted(d.items(), key=lambda item: int(item[1]), reverse=True)}\n",
        "\n",
        "\"\"\"\n",
        "This function takes in the ord dictionary and the sentences list as arguments.\n",
        "It initializes an empty list called result that we will append the found sentences to. It then iterates over each key in the ord dictionary and for each key, it iterates over each sentence in the sentences list. \n",
        "If the key is found in the sentence, the sentence is appended to the result list\n",
        "\"\"\"\n",
        "def find_sentences(ord, sentences):\n",
        "    result = []\n",
        "    for key in ord:\n",
        "        for sentence in sentences:\n",
        "            if key in sentence:\n",
        "                result.append(sentence)\n",
        "    return result\n",
        "\n",
        "\"\"\"\n",
        "This function takes a list of sentences and a keyword, removes the keyword from each sentence in the list, and returns the updated list.\n",
        "\"\"\"\n",
        "def remove_keyword(sentences, keyword):\n",
        "    updated_sentences = []\n",
        "    for sentence in sentences:\n",
        "        updated_sentence = sentence.replace(keyword, \"\")\n",
        "        updated_sentences.append(updated_sentence)\n",
        "    return updated_sentences\n",
        "\n",
        "\"\"\"\n",
        "This function takes a list of sentences and a list of keyword, removes the keyword from each sentence in the list, and returns the updated list. MAYBE NOT WORKING\n",
        "\"\"\"\n",
        "def remove_keywords(sentences, keywords):\n",
        "    \"\"\"\n",
        "    Removes one or more keywords from each sentence in the list of sentences.\n",
        "    \"\"\"\n",
        "    result = sentences\n",
        "    for entry in keywords:\n",
        "        result = remove_keyword(result, entry)\n",
        "    \n",
        "    return result\n",
        "\"\"\"\n",
        "This function prepends a given string to each sentence in a list.\n",
        "\"\"\"\n",
        "def prepend_string(sentences, prepend_str):\n",
        "    new_sentences = []\n",
        "    for sentence in sentences:\n",
        "        new_sentence = f\"{prepend_str}{sentence}\"\n",
        "        new_sentences.append(new_sentence)\n",
        "    return new_sentences\n",
        "\n",
        "\"\"\"\n",
        "This function creates a new list new_sentences and loops over each sentence in the input sentences list. \n",
        "It then uses a list comprehension and the difflib.SequenceMatcher class to compare the sentence to each sentence already in new_sentences. \n",
        "If the ratio of similarity between the two sentences is greater than 0.8 (adjust this threshold as needed), it considers the sentence to be similar and skips it. Otherwise, it adds the sentence to new_sentences. \n",
        "Finally, it returns the new list of unique sentences.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def remove_similar(sentences):\n",
        "    new_sentences = []\n",
        "    for sentence in sentences:\n",
        "        if not any(difflib.SequenceMatcher(None, sentence, s).ratio() > 0.8 for s in new_sentences):\n",
        "            new_sentences.append(sentence)\n",
        "    return new_sentences\n"
      ],
      "metadata": {
        "id": "wzL3elbnOlYl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTANT\n",
        "def thumbcaption_hints_per_year(years_list):\n",
        "  thumbcaption_hints = {}\n",
        "  wiki_base_link= 'https://en.wikipedia.org/wiki/'\n",
        "  pageviews_range_url = 'https://pageviews.wmcloud.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&range=all-time&pages='\n",
        "  \n",
        "  for y in years_list:\n",
        "    years_key = str(y)\n",
        "    test_link = wiki_base_link + years_key\n",
        "    sentences_of_thumbcaption = get_thumbcaption_sentences(test_link) #just gets the sentences from the thumbcaption section of a wikipedi years page \n",
        "    thumbcaption = get_wikipedia_backlinks_thumbcaption(test_link) #get all backlinks of the thumbcapture of the year (those are the most known events)\n",
        "    thumbcaption_key = next(iter(thumbcaption))\n",
        "    thumbcaption_val = thumbcaption[thumbcaption_key]\n",
        "    pruned = prune_links(thumbcaption_val) #prune those backlinks such that only the important part remains\n",
        "    com = combine_first_elements(pruned) #combine up to 10 of these links to create a request to pageview\n",
        "    url_list = add_combined_strings_to_url(pageviews_range_url, com) #now we have a list of pageview links with all the backlinks of the thumbcaption part of the wiki page\n",
        "    print(\"URL\")\n",
        "    print(url_list)\n",
        "    data=combine_dicts_from_links(url_list) #now we called the links and retreieved the pageviews; saved them as a dictionary\n",
        "    ord = sort_dict_desc(data) #now the list is ordered in ascending order\n",
        "    tmp = find_sentences(ord,sentences_of_thumbcaption) #search the corresponding sentence to the keyword (USA and school shooting for example)\n",
        "    #remove the years number from the hints OBVIOUSNESS\n",
        "    keywords_list = [years_key, 'clockwise ', 'Clockwise ', 'From top left', 'from top-left', 'from top left', 'From top-left', 'from top-left: ', ':', 'from left, clockwise'] #list of keywords that should be removed from the sentences\n",
        "    t4=remove_keywords(tmp, keywords_list)\n",
        "    prepend_str = 'In the same year, '\n",
        "    hints = prepend_string(t4, prepend_str)\n",
        "\n",
        "    final_hints = remove_similar(hints) #before adjusting the sentences\n",
        "    thumbcaption_hints[y] = final_hints\n",
        "\n",
        "  return thumbcaption_hints\n",
        "\n",
        "def get_year_thumbcaption_hints():\n",
        "  file_years_list = []\n",
        "  for index, row in year_df.iterrows():\n",
        "    file_years_list.append(row[\"Answer\"])\n",
        "\n",
        "  pop_thumb_hints = thumbcaption_hints_per_year(file_years_list)\n",
        "  return pop_thumb_hints\n",
        "\n",
        "#get_year_thumbcaption_hints()"
      ],
      "metadata": {
        "id": "cvcHIpCheNpL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dictionary for popular sports events of a year"
      ],
      "metadata": {
        "id": "O37okmzfPCcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Some global varaibles for faster execution\n",
        "pop_year_hints = {}\n",
        "pop_thumb_hints = {}\n",
        "\n",
        "def get_all_tables(url):\n",
        "    \"\"\"\n",
        "    Given a URL, this function opens the url and retrieves all tables on the page.\n",
        "    \"\"\"\n",
        "    options = webdriver.FirefoxOptions()\n",
        "    options.add_argument('--headless')\n",
        "\n",
        "    driver = webdriver.Firefox(options=options)\n",
        "    driver.get(url)\n",
        "    time.sleep(1) # Wait for the page to load completely\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    driver.quit()\n",
        "\n",
        "    tables = soup.find_all('table')\n",
        "    all_tables = []\n",
        "    for table in tables:\n",
        "        rows = table.find_all('tr')\n",
        "        headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
        "        data = []\n",
        "        for row in rows[1:]:\n",
        "            data.append([cell.text.strip() for cell in row.find_all('td')])\n",
        "        all_tables.append({'headers': headers, 'data': data})\n",
        "\n",
        "    return all_tables\n",
        "\n",
        "def get_first_elements(data_dict):\n",
        "    \"\"\"\n",
        "    Extracts the first element from each sublist in the 'data' list of lists in a dictionary and returns them in a separate list.\n",
        "    \n",
        "    Args:\n",
        "    - data_dict (dict): A dictionary containing a 'data' key with a list of lists as its value.\n",
        "    \n",
        "    Returns:\n",
        "    - A list containing the first element of each sublist in the 'data' list of lists.\n",
        "    \"\"\"\n",
        "    data_list = data_dict['data']\n",
        "    result = []\n",
        "    for sublist in data_list:\n",
        "        if len(sublist) > 0:\n",
        "            if len(sublist[0]) > 0:\n",
        "              result.append(sublist[0])\n",
        "    return result\n",
        "\n",
        "#prune the list of the hole wiki page down to the important table\n",
        "def prune_dict_list(dict_list, keyw):\n",
        "    for d in dict_list:\n",
        "        if 'headers' in d and d['headers'] == [keyw]:\n",
        "            return d\n",
        "    return None  # if no dict with the desired key-value pair is found\n",
        "\n",
        "#replace the \\n and create a list of lists \n",
        "def create_list_from_list_of_lists_key(lst, keyw):\n",
        "    result = []\n",
        "    for sublst in lst:\n",
        "        if sublst:\n",
        "          new_test = [item.replace(keyw, '') for item in sublst[0].split(keyw)]\n",
        "          result.append(new_test)\n",
        "    return result\n",
        "\n",
        "#replace the : and create a dict; {'year': 'CL-winner'}\n",
        "def create_dict_from_list_of_lists(lst):\n",
        "    result_dict = {}\n",
        "    for sublist in lst:\n",
        "        for item in sublist:\n",
        "            if \":\" in item:\n",
        "                key, value = item.split(\":\")\n",
        "                key = key.strip().replace(\"–\", \"-\")\n",
        "                value = value.strip()\n",
        "                result_dict[key] = value\n",
        "            else:\n",
        "                continue\n",
        "    return result_dict\n",
        "\n",
        "#split on the : and creates a dict\n",
        "def create_dict_from_list(lst):\n",
        "    result = {}\n",
        "    for item in lst:\n",
        "        parts = item.split(\":\")\n",
        "       # parts = parts.strip().replace(\":\", \"\")\n",
        "        result[parts[0]] = parts[1]\n",
        "    return result\n",
        "\n",
        "#splits on [ and creates a dict 1950: 'Farina'\n",
        "def get_year_with_driver(race_results):\n",
        "    results_dict = {}\n",
        "    for result in race_results:\n",
        "        if result:\n",
        "            results_dict[result[0].split(\"[\")[0]] = result[1]\n",
        "    return results_dict\n",
        "\n",
        "#get rid of the links ('Alberto Ascari[20]' => 'Alberto Ascari')\n",
        "def clean_driver_names(results_dict):\n",
        "    for year, driver in results_dict.items():\n",
        "        results_dict[year] = driver.split('[')[0].strip()\n",
        "    return results_dict\n",
        "\n",
        "#deletes the : from the key\n",
        "def clean_dict_keys(dict_to_clean):\n",
        "    cleaned_dict = {}\n",
        "    for key, value in dict_to_clean.items():\n",
        "        cleaned_dict[key.rstrip(':')] = value\n",
        "    return cleaned_dict\n",
        "\n",
        "#function to split on \\n but that lets the city names stay together\n",
        "def create_city_dict(city_list):\n",
        "    city_dict = {}\n",
        "    cities = city_list[0].split('\\n')\n",
        "    for city in cities:\n",
        "        if city:\n",
        "            year, *city_name = city.strip().split()\n",
        "            city_dict[year] = ' '.join(city_name)\n",
        "    return city_dict\n",
        "\n",
        "\n",
        "#get the dict of all the champions league winners \n",
        "def champions_league_winners_list():\n",
        "    champions_league_url = 'https://en.wikipedia.org/wiki/List_of_European_Cup_and_UEFA_Champions_League_finals#List_of_finals'\n",
        "    all = get_all_tables(champions_league_url) #gets all tables of wiki page\n",
        "    #first prune of that huge dict\n",
        "    keyw= 'showvteEuropean Cup and UEFA Champions League winners'\n",
        "    pruned_dict = prune_dict_list(all,keyw)\n",
        "    #second prune\n",
        "    inter = pruned_dict.get('data') \n",
        "    cl_list = inter[2:5] + inter[7:11]\n",
        "    tmp1 = create_list_from_list_of_lists_key(cl_list, '\\n')\n",
        "    tmp2 = create_dict_from_list_of_lists(tmp1)\n",
        "\n",
        "    return tmp2\n",
        "\n",
        "#get the dict of all the euros winners \n",
        "def uefa_euros_winners_list():\n",
        "    euros_url = 'https://en.wikipedia.org/wiki/List_of_UEFA_European_Championship_finals#List_of_finals'\n",
        "    all = get_all_tables(euros_url) #gets all tables of wiki page\n",
        "    #first prune of that huge dict\n",
        "    keyw= 'showvteUEFA European Championship winners'\n",
        "    pruned_dict = prune_dict_list(all,keyw)\n",
        "    #second prune\n",
        "    inter = pruned_dict.get('data') \n",
        "    tmp1 = create_list_from_list_of_lists_key(inter, '\\n')\n",
        "    tmp2 = create_dict_from_list_of_lists(tmp1)\n",
        "\n",
        "    return tmp2\n",
        "\n",
        "#get the dict of all the wold cup winners \n",
        "def uefa_worlds_winners_list():\n",
        "    worlds_url = 'https://en.wikipedia.org/wiki/List_of_FIFA_World_Cup_finals#List_of_final_matches'\n",
        "    all = get_all_tables(worlds_url) #gets all tables of wiki page\n",
        "    tmp3=get_first_elements(all[3])\n",
        "    #first prune of that huge dict\n",
        "    keyw= 'showvteFIFA World Cup'\n",
        "    pruned_dict = prune_dict_list(all,keyw)\n",
        "    #second prune\n",
        "    inter = pruned_dict.get('data') \n",
        "    inter = inter[2]\n",
        "    years = [s for s in inter[0].split('\\n')]\n",
        "    my_dict = dict(zip(years, tmp3))\n",
        "\n",
        "    return my_dict\n",
        "\n",
        "#get the dict of all the F1 drivers world champions\n",
        "def f1_winners_list():\n",
        "    euros_url = 'https://en.wikipedia.org/wiki/List_of_Formula_One_World_Drivers%27_Champions#By_season'\n",
        "    all = get_all_tables(euros_url) #gets all tables of wiki page\n",
        "    lst = all[2].get('data')\n",
        "    tmp2 = get_year_with_driver(lst)\n",
        "    tmp2 = clean_driver_names(tmp2)\n",
        "\n",
        "    return tmp2\n",
        "\n",
        "#get the dict of all summer olympics host cities\n",
        "def summer_olympics_hosts_list():\n",
        "    summerO_url = 'https://en.wikipedia.org/wiki/Summer_Olympic_Games#List_of_Summer_Olympic_Games'\n",
        "    all = get_all_tables(summerO_url) #gets all tables of wiki page\n",
        "    lst = all[10].get('data')\n",
        "    tmp1 = create_list_from_list_of_lists_key(lst, '\\n')\n",
        "    tmp1 = tmp1[0]\n",
        "    tmp1 = create_dict_from_list(tmp1)\n",
        "    tmp1 = clean_dict_keys(tmp1)\n",
        "    tmp1 = clean_driver_names(tmp1)\n",
        "\n",
        "    return tmp1\n",
        "\n",
        "#get the dict of all winter olympics host cities\n",
        "def winter_olympics_hosts_list():\n",
        "    winterO_url = 'https://en.wikipedia.org/wiki/Winter_Olympic_Games#List_of_Winter_Olympic_Games'\n",
        "    all = get_all_tables(winterO_url) #gets all tables of wiki page\n",
        "    lst = all[8].get('data')\n",
        "    tmp1 = create_list_from_list_of_lists_key(lst, '\\n')\n",
        "    tmp1 = tmp1[0]\n",
        "    tmp1 = create_dict_from_list(tmp1)\n",
        "    tmp1 = clean_dict_keys(tmp1)\n",
        "    tmp1 = clean_driver_names(tmp1)\n",
        "\n",
        "    return tmp1"
      ],
      "metadata": {
        "id": "ARMx75Z0QkVh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The basic sentences out of which we create the hint-sentences\n",
        "basic_sentences =  ['In the same year, ', 'In the previous year, ', 'In the following year, ']\n",
        "sport_sentences = [' has won the UEFA Champions League.', ' has won the UEFA Euro Football Championship.', ' has won the FIFA World Cup.', ' has won the F1 Drivers World Championship.', ]\n",
        "olympic_sentences = ['In the same year, the Summer Olympics were held in ', 'In the previous year, the Summer Olympics were held in ', 'In the following year, the Summer Olympics were held in ', 'In the same year, the Winter Olympics were held in ', 'In the previous year, the Winter Olympics were held in ', 'In the following year, the Winter Olympics were held in ']\n",
        "\n",
        "#write all of the winners of the different sports categories into lists\n",
        "cl_all = champions_league_winners_list() #For the Champions league, \n",
        "euro_all = uefa_euros_winners_list() #For Football-Euros\n",
        "worlds_all = uefa_worlds_winners_list() #For Football-Worlds\n",
        "f1_all = f1_winners_list() #For Fromula1\n",
        "summer_olympics_all = summer_olympics_hosts_list() #For OlympicSummerGames \n",
        "winter_olympics_all = winter_olympics_hosts_list() #For OlympicWinterGames \n",
        "\n",
        "'''\n",
        "takes a list of years and then creates a dict of dicts, where (if available) the most popular sports events of that year are saved as hints.\n",
        "returns a dict with the corresponding sports events from the years in years_list\n",
        "'''\n",
        "def popular_sports_per_year(years_list):\n",
        " \n",
        "  pop_sport_hints_year = {}\n",
        "  for index in years_list:\n",
        "    year = index\n",
        "    year_s = str(year)\n",
        "\n",
        "    year_dict = {\n",
        "        'cl': '', 'p_cl': '', 'f_cl': '',\n",
        "        'euros': '', 'p_euros': '', 'f_euros': '',\n",
        "        'worlds': '', 'p_worlds': '', 'f_worlds': '',\n",
        "        'f1': '', 'p_f1': '', 'f_f1': '',\n",
        "        'summer': '', 'p_summer': '', 'f_summer': '',\n",
        "        'winter': '', 'p_winter': '', 'f_winter': '', \n",
        "        }\n",
        "\n",
        "  # UEFA Champions League: Create the sentences like (In the same-, the following-, the previous-year)\n",
        "    for key in cl_all:\n",
        "      if int(key.split('-')[1]) == year % 100:\n",
        "        result = cl_all[key]\n",
        "        break\n",
        "    if result:\n",
        "      year_dict['cl'] = basic_sentences[0] + result + sport_sentences[0] \n",
        "    for key in cl_all:\n",
        "      if int(key.split('-')[1]) == (year - 1) % 100:\n",
        "        result = cl_all[key]\n",
        "        break\n",
        "    if result:\n",
        "      year_dict['p_cl'] = basic_sentences[1] + result + sport_sentences[0] \n",
        "    for key in cl_all:\n",
        "      if int(key.split('-')[1]) == (year + 1) % 100:\n",
        "        result = cl_all[key]\n",
        "        break\n",
        "    if result:\n",
        "      year_dict['f_cl'] = basic_sentences[2] + result + sport_sentences[0]       \n",
        "\n",
        "  # UEFA EURO Football Championship: Create the sentences like (In the same-, the following-, the previous-year)\n",
        "    for d in euro_all:\n",
        "      if year_s in d:\n",
        "        year_dict['euros'] = basic_sentences[0] + euro_all[year_s] + sport_sentences[1]       \n",
        "    for d in euro_all:\n",
        "      t = year - 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['p_euros'] = basic_sentences[1] + euro_all[year_int] + sport_sentences[1]\n",
        "    for d in euro_all:\n",
        "      t = year + 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['f_euros'] = basic_sentences[2] + euro_all[year_int] + sport_sentences[1]\n",
        "\n",
        "  # FIFA WORLD Football Championship: Create the sentences like (In the same-, the following-, the previous-year)\n",
        "    for d in worlds_all:\n",
        "      if year_s in d:\n",
        "        year_dict['worlds'] = basic_sentences[0] + worlds_all[year_s] + sport_sentences[2]\n",
        "    for d in worlds_all:\n",
        "      t = year - 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['p_worlds'] = basic_sentences[1] + worlds_all[year_int] + sport_sentences[2]\n",
        "    for d in worlds_all:\n",
        "      t = year + 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['f_worlds'] = basic_sentences[2] + worlds_all[year_int] + sport_sentences[2]\n",
        "\n",
        "  # F1 WORLD Drivers Championship: Create the sentences like (In the same-, the following-, the previous-year)\n",
        "    for d in f1_all:\n",
        "      if year_s in d:\n",
        "        year_dict['f1'] = basic_sentences[0] + f1_all[year_s] + sport_sentences[3]\n",
        "    for d in f1_all:\n",
        "      t = year - 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['p_f1'] = basic_sentences[1] + f1_all[year_int] + sport_sentences[3]  \n",
        "    for d in f1_all:\n",
        "      t = year + 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['f_f1'] = basic_sentences[2] + f1_all[year_int] + sport_sentences[3]    \n",
        "\n",
        "  # Summer Olympic Games: Create the sentences like (In the same-, the following-, the previous-year)\n",
        "    for d in summer_olympics_all:\n",
        "      if year_s in d:\n",
        "        year_dict['summer'] = olympic_sentences[0] + summer_olympics_all[year_s] \n",
        "    for d in summer_olympics_all:\n",
        "      t = year - 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['p_summer'] = olympic_sentences[1] + summer_olympics_all[year_int] \n",
        "    for d in summer_olympics_all:\n",
        "      t = year + 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['f_summer'] = olympic_sentences[2] + summer_olympics_all[year_int]  \n",
        "\n",
        "  # Winter Olympic Games: Create the sentences like (In the same-, the following-, the previous-year)\n",
        "    for d in winter_olympics_all:\n",
        "      if year_s in d:\n",
        "        year_dict['winter'] = olympic_sentences[3] + winter_olympics_all[year_s] \n",
        "    for d in winter_olympics_all:\n",
        "      t = year - 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['p_winter'] = olympic_sentences[4] + winter_olympics_all[year_int] \n",
        "    for d in winter_olympics_all:\n",
        "      t = year + 1\n",
        "      year_int = str(t)\n",
        "      if year_int in d:\n",
        "        year_dict['f_winter'] = olympic_sentences[5] + winter_olympics_all[year_int]  \n",
        "\n",
        "    #write the entry in the dict\n",
        "    pop_sport_hints_year[year] = year_dict\n",
        "  \n",
        "  return pop_sport_hints_year\n",
        "\n",
        "#CALL FUNCTION\n",
        "#returns a dictionary of the years that occured in the xls file, with its corresponding hints from the most popular sports events of that year.\n",
        "def get_year_sports_hints():\n",
        "  file_years_list = []\n",
        "  for index, row in year_df.iterrows():\n",
        "    file_years_list.append(row[\"Answer\"])\n",
        "  pop_sport_hints = popular_sports_per_year(file_years_list)\n",
        "  \n",
        "  return pop_sport_hints\n"
      ],
      "metadata": {
        "id": "kuWB4hrxPCcV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text and add special tokens\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "    # Convert the tokens to a tensor\n",
        "    token_tensor = torch.tensor(tokens).unsqueeze(0)\n",
        "    return token_tensor\n",
        "\n",
        "def get_similarity_score(text1, text2):\n",
        "    # Preprocess both texts\n",
        "    tensor1 = preprocess_text(text1)\n",
        "    tensor2 = preprocess_text(text2)\n",
        "\n",
        "    # Pass both tensors to the model to get the embeddings\n",
        "    with torch.no_grad():\n",
        "        output1 = model(tensor1)\n",
        "        output2 = model(tensor2)\n",
        "    \n",
        "    # Compute the cosine similarity between the two embeddings\n",
        "    cosine_sim = torch.nn.functional.cosine_similarity(output1.last_hidden_state.mean(dim=1), output2.last_hidden_state.mean(dim=1), dim=1)\n",
        "    return cosine_sim.item()"
      ],
      "metadata": {
        "id": "OVdCk8gQQifE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "2e3077fda0c04e998d6f9b190a313af7",
            "79fa7dc445054f369713c7528985cb76",
            "b029e29145154c0598c20da2623c665f",
            "c95671b034ff496eb12ebcf4782d9793",
            "6cbba4313638449db761910c45ec2525",
            "c02e3efe5f28490c934c8c2bcb11b19c",
            "889c3e14ec7d41f59d430025e0732af6",
            "fece28c7ddaf4c838a8dc2a927ae25ac",
            "963ca057072c4a098844321143faaf4b",
            "c0fa0d1042c84e63bf099a6addfb1bcb",
            "a9d81e17e4734513927d47e195ca2dcd",
            "a268c928ee064ed98e6f20d101889bd5",
            "c59ec4e2f2ce4f29b9b645d1efde7279",
            "ff1716c02b5c426d9d5d470519d0ea2a",
            "c76bc47d703d45b3bc98bf6726ec740f",
            "4df2ba959d1b444f8174dee4c7e6e73b",
            "91968fc50c0148b5bca69031bb3a40f5",
            "2b1a5d1c0bb644a7af051cd760d1a180",
            "83bb5190e2e34e8c96c8c5692cbacd55",
            "a07fa7f665a643d2a33706ac68c8cbb6",
            "d132b8194ca645fd9f61cc9190b1fa6b",
            "97effe0b3bf94cf6ba8d18fef5f0e2ed",
            "3939f16a072641069cf5f1b5aab86e15",
            "9c50061a3b13420ba8b83c32a77fa8b5",
            "977d87520d90447fa6f7a15d619497c3",
            "3c5e148e4bd84114afd916fc171b86c9",
            "615fc8c6dd3d47e8b293959c87d07a70",
            "d6235fad7c774de8817f7d3f1ad19a68",
            "d0977afc41194db4a37eac80944f9b53",
            "29d49b5e0fee46d7921f3f18bb3e6873",
            "1d2fb06ff0b24129a0c5cfe6cc4821b5",
            "9a251d6ef16e430db0a4f98d05b3ae82",
            "63588c2bc1304c52a4c4dc3e87f1456c",
            "9527f5a524034758823b4455dcc90f2d",
            "7575367af58a4014b01a07b9587f1060",
            "0267a16c127841aab94cf55aa0ed3b06",
            "3c285f23ac6c4e7c8bab966ba204f70f",
            "508c7cd9977745b1b9c0066e9cd5a324",
            "62df688f73e342ea91c90ba60e7de0d5",
            "f4366d4710664b4ebc7b605a7ffab843",
            "2f2c3ee80a3f471fb43e2fc3e9bb2353",
            "e2c6cccfa142400c92da839baf6f9a2e",
            "e5bd3b23166b4117821715483aa9134b",
            "ebe044079d3148928bf88683f4583869",
            "32e0944bde7748b38d7442810185e759",
            "4178e384b5a647598c9f247b1938509c",
            "3ac4808ffa9a4d52b7cd911001d6aa63",
            "b73602400b7b47539b57e50241da7254",
            "59b40b3c97c04c439790cdff390d8122",
            "f5c74df62ca04d529e5e32bb2d9d2248",
            "d75c7489403c49688965ad2a4a2e90b4",
            "fc8c5a11ffdb40ef9e8e9e99dd004f48",
            "999bda6f524245a1bff9aabbc5c97e30",
            "cc961e4c0bc74d3b8b896903d8a4a7b6",
            "3251ff0b4b7442269ebcaa72d5f82fcb"
          ]
        },
        "outputId": "592ec4ba-6258-4872-f071-1a6200ba3c41"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e3077fda0c04e998d6f9b190a313af7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a268c928ee064ed98e6f20d101889bd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3939f16a072641069cf5f1b5aab86e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9527f5a524034758823b4455dcc90f2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32e0944bde7748b38d7442810185e759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test it!"
      ],
      "metadata": {
        "id": "6vIkujY8y8Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the hints for the questions where the answer is a year and print them\n",
        "#if len(pop_year_hints) == 0 and len(pop_thumb_hints) == 0:\n",
        "pop_year_hints = get_year_sports_hints()\n",
        "pop_thumb_hints = get_year_thumbcaption_hints()\n",
        "\n",
        "years_hints = {}\n",
        "\n",
        "for y in pop_year_hints:\n",
        "  year_dict = {\n",
        "      'sports': pop_year_hints[y],\n",
        "      'thumbcaption': pop_thumb_hints[y]\n",
        "  }\n",
        "\n",
        "  years_hints[y] = year_dict\n",
        "\n",
        "generated_hints_for_years = years_hints\n",
        "pprint.pprint(generated_hints_for_years, indent=1)\n",
        "\n",
        "'''\n",
        "#Test for utility score of new questions; calculate score via BERT for each question,hint pair and write the score together with the question into the sim_scores dictionary.\n",
        "'''\n",
        "\n",
        "qa_dict = dict(zip(year_df['Answer'], year_df['Question']))\n",
        "sim_scores = years_hints\n",
        "\n",
        "for y, q in qa_dict.items():\n",
        "  for year, data in years_hints.items():\n",
        "    if y == year:\n",
        "      for category, subdata in data.items():\n",
        "        #sim_scores[year]['question'] = q\n",
        "        if category != 'thumbcaption':\n",
        "          for key, value in subdata.items():\n",
        "            sim_scores[year][category][key] = {}\n",
        "            similarity_score = get_similarity_score(q,value)\n",
        "            sim_scores[year][category][key][value] = similarity_score\n",
        "        else:\n",
        "          for i in subdata:\n",
        "            sim_scores[year][category] = {}\n",
        "            similarity_score = get_similarity_score(q,i)\n",
        "            sim_scores[year][category][i] = similarity_score\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "for y, q in qa_dict.items():\n",
        "  for year, data in years_hints.items():\n",
        "    if y == year:\n",
        "      sim_scores[year]['question'] = q\n",
        "\n",
        "pprint.pprint(sim_scores, indent=1)"
      ],
      "metadata": {
        "id": "-Pcx5uKity9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa33c729-2df4-4949-b8f9-908fb8d68e4c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dictionary for thumbcaption part of a year\n",
        "\n"
      ],
      "metadata": {
        "id": "-sY3op9nbu0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New prediction Methods for locations and people:**"
      ],
      "metadata": {
        "id": "98m65vq_tyWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All the functions to get wiki-categories of a location-, or person-question"
      ],
      "metadata": {
        "id": "BWmgtRy6t6rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to create some sort of metric to explain how popular or well-known a entity is, to give better hints. Therefore we look at how many options there are (how many entries in a certain category) and at how diverse these options are. If a category for example has 100s of entries, then it probably isn't a good base for a hint because there are many to choose from.\n",
        "\n"
      ],
      "metadata": {
        "id": "uRT1_8HpefRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category_links(categories):\n",
        "    \"\"\"\n",
        "    Given a list of Wikipedia category names, creates the corresponding Wikipedia category links.\n",
        "    \n",
        "    Args:\n",
        "        categories (list): A list of Wikipedia category names to create links for.\n",
        "    \n",
        "    Returns:\n",
        "        category_links (list): A list of Wikipedia category links corresponding to the input categories.\n",
        "    \"\"\"\n",
        "    category_links = []\n",
        "    for category in categories:\n",
        "        category_link = \"https://en.wikipedia.org/wiki/Category:\" + category.replace(\" \", \"_\")\n",
        "        #category_link = \"https://wikipedia.org/wiki/Category:\" + category.replace(\" \", \"_\")\n",
        "        category_links.append(category_link)\n",
        "    return category_links\n",
        "\n",
        "def get_category_with_underscores(categories):\n",
        "    \"\"\"\n",
        "    Given a list of Wikipedia category names, creates the corresponding Wikipedia category links.\n",
        "    Args: categories (list): A list of Wikipedia category names to create links for.\n",
        "    Returns: category_links (list): A list of Wikipedia category links corresponding to the input categories.\n",
        "    \"\"\"\n",
        "    category_links = []\n",
        "    for category in categories:\n",
        "        category_link = category.replace(\" \", \"_\")\n",
        "        category_links.append(category_link)\n",
        "    return category_links\n",
        "\n",
        "def get_category_entry_counts(categories):\n",
        "    \"\"\"\n",
        "    Given a list of Wikipedia category names, retrieves the number of entries in each category and returns a dictionary\n",
        "    with the category names as keys and the entry counts as values.\n",
        "    Args: categories (list): A list of Wikipedia category names to retrieve entry counts for.\n",
        "    Returns: category_entry_counts (dict): A dictionary of Wikipedia category names and their respective entry counts.\n",
        "    \"\"\"\n",
        "    category_links = get_category_links(categories)\n",
        "    category_entry_counts = {}\n",
        "\n",
        "    for i, category_link in enumerate(category_links):\n",
        "        response = requests.get(category_link)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        try:\n",
        "            entry_count_text = soup.find(\"div\", {\"id\": \"catlinks\"}).find_all(\"a\")[1].text.strip()\n",
        "            entry_count = int(entry_count_text.split()[-2])\n",
        "            category_name = categories[i]\n",
        "            if category_name:\n",
        "                category_entry_counts[category_name] = entry_count\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return category_entry_counts"
      ],
      "metadata": {
        "id": "30UlMOBLt9uH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rewrite with wikiapi\n",
        "\n",
        "\n",
        "def get_wikipedia_categories(title):\n",
        "    \"\"\"\n",
        "    Retrieves the categories of a Wikipedia page using the wikipediaapi package.\n",
        "    Args: title (str): The title of the Wikipedia page.\n",
        "    Returns: categories (list): A list of categories associated with the page.\n",
        "    \"\"\"\n",
        "    wikipedia = wikipediaapi.Wikipedia(\"en\")\n",
        "    page = wikipedia.page(title)\n",
        "    #print(page)\n",
        "    if not page.exists():\n",
        "        return []\n",
        "    categories = [c for c in page.categories]\n",
        "    return [cat.split(\":\")[1] for cat in categories]\n"
      ],
      "metadata": {
        "id": "Y64pRY2CJSLx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category_subcategories(link):\n",
        "    #print(link)\n",
        "    # Create a Wikipedia API object\n",
        "    wiki_api = wikipediaapi.Wikipedia('en')\n",
        "\n",
        "    # Extract the category name from the link\n",
        "    category_name = link.split('/')[-1]\n",
        "\n",
        "    # Retrieve the category page\n",
        "    category_page = wiki_api.page(f\"Category:{category_name}\")\n",
        "\n",
        "    # Find the subcategories section of the page\n",
        "    subcategories_section = category_page.categorymembers\n",
        "\n",
        "    # Extract the subcategories from the section\n",
        "    subcategories = []\n",
        "    i=0\n",
        "\n",
        "    for subcategory in subcategories_section.values():\n",
        "      if i < 100: #threshold for how many entries per category\n",
        "        i +=1\n",
        "        if subcategory.ns == wikipediaapi.Namespace.CATEGORY:\n",
        "            subcategories.append(subcategory.fullurl)\n",
        "\n",
        "    return subcategories\n",
        "\n",
        "\n",
        "def get_category_pages(category_title, limit=100):\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"list\": \"categorymembers\",\n",
        "        \"cmtitle\": category_title,\n",
        "        \"cmlimit\": str(limit) # limit to 100 entries\n",
        "    }\n",
        "    pages = []\n",
        "    while True:\n",
        "        response = requests.get(\"https://en.wikipedia.org/w/api.php\", params=params).json()\n",
        "        pages += [p[\"title\"] for p in response[\"query\"][\"categorymembers\"]]\n",
        "        if \"continue\" in response:\n",
        "            params.update(response[\"continue\"])\n",
        "        else:\n",
        "            break\n",
        "        if len(pages) >= limit: # break the loop if the number of entries exceeds 100\n",
        "            break\n",
        "    return pages[:limit] # return only the first 100 entries\n"
      ],
      "metadata": {
        "id": "oQxIJV3W3AC9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cat_with_all_subcats(searched_location):\n",
        "    \"\"\"\n",
        "    Given a list of Wikipedia category names, retrieves the number of entries in each category and returns a dictionary\n",
        "    with the category names as keys and the entry counts as values.\n",
        "    Args: searched_location: The desired location for wich a hint should be created. (The answer to the question)\n",
        "    Returns: dicto (dict): A dictionary of all categories with the subcategories and how many entries there are in each.\n",
        "    \"\"\"\n",
        "    #retrieves the list of categories from the location-wikipedia page\n",
        "    categories = get_wikipedia_categories(searched_location)\n",
        "    categories_with_underscore = get_category_with_underscores(categories)\n",
        "    categories_links = get_category_links(categories)\n",
        "\n",
        "    categories_with_links_dict = {}\n",
        "    for i in range(len(categories_with_underscore)):\n",
        "      key = categories_with_underscore[i]\n",
        "      link = categories_links[i]\n",
        "      categories_with_links_dict[key] = link\n",
        "\n",
        "    cat_with_subcats_dict = {}\n",
        "    for category in categories_links:\n",
        "      sub_cats = get_category_subcategories(category)\n",
        "      #print(category)\n",
        "      ct = get_category_title(category)\n",
        "      pages_list = get_category_pages(ct)\n",
        "      #print(pages_list)\n",
        "      filtered_list = [str(entry) for entry in pages_list if not entry.startswith(\"Category:\")]\n",
        "      new_list = [len(filtered_list), filtered_list]\n",
        "      if sub_cats is None:\n",
        "        continue\n",
        "      else:\n",
        "        cat_with_subcats_dict[category] = [[len(sub_cats), sub_cats], new_list]\n",
        "\n",
        "    return cat_with_subcats_dict\n",
        "\n",
        "#input a url of a category, this returns the tilte\n",
        "def get_category_title(category_url):\n",
        "    parts = category_url.split('/')\n",
        "    title = [part for part in parts if part.startswith('Category:')]\n",
        "    if title:\n",
        "        return title[0]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "#input searched location and returns a dict with number of pages and number of subcategories\n",
        "def get_categories_ranking(searched_location):\n",
        "  categories = get_wikipedia_categories(searched_location)\n",
        "  categories_links = []\n",
        "  cat_without_articles = []\n",
        "\n",
        "  bad_list = ['Articles with', 'CS1', 'Wikipedia', 'Webarchive', 'Short', 'Biography', 'Commons', 'Pages', 'Use', 'All', 'Articles', 'Coordinates', 'Engvar', 'Lang', 'Official' ]\n",
        "\n",
        "  for c in categories:\n",
        "    if not any(c.startswith(word) for word in bad_list):\n",
        "        cat_without_articles.append(c)\n",
        "    \n",
        "  categories_links = get_category_links(cat_without_articles)\n",
        "  cat_with_amount = {}\n",
        "\n",
        "  for category in categories_links:\n",
        "    sub_cats = get_category_subcategories(category)\n",
        "    ct = get_category_title(category)\n",
        "    pages_list = get_category_pages(ct)\n",
        "\n",
        "    if sub_cats is None:\n",
        "      continue\n",
        "    else:\n",
        "      cat_with_amount[category] =  len(pages_list), len(sub_cats)\n",
        "  #x[0] sort after subcats and x[1] sorts after pages\n",
        "  sorted_dict = dict(sorted(cat_with_amount.items(), key=lambda x: x[1], reverse=True))\n",
        "  \n",
        "  return sorted_dict\n",
        "\n",
        "#NEW\n",
        "\n",
        "#extract the category part from the wiki links\n",
        "def extract_last_parts(links):\n",
        "    last_parts = []\n",
        "    for link in links:\n",
        "        last_part = link.split('/')[-1]\n",
        "        last_parts.append(last_part)\n",
        "    return last_parts\n",
        "\n",
        "#function to concatenate the category links to insert into a pageviews url\n",
        "def concatenate_elements(elements, n=10):\n",
        "    result = []\n",
        "    for i in range(0, len(elements), n):\n",
        "        group = elements[i:i+n]\n",
        "        result.append('|'.join(group))\n",
        "    return result\n",
        "\n",
        "\"\"\"\n",
        "This function first initializes an empty list url_list that will hold the modified URLs. Then, it uses a for loop to iterate through each combined string in the input list. \n",
        "For each combined string, it concatenates the base URL with a forward slash and the combined string, and appends the resulting URL to the url_list. Finally, the function returns the url_list at the end.\n",
        "\"\"\"\n",
        "def combine_pv_urls(base_url, combined_strings):\n",
        "    url_list = []\n",
        "    for string in combined_strings:\n",
        "        url_list.append(base_url  + string)\n",
        "    return url_list\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This function takes a list of links, opens each link to get the data, discards the header and converts the data into a dictionary using the list_to_dict() function, \n",
        "and then updates a combined dictionary with the resulting dictionary from each link. Finally, it returns the combined dictionary.\n",
        "\"\"\"\n",
        "def combine_dicts_from_links(link_list):\n",
        "    combined_dict = {}\n",
        "    for link in link_list:\n",
        "        header, data = get_table_info(link)\n",
        "        #print(data)\n",
        "        link_dict = list_to_dict(data)\n",
        "        combined_dict.update(link_dict)\n",
        "    return combined_dict"
      ],
      "metadata": {
        "id": "8Iqf7G5usErf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_values_to_links(links_dict, values_dict):\n",
        "    new_dict = {}\n",
        "    for link, value in links_dict.items():\n",
        "        key = link.split(':')[-1]\n",
        "        if key in values_dict:\n",
        "            value += (values_dict[key],)\n",
        "        new_dict[link] = value\n",
        "    return new_dict\n",
        "\n",
        "def combine_catnumbers_pvs(ord_dict, norm_dict):\n",
        "  for key in ord_dict:\n",
        "    if key in norm_dict:\n",
        "      ord_dict[key] = ord_dict[key] + (norm_dict[key],)\n",
        "      print(ord_dict)\n",
        "  return ord_dict\n",
        "\n",
        "def add_values_to_linkss(links_dict, values_dict):\n",
        "  new_dict = {}\n",
        "  for loc, ord_list in links_dict.items():\n",
        "    for loc2, ord_list_pv in values_dict.items():\n",
        "      if loc == loc2:\n",
        "        new_dict[loc] = combine_catnumbers_pvs(ord_list, ord_list_pv)\n",
        "        #new_dict[loc] = combine_catnumbers_pvs(ord_list_pv, ord_list)\n",
        "  return new_dict\n",
        "\n",
        "#combines the pageviews of the categories of the location together with the sub-categories and pages of those subcategories\n",
        "def combine_pv_cats(cat_dict, pv_dict):\n",
        "  tmp = cat_dict\n",
        "\n",
        "  for key, value in cat_dict.items():\n",
        "    for key2, value2 in pv_dict.items():\n",
        "      category_name = key.split('/')[-1]\n",
        "      new_string = key2.replace(' ', '_')\n",
        "\n",
        "      if category_name == new_string:\n",
        "        #print(category_name)\n",
        "        org_tup = cat_dict[key]\n",
        "        #new_tup = org_tup + (value2, 0)\n",
        "        new_tup = org_tup + (value2,)\n",
        "        tmp[key] = new_tup\n",
        "\n",
        "        if len(new_tup) != 3:\n",
        "          print(\"PROBLEM\\n\")\n",
        "\n",
        "  return tmp\n",
        "\n",
        "#combines the pageviews of the categories of the location together with the sub-categories and pages of those subcategories\n",
        "def get_dict_for_every_location(cat_ranking, cat_with_pv):\n",
        "  ret=cat_ranking\n",
        "\n",
        "  for location, value in cat_ranking.items():\n",
        "    for location1, value1 in cat_with_pv.items():\n",
        "      if location == location1:\n",
        "        tmp = combine_pv_cats(value, value1)\n",
        "        ret[location] = tmp\n",
        "  return ret"
      ],
      "metadata": {
        "id": "GO7WJ-RIn3wQ"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# person_questions_dict = dict(zip(person_df['Answer'], person_df['Question']))\n",
        "\n",
        "# for subject, question in person_questions_dict.items():\n",
        "  #print(subject)\n",
        "  # ranking = get_categories_ranking(subject)\n",
        "  #categories = get_wikipedia_categories(subject)\n",
        "\n",
        "#print(ranking)\n",
        "#print(categories)"
      ],
      "metadata": {
        "id": "z4MpaoWRLoc1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categories(subject_dict):\n",
        "  categories_for_subject_dict= {}\n",
        "  rankings_for_categories_dict = {}\n",
        "  #creates a dict with all the dicts of each location with its categories and sub-categories\n",
        "  for subject, question in subject_dict.items():\n",
        "    dicto = get_cat_with_all_subcats(subject)\n",
        "    categories_for_subject_dict[subject] = dicto\n",
        "    ranking = get_categories_ranking(subject)\n",
        "    ordict = OrderedDict(ranking)\n",
        "    rankings_for_categories_dict[subject] = ordict\n",
        "\n",
        "  return rankings_for_categories_dict\n",
        "\n",
        "#given a dictionary with all the categories, the function returns the categories in a OrderedDict with the corresponding pageviews for each category\n",
        "def get_pageviews_for_categories(cat_dict):\n",
        "  #pageviews_range_url = 'https://pageviews.wmcloud.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&range=all-time&pages='\n",
        "  pageviews_range_url = 'https://pageviews.wmcloud.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&range=last-year&pages='\n",
        "  \n",
        "  all_cats_with_pvs = {}\n",
        "\n",
        "  for subject in cat_dict:\n",
        "    ord_dict = OrderedDict()\n",
        "    ordered_dict_sub =  cat_dict[subject]\n",
        "    links_list = [link for link in ordered_dict_sub.keys()]\n",
        "    #print(links_list)\n",
        "    pruned_link_parts_list = extract_last_parts(links_list)\n",
        "    concat_str_for_links = concatenate_elements(pruned_link_parts_list) #combine up to 10 of these links to create a request to pageview\n",
        "    pageviews_url_list = combine_pv_urls(pageviews_range_url, concat_str_for_links) #now we have a list of pageview links with all the backlinks of the thumbcaption part of the wiki page (REUSED FROM YEARS PART)\n",
        "    #print(pageviews_url_list)\n",
        "    categories_with_pageviews =combine_dicts_from_links(pageviews_url_list) #now we called the links and retreieved the pageviews; saved them as a dictionary\n",
        "    #print(categories_with_pageviews)\n",
        "    ordered_categories_with_pageviews = sort_dict_desc(categories_with_pageviews) #now the list is ordered in ascending order\n",
        "    #all_cats_with_pvs[loc] = OrderedDict(ordered_categories_with_pageviews)\n",
        "    all_cats_with_pvs[subject] = OrderedDict(ordered_categories_with_pageviews)\n",
        "  return all_cats_with_pvs\n",
        "\n",
        "def sorting_dict(sor_dict):\n",
        "  ret = {}\n",
        "  #sorting the dict after pageviews\n",
        "  for loc, value in sor_dict.items():\n",
        "    try:\n",
        "      sorted_dict = OrderedDict(sorted(value.items(), key=lambda x: x[1][2], reverse=True))\n",
        "    except Exception as e:\n",
        "      print(f\"Sorting failed for location {loc}: {e}\")\n",
        "      sorted_dict = value\n",
        "    ret[loc] = sorted_dict\n",
        "    #sorted_dict = dict(sorted(value.items(), key=lambda x: x[2], reverse=True))\n",
        "  return ret\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "# function that takes a dictionary with an ordered dictionary as the value and prunes the ordered dictionary to keep only the first n entries:\n",
        "def prune_ordered_dict(dictionary, n):\n",
        "    pruned_dict = OrderedDict()\n",
        "    for key, value in dictionary.items():\n",
        "        pruned_dict[key] = OrderedDict(list(value.items())[:n])\n",
        "    return pruned_dict\n",
        "\n",
        "\n",
        "# function that takes a dictionary with an ordered dictionary as the value and prunes the ordered dictionary to keep only the first n entries and deltes certain categories:\n",
        "def prune_and_ordered_dict(dictionary, n):\n",
        "  pruned_dict = OrderedDict()\n",
        "  inter1_dict= OrderedDict()\n",
        "  for key, value in dictionary.items():\n",
        "    inter3_dict= OrderedDict()\n",
        "    for link, tuplee in value.items():\n",
        "      link_str = str(link)\n",
        "      if 'Living_people' not in link_str and '_births' not in link_str and '_deaths' not in link_str: \n",
        "        inter3_dict[link] = tuplee\n",
        "    pruned_dict[key] = inter3_dict\n",
        "\n",
        "  for key, value in pruned_dict.items():\n",
        "    inter1_dict[key] = OrderedDict(list(value.items())[:n])\n",
        "  return inter1_dict\n"
      ],
      "metadata": {
        "id": "XfUS-hxe3mPX"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the 20 most appearing categories \n",
        "def find_most_common_links(data_dict):\n",
        "    link_count = {}\n",
        "    for key, value in data_dict.items():\n",
        "        for link in value:\n",
        "            if link not in link_count:\n",
        "                link_count[link] = {\"count\": 1, \"keys\": [key]}\n",
        "            else:\n",
        "                link_count[link][\"count\"] += 1\n",
        "                link_count[link][\"keys\"].append(key)\n",
        "\n",
        "    # Sort the links by their count in descending order\n",
        "    sorted_links = sorted(link_count.items(), key=lambda x: x[1][\"count\"], reverse=True)\n",
        "\n",
        "    # Return a list of tuples with the link, count, and keys\n",
        "    return [(link, data[\"count\"], data[\"keys\"]) for link, data in sorted_links[:20]]\n",
        "\n"
      ],
      "metadata": {
        "id": "0G3miACErdVS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test it!"
      ],
      "metadata": {
        "id": "NAAni7kJb4Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for locations\n",
        "\n",
        "location_questions_dict = dict(zip(location_df['Answer'], location_df['Question']))\n",
        "cat_with_pv_location = {}\n",
        "\n",
        "#for locations\n",
        "cat_ranking_location = get_categories(location_questions_dict)\n",
        "#pprint.pprint(cat_ranking_location, indent=1)\n",
        "cat_with_pv_location = get_pageviews_for_categories(cat_ranking_location)\n",
        "#pprint.pprint(cat_with_pv_location, indent=1)\n",
        "#for locations: sorting the dict after pages per category\n",
        "categories_with_subs_and_pageviews_location = get_dict_for_every_location(cat_ranking_location, cat_with_pv_location)\n",
        "#pprint.pprint(categories_with_subs_and_pageviews_location,indent=1)\n",
        "new_ordered_dict_location = sorting_dict(categories_with_subs_and_pageviews_location)\n",
        "#pprint.pprint(new_ordered_dict_location,indent=1)\n",
        "\n",
        "#for 3 locations 1m33s"
      ],
      "metadata": {
        "id": "sJ7C8z2j_Qqi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for person\n",
        "person_questions_dict = dict(zip(person_df['Answer'], person_df['Question']))\n",
        "cat_with_pv_person = {}\n",
        "\n",
        "#for person\n",
        "cat_ranking_person = get_categories(person_questions_dict)\n",
        "#pprint.pprint(cat_ranking_person, indent=1)\n",
        "cat_with_pv_person = get_pageviews_for_categories(cat_ranking_person)\n",
        "#pprint.pprint(cat_with_pv_person, indent=1)\n",
        "#for person: sorting the dict after pages per category\n",
        "categories_with_subs_and_pageviews_person = get_dict_for_every_location(cat_ranking_person, cat_with_pv_person)\n",
        "#pprint.pprint(categories_with_subs_and_pageviews_person,indent=1)\n",
        "new_ordered_dict_person = sorting_dict(categories_with_subs_and_pageviews_person)\n",
        "#pprint.pprint(new_ordered_dict_person,indent=1)\n",
        "\n",
        "#for 3 people 17m22s\n",
        "#27s\n",
        "# for 20 F1 drivers -> 20mins"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1_R-UOV1ZYl",
        "outputId": "75465d32-a879-4369-bc25-f56bcb8b95b7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorting failed for location Max Verstappen: tuple index out of range\n",
            "Sorting failed for location Michael Jackson: tuple index out of range\n",
            "Sorting failed for location Joe Biden: tuple index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print it!"
      ],
      "metadata": {
        "id": "-q_xTwdBHXTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#just for easy printing such that you dont have to0 calculate everything everytime\n",
        "copy_categories_with_subs_and_pageviews_location = categories_with_subs_and_pageviews_location\n",
        "copy_new_ordered_dict_location = new_ordered_dict_location\n",
        "#print(\"Ordered after the number of pages per category:\")\n",
        "#pprint.pprint(copy_categories_with_subs_and_pageviews_location,indent=1)\n",
        "print(\"Ordered after the number of pageviews per category:\")\n",
        "pprint.pprint(copy_new_ordered_dict_location,indent=1, compact=True)\n",
        "\n",
        "copy_categories_with_subs_and_pageviews_person = categories_with_subs_and_pageviews_person\n",
        "copy_new_ordered_dict_person = new_ordered_dict_person\n",
        "#print(\"Ordered after the number of pages per category:\")\n",
        "#pprint.pprint(copy_categories_with_subs_and_pageviews_person,indent=1)\n",
        "print(\"Ordered after the number of pageviews per category:\")\n",
        "#prune the dict down to 20 most visited categories per person\n",
        "#copy_new_ordered_dict_person = prune_ordered_dict(copy_new_ordered_dict_person, 20)\n",
        "#first delete categories like (livingpeople, deaths, births) and prune the dict down to 20 most visited categories per person\n",
        "copy_new_ordered_dict_person_test = prune_and_ordered_dict(copy_new_ordered_dict_person, 20)\n",
        "copy_new_ordered_dict_person = sorting_dict(copy_new_ordered_dict_person_test)\n",
        "pprint.pprint(copy_new_ordered_dict_person,indent=1, compact=True)\n",
        "\n",
        "#8.30 for 10 drivers\n",
        "category_occurences = find_most_common_links(copy_new_ordered_dict_person)\n",
        "print('These are the categories that occur most between the person-entities:')\n",
        "pprint.pprint(category_occurences, indent=1, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJj4vnEC6TKK",
        "outputId": "e6111116-7285-4435-f8c2-557f5e62d75e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ordered after the number of pageviews per category:\n",
            "{}\n",
            "Ordered after the number of pageviews per category:\n",
            "NEW ORDERED DICT \n",
            "\n",
            "OrderedDict([('Max Verstappen', OrderedDict([('https://en.wikipedia.org/wiki/Category:Belgian_racing_drivers', (100, 0, 1271)), ('https://en.wikipedia.org/wiki/Category:Dutch_racing_drivers', (100, 0, 1714)), ('https://en.wikipedia.org/wiki/Category:FIA_Formula_3_European_Championship_drivers', (100, 0, 163)), ('https://en.wikipedia.org/wiki/Category:Formula_One_race_winners', (100, 0, 1111)), ('https://en.wikipedia.org/wiki/Category:Karting_World_Championship_drivers', (100, 0, 808)), ('https://en.wikipedia.org/wiki/Category:Motopark_Academy_drivers', (100, 0, 140)), ('https://en.wikipedia.org/wiki/Category:Officers_of_the_Order_of_Orange-Nassau', (100, 0, 3055)), ('https://en.wikipedia.org/wiki/Category:Twitch_(service)_streamers', (100, 0, 14054)), ('https://en.wikipedia.org/wiki/Category:Van_Amersfoort_Racing_drivers', (97, 0, 119)), ('https://en.wikipedia.org/wiki/Category:Sportspeople_from_Hasselt', (64, 0, 66)), (\"https://en.wikipedia.org/wiki/Category:Formula_One_World_Drivers'_Champions\", (35, 0, 950)), ('https://en.wikipedia.org/wiki/Category:Dutch_Formula_One_drivers', (20, 0, 1715)), ('https://en.wikipedia.org/wiki/Category:Dutch_people_of_Belgian_descent', (18, 0, 255)), ('https://en.wikipedia.org/wiki/Category:Belgian_people_of_Dutch_descent', (15, 0, 220)), ('https://en.wikipedia.org/wiki/Category:Toro_Rosso_Formula_One_drivers', (14, 0, 244)), ('https://en.wikipedia.org/wiki/Category:Red_Bull_Formula_One_drivers', (12, 0, 1012)), ('https://en.wikipedia.org/wiki/Category:Belgian_expatriates_in_Monaco', (10, 0, 197)), ('https://en.wikipedia.org/wiki/Category:Dutch_expatriate_sportspeople_in_Monaco', (8, 0, 48)), ('https://en.wikipedia.org/wiki/Category:Max_Verstappen', (2, 0))])), ('Michael Jackson', OrderedDict([('https://en.wikipedia.org/wiki/Category:20th-century_American_businesspeople', (100, 0, 7750)), ('https://en.wikipedia.org/wiki/Category:20th-century_American_singers', (100, 0, 9318)), ('https://en.wikipedia.org/wiki/Category:21st-century_American_businesspeople', (100, 0, 6818)), ('https://en.wikipedia.org/wiki/Category:21st-century_American_singers', (100, 0, 12476)), ('https://en.wikipedia.org/wiki/Category:African-American_businesspeople', (100, 0, 1909)), ('https://en.wikipedia.org/wiki/Category:African-American_male_dancers', (100, 0, 1870)), ('https://en.wikipedia.org/wiki/Category:African-American_male_singers', (100, 0, 20314)), ('https://en.wikipedia.org/wiki/Category:African-American_record_producers', (100, 0, 1656)), ('https://en.wikipedia.org/wiki/Category:African-American_songwriters', (100, 0, 1739)), ('https://en.wikipedia.org/wiki/Category:American_child_singers', (100, 0, 11895)), ('https://en.wikipedia.org/wiki/Category:American_choreographers', (100, 0, 1721)), ('https://en.wikipedia.org/wiki/Category:American_dance_musicians', (100, 0, 1689)), ('https://en.wikipedia.org/wiki/Category:American_funk_singers', (100, 0, 676)), ('https://en.wikipedia.org/wiki/Category:American_humanitarians', (100, 0, 1966)), ('https://en.wikipedia.org/wiki/Category:American_male_dancers', (100, 0, 2787)), ('https://en.wikipedia.org/wiki/Category:American_male_pop_singers', (100, 0, 17599)), ('https://en.wikipedia.org/wiki/Category:American_male_singers', (100, 0, 30303)), ('https://en.wikipedia.org/wiki/Category:American_male_songwriters', (100, 0, 4813)), ('https://en.wikipedia.org/wiki/Category:American_multi-instrumentalists', (100, 0, 1754)), ('https://en.wikipedia.org/wiki/Category:American_philanthropists', (100, 0, 10318))])), ('Joe Biden', OrderedDict([('https://en.wikipedia.org/wiki/Category:20th-century_American_lawyers', (100, 0, 5755)), ('https://en.wikipedia.org/wiki/Category:20th-century_American_politicians', (100, 0, 8176)), ('https://en.wikipedia.org/wiki/Category:20th-century_Roman_Catholics', (100, 0, 1405)), ('https://en.wikipedia.org/wiki/Category:21st-century_American_memoirists', (100, 0, 769)), ('https://en.wikipedia.org/wiki/Category:21st-century_Roman_Catholics', (100, 0, 2832)), ('https://en.wikipedia.org/wiki/Category:American_Roman_Catholics', (100, 0, 14103)), ('https://en.wikipedia.org/wiki/Category:American_people_of_English_descent', (100, 0, 22035)), ('https://en.wikipedia.org/wiki/Category:American_people_of_French_descent', (100, 0, 7338)), ('https://en.wikipedia.org/wiki/Category:American_people_of_Irish_descent', (100, 0, 32705)), ('https://en.wikipedia.org/wiki/Category:Candidates_in_the_2020_United_States_presidential_election', (100, 0, 803)), ('https://en.wikipedia.org/wiki/Category:Catholics_from_Pennsylvania', (100, 0, 680)), ('https://en.wikipedia.org/wiki/Category:Delaware_lawyers', (100, 0, 214)), ('https://en.wikipedia.org/wiki/Category:People_appearing_on_C-SPAN', (100, 0, 4536)), ('https://en.wikipedia.org/wiki/Category:People_from_Wilmington,_Delaware', (100, 0, 452)), ('https://en.wikipedia.org/wiki/Category:People_involved_in_plagiarism_controversies', (100, 0, 2801)), ('https://en.wikipedia.org/wiki/Category:Presidential_Medal_of_Freedom_recipients', (100, 0, 10987)), ('https://en.wikipedia.org/wiki/Category:Presidents_of_the_United_States', (100, 0, 18140)), ('https://en.wikipedia.org/wiki/Category:Public_defenders', (100, 0, 1468)), ('https://en.wikipedia.org/wiki/Category:Recipients_of_the_Order_of_the_Cross_of_Terra_Mariana,_1st_Class', (100, 0, 405)), ('https://en.wikipedia.org/wiki/Category:Transgender_rights_activists', (100, 0, 4510))]))])\n",
            "Sorting failed for location Max Verstappen: tuple index out of range\n",
            "{'Joe Biden': OrderedDict([('https://en.wikipedia.org/wiki/Category:American_people_of_Irish_descent',\n",
            "                            (100, 0, 32705)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:American_people_of_English_descent',\n",
            "                            (100, 0, 22035)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Presidents_of_the_United_States',\n",
            "                            (100, 0, 18140)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:American_Roman_Catholics',\n",
            "                            (100, 0, 14103)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Presidential_Medal_of_Freedom_recipients',\n",
            "                            (100, 0, 10987)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:20th-century_American_politicians',\n",
            "                            (100, 0, 8176)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:American_people_of_French_descent',\n",
            "                            (100, 0, 7338)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:20th-century_American_lawyers',\n",
            "                            (100, 0, 5755)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:People_appearing_on_C-SPAN',\n",
            "                            (100, 0, 4536)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Transgender_rights_activists',\n",
            "                            (100, 0, 4510)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:21st-century_Roman_Catholics',\n",
            "                            (100, 0, 2832)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:People_involved_in_plagiarism_controversies',\n",
            "                            (100, 0, 2801)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Public_defenders',\n",
            "                            (100, 0, 1468)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:20th-century_Roman_Catholics',\n",
            "                            (100, 0, 1405)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Candidates_in_the_2020_United_States_presidential_election',\n",
            "                            (100, 0, 803)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:21st-century_American_memoirists',\n",
            "                            (100, 0, 769)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Catholics_from_Pennsylvania',\n",
            "                            (100, 0, 680)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:People_from_Wilmington,_Delaware',\n",
            "                            (100, 0, 452)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Recipients_of_the_Order_of_the_Cross_of_Terra_Mariana,_1st_Class',\n",
            "                            (100, 0, 405)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Delaware_lawyers',\n",
            "                            (100, 0, 214))]),\n",
            " 'Max Verstappen': OrderedDict([('https://en.wikipedia.org/wiki/Category:Belgian_racing_drivers',\n",
            "                                 (100, 0, 1271)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Dutch_racing_drivers',\n",
            "                                 (100, 0, 1714)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:FIA_Formula_3_European_Championship_drivers',\n",
            "                                 (100, 0, 163)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Formula_One_race_winners',\n",
            "                                 (100, 0, 1111)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Karting_World_Championship_drivers',\n",
            "                                 (100, 0, 808)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Motopark_Academy_drivers',\n",
            "                                 (100, 0, 140)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Officers_of_the_Order_of_Orange-Nassau',\n",
            "                                 (100, 0, 3055)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Twitch_(service)_streamers',\n",
            "                                 (100, 0, 14054)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Van_Amersfoort_Racing_drivers',\n",
            "                                 (97, 0, 119)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Sportspeople_from_Hasselt',\n",
            "                                 (64, 0, 66)),\n",
            "                                (\"https://en.wikipedia.org/wiki/Category:Formula_One_World_Drivers'_Champions\",\n",
            "                                 (35, 0, 950)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Dutch_Formula_One_drivers',\n",
            "                                 (20, 0, 1715)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Dutch_people_of_Belgian_descent',\n",
            "                                 (18, 0, 255)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Belgian_people_of_Dutch_descent',\n",
            "                                 (15, 0, 220)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Toro_Rosso_Formula_One_drivers',\n",
            "                                 (14, 0, 244)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Red_Bull_Formula_One_drivers',\n",
            "                                 (12, 0, 1012)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Belgian_expatriates_in_Monaco',\n",
            "                                 (10, 0, 197)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Dutch_expatriate_sportspeople_in_Monaco',\n",
            "                                 (8, 0, 48)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Max_Verstappen',\n",
            "                                 (2, 0))]),\n",
            " 'Michael Jackson': OrderedDict([('https://en.wikipedia.org/wiki/Category:American_male_singers',\n",
            "                                  (100, 0, 30303)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_male_singers',\n",
            "                                  (100, 0, 20314)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_male_pop_singers',\n",
            "                                  (100, 0, 17599)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:21st-century_American_singers',\n",
            "                                  (100, 0, 12476)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_child_singers',\n",
            "                                  (100, 0, 11895)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_philanthropists',\n",
            "                                  (100, 0, 10318)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:20th-century_American_singers',\n",
            "                                  (100, 0, 9318)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:20th-century_American_businesspeople',\n",
            "                                  (100, 0, 7750)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:21st-century_American_businesspeople',\n",
            "                                  (100, 0, 6818)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_male_songwriters',\n",
            "                                  (100, 0, 4813)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_male_dancers',\n",
            "                                  (100, 0, 2787)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_humanitarians',\n",
            "                                  (100, 0, 1966)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_businesspeople',\n",
            "                                  (100, 0, 1909)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_male_dancers',\n",
            "                                  (100, 0, 1870)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_multi-instrumentalists',\n",
            "                                  (100, 0, 1754)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_songwriters',\n",
            "                                  (100, 0, 1739)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_choreographers',\n",
            "                                  (100, 0, 1721)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_dance_musicians',\n",
            "                                  (100, 0, 1689)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_record_producers',\n",
            "                                  (100, 0, 1656)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_funk_singers',\n",
            "                                  (100, 0, 676))])}\n",
            "These are the categories that occur most between the person-entities:\n",
            "[('https://en.wikipedia.org/wiki/Category:Belgian_racing_drivers', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Dutch_racing_drivers', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:FIA_Formula_3_European_Championship_drivers',\n",
            "  1, ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Formula_One_race_winners', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Karting_World_Championship_drivers',\n",
            "  1, ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Motopark_Academy_drivers', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Officers_of_the_Order_of_Orange-Nassau',\n",
            "  1, ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Twitch_(service)_streamers', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Van_Amersfoort_Racing_drivers', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Sportspeople_from_Hasselt', 1,\n",
            "  ['Max Verstappen']),\n",
            " (\"https://en.wikipedia.org/wiki/Category:Formula_One_World_Drivers'_Champions\",\n",
            "  1, ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Dutch_Formula_One_drivers', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Dutch_people_of_Belgian_descent', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Belgian_people_of_Dutch_descent', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Toro_Rosso_Formula_One_drivers', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Red_Bull_Formula_One_drivers', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Belgian_expatriates_in_Monaco', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Dutch_expatriate_sportspeople_in_Monaco',\n",
            "  1, ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:Max_Verstappen', 1,\n",
            "  ['Max Verstappen']),\n",
            " ('https://en.wikipedia.org/wiki/Category:American_male_singers', 1,\n",
            "  ['Michael Jackson'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create the hints with the categories\n",
        "#at the moment the program is just working with person/location that have english wiki pages\n",
        "#create the actual hint-sentences\n",
        "\n",
        "print(\"Generated by the ordering of how many pages there are in a category:\")\n",
        "pprint.pprint(get_first_three_categs_location(copy_categories_with_subs_and_pageviews_location))\n",
        "print(\"Generated by the ordering of how many pageviews a category has:\")\n",
        "pprint.pprint(get_first_three_categs_location(new_ordered_dict_location))\n",
        "\n",
        "print(\"Generated by the ordering of how many pages there are in a category:\")\n",
        "pprint.pprint(get_first_three_categs_person(copy_categories_with_subs_and_pageviews_person))\n",
        "print(\"Generated by the ordering of how many pageviews a category has:\")\n",
        "pprint.pprint(get_first_three_categs_person(new_ordered_dict_person))"
      ],
      "metadata": {
        "id": "C8xR9xCvJwdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4e1d37-877d-4b1b-9659-c668c767cfaf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated by the ordering of how many pages there are in a category:\n",
            "{}\n",
            "Generated by the ordering of how many pageviews a category has:\n",
            "{}\n",
            "Generated by the ordering of how many pages there are in a category:\n",
            "{'Joe Biden': ['The person you are looking for, belongs to the category 1942 '\n",
            "               'births',\n",
            "               'The person you are looking for, belongs to the category '\n",
            "               '20th-century American lawyers',\n",
            "               'The person you are looking for, belongs to the category '\n",
            "               '20th-century American politicians'],\n",
            " 'Max Verstappen': ['The person you are looking for, belongs to the category '\n",
            "                    '1997 births',\n",
            "                    'The person you are looking for, belongs to the category '\n",
            "                    'Belgian racing drivers',\n",
            "                    'The person you are looking for, belongs to the category '\n",
            "                    'Dutch racing drivers'],\n",
            " 'Michael Jackson': ['The person you are looking for, belongs to the category '\n",
            "                     '1958 births',\n",
            "                     'The person you are looking for, belongs to the category '\n",
            "                     '2009 deaths',\n",
            "                     'The person you are looking for, belongs to the category '\n",
            "                     '20th-century American businesspeople']}\n",
            "Generated by the ordering of how many pageviews a category has:\n",
            "{'Joe Biden': ['The person you are looking for, belongs to the category 1942 '\n",
            "               'births',\n",
            "               'The person you are looking for, belongs to the category '\n",
            "               '20th-century American lawyers',\n",
            "               'The person you are looking for, belongs to the category '\n",
            "               '20th-century American politicians'],\n",
            " 'Max Verstappen': ['The person you are looking for, belongs to the category '\n",
            "                    '1997 births',\n",
            "                    'The person you are looking for, belongs to the category '\n",
            "                    'Belgian racing drivers',\n",
            "                    'The person you are looking for, belongs to the category '\n",
            "                    'Dutch racing drivers'],\n",
            " 'Michael Jackson': ['The person you are looking for, belongs to the category '\n",
            "                     '1958 births',\n",
            "                     'The person you are looking for, belongs to the category '\n",
            "                     '2009 deaths',\n",
            "                     'The person you are looking for, belongs to the category '\n",
            "                     '20th-century American businesspeople']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing/Calculating unexpectedness via categories"
      ],
      "metadata": {
        "id": "kr_qll0aSaCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import requests\n",
        "\n",
        "template_sentence_location = 'The location you are looking for, is a member of the category x'\n",
        "template_sentence_location2 = 'The location you are looking for, belongs to the category '\n",
        "\n",
        "template_sentence_person = 'The person you are looking for, is a member of the category x'\n",
        "template_sentence_person2 = 'The person you are looking for, belongs to the category '\n",
        "\n",
        "#retrives the category name from the link\n",
        "def get_category_name(link):\n",
        "    category_prefix = \"Category:\"\n",
        "    if link.startswith(\"https://wikipedia.org/wiki/\"):\n",
        "        return link[len(\"https://wikipedia.org/wiki/\" + category_prefix):].replace(\"_\", \" \")\n",
        "    else:\n",
        "      if link.startswith(\"https://en.wikipedia.org/wiki/\"):\n",
        "        return link[len(\"https://en.wikipedia.org/wiki/\" + category_prefix):].replace(\"_\", \" \")\n",
        "      else:\n",
        "        return None\n",
        "        \n",
        "#just get the first 3 categories without any special formula\n",
        "def get_first_three_categs_location(copy_categories_with_subs_and_pageviews_location):\n",
        "  first_three_categories_per_location = {}\n",
        "  for key, value in copy_categories_with_subs_and_pageviews_location.items():\n",
        "    first_three = dict(itertools.islice(value.items(), 3))\n",
        "    first_three_categories_per_location[key] = first_three\n",
        "\n",
        "  hint_sentence_location = {}\n",
        "  for key, value in first_three_categories_per_location.items():\n",
        "    inter_hints = []\n",
        "    for link, tup in value.items():\n",
        "      cat_name=get_category_name(link)\n",
        "      if cat_name is not None:\n",
        "        ok = template_sentence_location2 + cat_name\n",
        "      else: \n",
        "        ok = template_sentence_location2\n",
        "      inter_hints.append(ok)\n",
        "    hint_sentence_location[key] = inter_hints\n",
        "  return hint_sentence_location\n",
        "\n",
        "#just get the first 3 categories without any special formula\n",
        "def get_first_three_categs_person(copy_categories_with_subs_and_pageviews_location):\n",
        "  first_three_categories_per_location = {}\n",
        "  for key, value in copy_categories_with_subs_and_pageviews_location.items():\n",
        "    first_three = dict(itertools.islice(value.items(), 3))\n",
        "    first_three_categories_per_location[key] = first_three\n",
        "\n",
        "  hint_sentence_location = {}\n",
        "  for key, value in first_three_categories_per_location.items():\n",
        "    inter_hints = []\n",
        "    for link, tup in value.items():\n",
        "      cat_name=get_category_name(link)\n",
        "      if cat_name is not None:\n",
        "        ok = template_sentence_person2 + cat_name\n",
        "      else: \n",
        "        ok = template_sentence_person2\n",
        "      inter_hints.append(ok)\n",
        "    hint_sentence_location[key] = inter_hints\n",
        "  return hint_sentence_location\n",
        "\n",
        "#get predicates of a wiki page via wikidataAPI\n",
        "def get_wikidata_predicates(page_title):\n",
        "    # First, get the Wikidata item ID of the page\n",
        "    url = f\"https://en.wikipedia.org/w/api.php?action=query&prop=pageprops&ppprop=wikibase_item&redirects=1&titles={page_title}&format=json\"\n",
        "    response = requests.get(url).json()\n",
        "    pages = response[\"query\"][\"pages\"]\n",
        "    if \"-1\" in pages:\n",
        "        return None\n",
        "    page_id = next(iter(pages))\n",
        "    wikidata_id = pages[page_id][\"pageprops\"][\"wikibase_item\"]\n",
        "\n",
        "    # Then, get the predicates and their values of the Wikidata item\n",
        "    url = f\"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={wikidata_id}&format=json&props=claims\"\n",
        "    response = requests.get(url).json()\n",
        "    entity = response[\"entities\"][wikidata_id]\n",
        "    predicates = {}\n",
        "    for claim_id, claim in entity[\"claims\"].items():\n",
        "        predicate_id = claim[\"mainsnak\"][\"property\"]\n",
        "        predicate_value = claim[\"mainsnak\"][\"datavalue\"][\"value\"]\n",
        "        predicates[predicate_id] = predicate_value\n",
        "    return predicates\n",
        "\n",
        "#\n",
        "#TEST\n",
        "#\n",
        "\n",
        "people_list=[]\n",
        "for l in dataPerson:\n",
        "  people_list.append(l[1])\n",
        "\n",
        "# takes a list of all the people and the list of category occurences where all the categories that were assigned to these wiki-pages \n",
        "# are listed and ranked after how often they occur; \n",
        "# output: a list where the person is the key and the entries show wich categories the entity shares with wich other entitities and how many they are\n",
        "def get_people_dict(people_list, occurences_list):\n",
        "    people_dict = {}\n",
        "    for person in people_list:\n",
        "        person_categories = []\n",
        "        for occurence in occurences_list:\n",
        "            if person in occurence[2]:\n",
        "                person_categories.append((occurence[0], occurence[1], occurence[2]))\n",
        "        people_dict[person] = person_categories\n",
        "    return people_dict\n",
        "\n",
        "#returns a dict where for each person in people_list we calculate how often they occur in the same category as the keys in person_dict \n",
        "# (where already for each person we looked at each of the categories he appears and counted how many other people from people_list appear in these )\n",
        "def count_people_occurrences(person_dict, people_list):\n",
        "  # Initialize an empty dictionary to hold the counts  \n",
        "  count_dict = {}\n",
        "  # Loop through all pairs of drivers and count the number of occurrences\n",
        "  for key, value in person_dict.items():\n",
        "    counter = {}\n",
        "    for person in people_list:\n",
        "      counter[person] = 0\n",
        "      for cat in value:\n",
        "        if person in cat[2]:\n",
        "          counter[person] += 1  \n",
        "    count_dict[key] = counter\n",
        "  return count_dict\n",
        "\n",
        "#sorting\n",
        "def sort_dict_by_value_desc(d):\n",
        "    # Sort the inner dictionary by value in descending order\n",
        "    sorted_dict = OrderedDict(sorted(d.items(), key=lambda x: x[1], reverse=True))\n",
        "    return sorted_dict\n",
        "\n",
        "def get_categories_union(overlap_dict, people_list):\n",
        "  # Initialize an empty dictionary to hold the counts  \n",
        "  count_dict = {}\n",
        "  for key, value in overlap_dict.items():\n",
        "    counter = {}\n",
        "    for item, number in value.items():\n",
        "      #print(number)\n",
        "      counter[item] = number_categories_per_person[key] + number_categories_per_person[item] - number\n",
        "    count_dict[key] = counter\n",
        "  return count_dict\n",
        "\n",
        "def get_avg_pairwise_sim(cat_div_union, cat_div_overlap, number_categories_per_person, people_list):\n",
        "  count_dict = {}\n",
        "  for key, value in cat_div_union.items():\n",
        "    inter = {}\n",
        "    for key1, value1 in cat_div_overlap.items():\n",
        "      if key == key1:\n",
        "        for name, number in value.items():\n",
        "          for name1, number1 in value1.items():\n",
        "            if name == name1:\n",
        "              if not number  or not number1:\n",
        "                inter[name] = 0\n",
        "              else:\n",
        "                inter[name] = (number1 / number)\n",
        "    count_dict[key] = inter\n",
        "  return count_dict\n",
        "\n",
        "def get_cat_diversity(shared_categories, copy_new_ordered_dict_person):\n",
        "  count_dict = {}\n",
        "  for key, value in copy_new_ordered_dict_person.items():\n",
        "    for item in value.items():\n",
        "      pv = 0\n",
        "      #print(item)\n",
        "      link = item[0]\n",
        "      trip = item[1]\n",
        "      if len(trip) == 3:\n",
        "        pv = trip[2]\n",
        "      if link not in count_dict:\n",
        "        count_dict[link] = pv\n",
        "  return count_dict"
      ],
      "metadata": {
        "id": "DVtrfLWuQZgi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create scores and metric to determine the best hint\n",
        "\n",
        "#The unexpectedness approach I am taking at the moment is:\n",
        "#1. Look up the occupation of the person-answer-entity\n",
        "#2. Search for 3-5 similar/comparable people from the same occupation (direction)\n",
        "#3, Gather the 20 most popular categories from all entities (rank them)\n",
        "#4. Try to find a popular category (piece of information) that is untypical for most people from this occupation or field-of-work\n",
        "\n",
        "#category diversity = avg pairwise-similarity of members (=Jaccard similarity coefficient = IoU)\n",
        "#IoU = intersection over union = (#shared categories of A and B) / (#categories of A + #categories of B)\n",
        "\n",
        "\n",
        "#wich drivers shares what category with wich other driver\n",
        "shared_categories = get_people_dict(people_list, category_occurences)\n",
        "pprint.pprint(shared_categories, indent=1, compact=True)\n",
        "\n",
        "print(\"People dict with the number of how many categories they appear in:\")\n",
        "number_categories_per_person = {}\n",
        "for key, value in copy_new_ordered_dict_person.items():\n",
        "    number_categories_per_person[key] = len(value)\n",
        "#pprint.pprint(number_categories_per_person, indent=1, compact=True)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Category overlap: how many categories in A AND B together\")\n",
        "unsorted_category_diversity = count_people_occurrences(shared_categories, people_list)\n",
        "cat_div_overlap = {k: sort_dict_by_value_desc(v) for k, v in unsorted_category_diversity.items()}\n",
        "#pprint.pprint(cat_div_overlap, indent=1, compact=True)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Category union: how many categories in A OR B\")\n",
        "unsorted_cat_div_union = get_categories_union(cat_div_overlap, people_list)\n",
        "cat_div_union = {k: sort_dict_by_value_desc(v) for k, v in unsorted_cat_div_union.items()}\n",
        "#pprint.pprint(cat_div_union, indent=1, compact=True)\n",
        "print(\"\\n\")\n",
        "\n",
        "#avg pairwise-similarity of each person to each other person in people_list\n",
        "print(\"Cat_diversity = avg_pairwise_similarity = IoU\")\n",
        "unordered_avg_pairwise_sim = get_avg_pairwise_sim(cat_div_union, cat_div_overlap, number_categories_per_person, people_list)\n",
        "avg_pairwise_sim = {k: sort_dict_by_value_desc(v) for k, v in unordered_avg_pairwise_sim.items()}\n",
        "pprint.pprint(avg_pairwise_sim, indent=1, compact=True)\n",
        "\n",
        "\n",
        "#avg pairwise-similarity of each ossuring category in the wiki pages of the people\n",
        "# cat_popularity = avg view count of categories that appear in the persons wiki pages ordered descending after the highest\n",
        "print(\"Cat_popularity = avg view count of category\")\n",
        "unordered_cat_popularity= get_cat_diversity(category_occurences, copy_new_ordered_dict_person)\n",
        "cat_popularity = OrderedDict(sorted(unordered_cat_popularity.items(), key=lambda x: x[1], reverse=True))\n",
        "pprint.pprint(cat_popularity, indent=1, compact=True)\n",
        "\n",
        "#1. write a function that finds similar entities to our searched entity (3-5 comparable entities)\n",
        "#2. compare those via avg pairwise to \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjdNT2Hn5RPW",
        "outputId": "823bbd2e-8859-4a93-cc88-45921d125f2f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Joe Biden': [('https://en.wikipedia.org/wiki/Category:Living_people', 2,\n",
            "                ['Max Verstappen', 'Joe Biden'])],\n",
            " 'Max Verstappen': [('https://en.wikipedia.org/wiki/Category:Living_people', 2,\n",
            "                     ['Max Verstappen', 'Joe Biden']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:1997_births', 1,\n",
            "                     ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Twitch_(service)_streamers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Officers_of_the_Order_of_Orange-Nassau',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Dutch_Formula_One_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Dutch_racing_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Belgian_racing_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Formula_One_race_winners',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Red_Bull_Formula_One_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    (\"https://en.wikipedia.org/wiki/Category:Formula_One_World_Drivers'_Champions\",\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Karting_World_Championship_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Dutch_people_of_Belgian_descent',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Toro_Rosso_Formula_One_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Belgian_people_of_Dutch_descent',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Belgian_expatriates_in_Monaco',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:FIA_Formula_3_European_Championship_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Motopark_Academy_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Van_Amersfoort_Racing_drivers',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Sportspeople_from_Hasselt',\n",
            "                     1, ['Max Verstappen']),\n",
            "                    ('https://en.wikipedia.org/wiki/Category:Dutch_expatriate_sportspeople_in_Monaco',\n",
            "                     1, ['Max Verstappen'])],\n",
            " 'Michael Jackson': []}\n",
            "People dict with the number of how many categories they appear in:\n",
            "\n",
            "\n",
            "Category overlap: how many categories in A AND B together\n",
            "\n",
            "\n",
            "Category union: how many categories in A OR B\n",
            "\n",
            "\n",
            "Cat_diversity = avg_pairwise_similarity = IoU\n",
            "{'Joe Biden': OrderedDict([('Max Verstappen', 0.02564102564102564),\n",
            "                           ('Joe Biden', 0.02564102564102564),\n",
            "                           ('Michael Jackson', 0)]),\n",
            " 'Max Verstappen': OrderedDict([('Max Verstappen', 1.0),\n",
            "                                ('Joe Biden', 0.02564102564102564),\n",
            "                                ('Michael Jackson', 0)]),\n",
            " 'Michael Jackson': OrderedDict([('Max Verstappen', 0), ('Michael Jackson', 0),\n",
            "                                 ('Joe Biden', 0)])}\n",
            "Cat_popularity = avg view count of category\n",
            "OrderedDict([('https://en.wikipedia.org/wiki/Category:Living_people', 509392),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_people_of_Irish_descent',\n",
            "              32705),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_male_singers',\n",
            "              30303),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_people_of_English_descent',\n",
            "              22035),\n",
            "             ('https://en.wikipedia.org/wiki/Category:1997_births', 21263),\n",
            "             ('https://en.wikipedia.org/wiki/Category:1958_births', 20968),\n",
            "             ('https://en.wikipedia.org/wiki/Category:African-American_male_singers',\n",
            "              20314),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Presidents_of_the_United_States',\n",
            "              18140),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_male_pop_singers',\n",
            "              17599),\n",
            "             ('https://en.wikipedia.org/wiki/Category:1942_births', 16155),\n",
            "             ('https://en.wikipedia.org/wiki/Category:2009_deaths', 14797),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_Roman_Catholics',\n",
            "              14103),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Twitch_(service)_streamers',\n",
            "              14054),\n",
            "             ('https://en.wikipedia.org/wiki/Category:21st-century_American_singers',\n",
            "              12476),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_child_singers',\n",
            "              11895),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Presidential_Medal_of_Freedom_recipients',\n",
            "              10987),\n",
            "             ('https://en.wikipedia.org/wiki/Category:20th-century_American_singers',\n",
            "              9318),\n",
            "             ('https://en.wikipedia.org/wiki/Category:20th-century_American_politicians',\n",
            "              8176),\n",
            "             ('https://en.wikipedia.org/wiki/Category:20th-century_American_businesspeople',\n",
            "              7750),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_people_of_French_descent',\n",
            "              7338),\n",
            "             ('https://en.wikipedia.org/wiki/Category:21st-century_American_businesspeople',\n",
            "              6818),\n",
            "             ('https://en.wikipedia.org/wiki/Category:20th-century_American_lawyers',\n",
            "              5755),\n",
            "             ('https://en.wikipedia.org/wiki/Category:People_appearing_on_C-SPAN',\n",
            "              4536),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Accidental_deaths_in_California',\n",
            "              4250),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Officers_of_the_Order_of_Orange-Nassau',\n",
            "              3055),\n",
            "             ('https://en.wikipedia.org/wiki/Category:21st-century_Roman_Catholics',\n",
            "              2832),\n",
            "             ('https://en.wikipedia.org/wiki/Category:People_involved_in_plagiarism_controversies',\n",
            "              2801),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_male_dancers',\n",
            "              2787),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_humanitarians',\n",
            "              1966),\n",
            "             ('https://en.wikipedia.org/wiki/Category:African-American_businesspeople',\n",
            "              1909),\n",
            "             ('https://en.wikipedia.org/wiki/Category:African-American_male_dancers',\n",
            "              1870),\n",
            "             ('https://en.wikipedia.org/wiki/Category:African-American_songwriters',\n",
            "              1739),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_choreographers',\n",
            "              1721),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Dutch_Formula_One_drivers',\n",
            "              1715),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Dutch_racing_drivers',\n",
            "              1714),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_dance_musicians',\n",
            "              1689),\n",
            "             ('https://en.wikipedia.org/wiki/Category:African-American_record_producers',\n",
            "              1656),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Public_defenders', 1468),\n",
            "             ('https://en.wikipedia.org/wiki/Category:20th-century_Roman_Catholics',\n",
            "              1405),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Belgian_racing_drivers',\n",
            "              1271),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Formula_One_race_winners',\n",
            "              1111),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Red_Bull_Formula_One_drivers',\n",
            "              1012),\n",
            "             (\"https://en.wikipedia.org/wiki/Category:Formula_One_World_Drivers'_Champions\",\n",
            "              950),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Karting_World_Championship_drivers',\n",
            "              808),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Candidates_in_the_2020_United_States_presidential_election',\n",
            "              803),\n",
            "             ('https://en.wikipedia.org/wiki/Category:21st-century_American_memoirists',\n",
            "              769),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Catholics_from_Pennsylvania',\n",
            "              680),\n",
            "             ('https://en.wikipedia.org/wiki/Category:American_funk_singers',\n",
            "              676),\n",
            "             ('https://en.wikipedia.org/wiki/Category:People_from_Wilmington,_Delaware',\n",
            "              452),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Dutch_people_of_Belgian_descent',\n",
            "              255),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Toro_Rosso_Formula_One_drivers',\n",
            "              244),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Belgian_people_of_Dutch_descent',\n",
            "              220),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Delaware_lawyers', 214),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Belgian_expatriates_in_Monaco',\n",
            "              197),\n",
            "             ('https://en.wikipedia.org/wiki/Category:FIA_Formula_3_European_Championship_drivers',\n",
            "              163),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Motopark_Academy_drivers',\n",
            "              140),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Van_Amersfoort_Racing_drivers',\n",
            "              119),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Sportspeople_from_Hasselt',\n",
            "              66),\n",
            "             ('https://en.wikipedia.org/wiki/Category:Dutch_expatriate_sportspeople_in_Monaco',\n",
            "              48)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categories_with_ranking():\n",
        "  #for person\n",
        "  person_questions_dict = dict(zip(person_df['Answer'], person_df['Question']))\n",
        "  cat_with_pv_person = {}\n",
        "\n",
        "  #for person\n",
        "  cat_ranking_person = get_categories(person_questions_dict)\n",
        "  #pprint.pprint(cat_ranking_person, indent=1)\n",
        "  cat_with_pv_person = get_pageviews_for_categories(cat_ranking_person)\n",
        "  #pprint.pprint(cat_with_pv_person, indent=1)\n",
        "  #for person: sorting the dict after pages per category\n",
        "  categories_with_subs_and_pageviews_person = get_dict_for_every_location(cat_ranking_person, cat_with_pv_person)\n",
        "  #pprint.pprint(categories_with_subs_and_pageviews_person,indent=1)\n",
        "  new_ordered_dict_person = sorting_dict(categories_with_subs_and_pageviews_person)\n",
        "  #pprint.pprint(new_ordered_dict_person,indent=1)\n",
        "\n",
        "  return new_ordered_dict_person\n",
        "\n",
        "all_people_cat_ranked = get_categories_with_ranking() #copy_new_ordered_dict_person"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIiJDuAJmnSf",
        "outputId": "1594f740-b0d7-43bd-e779-ec7c2ca2a42f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorting failed for location Max Verstappen: tuple index out of range\n",
            "Sorting failed for location Michael Jackson: tuple index out of range\n",
            "Sorting failed for location Joe Biden: tuple index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import wikipediaapi\n",
        "import requests\n",
        "\n",
        "#given a name, retrieve the infomration in the short-description part of the wiki page\n",
        "def get_page_short_description(page_title):\n",
        "    # Prepare the API request URL\n",
        "    url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{page_title.replace(' ', '_')}\"\n",
        "\n",
        "    # Send the API request\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extract the short description from the API response\n",
        "    short_description = data.get('description', '')\n",
        "\n",
        "    return short_description\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import OrderedDict\n",
        "\n",
        "def find_most_similar_category(persons, specific_category, num_similar_categories=3):\n",
        "    most_similar_categories = {}\n",
        "\n",
        "    for person, categories in persons.items():\n",
        "        category_texts = [category_link.split('/')[-1].replace('_', ' ') for category_link in categories.keys()]\n",
        "        category_texts.append(specific_category[person])  # Add the specific category for comparison\n",
        "\n",
        "        # Vectorize the category texts\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(category_texts)\n",
        "        #print(category_texts)\n",
        "        # Calculate cosine similarity between the specific category and other categories\n",
        "        similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]\n",
        "         # Calculate cosine similarity between the specific category and other categories\n",
        "        similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]\n",
        "        # Find the most similar categories textually\n",
        "        similar_indices = similarities.argsort()[-num_similar_categories:][::-1]\n",
        "        similar_categories = [category_texts[index] for index in similar_indices]\n",
        "        most_similar_categories[person] = similar_categories\n",
        "    return most_similar_categories\n",
        "\n",
        "\n",
        "def get_work_category(similar_categories):\n",
        "  person_with_work_categories = {}\n",
        "  person_with_work_category = {}\n",
        "  strings_to_check = [\"births\", \"deaths\"]\n",
        "  for person, categories in similar_categories.items():\n",
        "    for strs in strings_to_check:\n",
        "      for cats in categories:\n",
        "        #print(person , strs)\n",
        "        if strs in cats:\n",
        "          #print(cats)\n",
        "          categories.remove(cats)\n",
        "        else:\n",
        "          continue\n",
        "      person_with_work_categories[person] = categories\n",
        "  for person, categories in person_with_work_categories.items():\n",
        "    person_with_work_category[person] = categories[0]\n",
        "  return person_with_work_category\n",
        "\n",
        "\n",
        "\n",
        "def get_container_categories(work_cats):\n",
        "  for person, categories in work_cats.items():\n",
        "    wiki_category = categories\n",
        "    base_url = 'https://en.wikipedia.org/w/api.php'\n",
        "    params = {\n",
        "        'action': 'query',\n",
        "        'titles': wiki_category,\n",
        "        'prop': 'categories',\n",
        "        'format': 'json',\n",
        "        'cllimit': 'max'\n",
        "    }\n",
        "    response = requests.get(base_url, params=params)\n",
        "    data = response.json()\n",
        "    page_id = next(iter(data['query']['pages'].keys()))\n",
        "    categories = data['query']['pages'][page_id].get('categories', [])\n",
        "    container_categories = []\n",
        "    for category in categories:\n",
        "        if category['title'].startswith('Category:'):\n",
        "            container_categories.append(category['title'][9:])\n",
        "\n",
        "    strings_to_check = [\"CatAutoTOC \", \"Commons\", \"Template\"]\n",
        "    for strs in strings_to_check:\n",
        "      for cats in container_categories:\n",
        "        if strs in cats:\n",
        "          container_categories.remove(cats)\n",
        "        else:\n",
        "          continue\n",
        "    work_cats[person] = container_categories\n",
        "  return work_cats\n",
        "\n",
        "def replace_spaces_with_underscore(dictionary):\n",
        "    updated_dict = {}\n",
        "    for key, value in dictionary.items():\n",
        "        updated_dict[key] = value.replace(\" \", \"_\")\n",
        "    return updated_dict\n",
        "\n",
        "def format_category_dict(category_dict):\n",
        "    formatted_dict = {}\n",
        "    for key, value in category_dict.items():\n",
        "        if isinstance(value, list):\n",
        "            formatted_value = [f\"Category:{v.replace(' ', '_')}\" for v in value]\n",
        "        else:\n",
        "            formatted_value = f\"Category:{value.replace(' ', '_')}\"\n",
        "        formatted_dict[key] = formatted_value\n",
        "    return formatted_dict\n",
        "\n",
        "\n",
        "\n",
        "#dict that contains the person as key and the occupation as value\n",
        "person_with_job = {}\n",
        "for person in people_list:\n",
        "  person_with_job[person] = get_page_short_description(person) \n",
        "\n",
        "#this is a dict where the person name is the key and the value is the category of the work place\n",
        "#print(person_with_job)\n",
        "print(all_people_cat_ranked)\n",
        "\n",
        "#this is a dict where the person name is the key and a list of 3 most similar categories to the \"job-category\" of the person\n",
        "similar_categories = find_most_similar_category(all_people_cat_ranked, person_with_job)\n",
        "print(similar_categories)\n",
        "\n",
        "#return the work category of the person\n",
        "work_category = get_work_category(similar_categories)\n",
        "print(\"wk \" , work_category)\n",
        "\n",
        "#get the container category\n",
        "container_category_work = get_container_categories(work_category)\n",
        "print(container_category_work)\n",
        "\n",
        "#format the dictionary\n",
        "test2 = format_category_dict(container_category_work)\n",
        "print(test2)\n",
        "\n",
        "\n",
        "\n",
        "#test = get_container_categories(format_category_dict(wk))\n",
        "#print(test)\n",
        "\n",
        "\n",
        "#print(get_container_categories(test))\n",
        "\n",
        "#test3 = get_pageviews_for_categories(test2)\n",
        "#print(test3)\n",
        "\n",
        "#test4 = get_dict_for_every_location(test2, cat_with_pv_location)\n",
        "\n",
        "#Nowthat we have the parent categories, lets go one step above to get Racing drivers instead of nationality of racing drivers\n",
        "# now look for"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxTmbkd3bCIs",
        "outputId": "4da4bd4b-85b5-4ee4-8ba9-1fa4633f14cb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Max Verstappen': OrderedDict([('https://en.wikipedia.org/wiki/Category:1997_births', (100, 0, 21263)), ('https://en.wikipedia.org/wiki/Category:Belgian_racing_drivers', (100, 0, 1271)), ('https://en.wikipedia.org/wiki/Category:Dutch_racing_drivers', (100, 0, 1714)), ('https://en.wikipedia.org/wiki/Category:FIA_Formula_3_European_Championship_drivers', (100, 0, 163)), ('https://en.wikipedia.org/wiki/Category:Formula_One_race_winners', (100, 0, 1111)), ('https://en.wikipedia.org/wiki/Category:Karting_World_Championship_drivers', (100, 0, 808)), ('https://en.wikipedia.org/wiki/Category:Living_people', (100, 0, 509392)), ('https://en.wikipedia.org/wiki/Category:Motopark_Academy_drivers', (100, 0, 140)), ('https://en.wikipedia.org/wiki/Category:Officers_of_the_Order_of_Orange-Nassau', (100, 0, 3055)), ('https://en.wikipedia.org/wiki/Category:Twitch_(service)_streamers', (100, 0, 14054)), ('https://en.wikipedia.org/wiki/Category:Van_Amersfoort_Racing_drivers', (97, 0, 119)), ('https://en.wikipedia.org/wiki/Category:Sportspeople_from_Hasselt', (64, 0, 66)), (\"https://en.wikipedia.org/wiki/Category:Formula_One_World_Drivers'_Champions\", (35, 0, 950)), ('https://en.wikipedia.org/wiki/Category:Dutch_Formula_One_drivers', (20, 0, 1715)), ('https://en.wikipedia.org/wiki/Category:Dutch_people_of_Belgian_descent', (18, 0, 255)), ('https://en.wikipedia.org/wiki/Category:Belgian_people_of_Dutch_descent', (15, 0, 220)), ('https://en.wikipedia.org/wiki/Category:Toro_Rosso_Formula_One_drivers', (14, 0, 244)), ('https://en.wikipedia.org/wiki/Category:Red_Bull_Formula_One_drivers', (12, 0, 1012)), ('https://en.wikipedia.org/wiki/Category:Belgian_expatriates_in_Monaco', (10, 0, 197)), ('https://en.wikipedia.org/wiki/Category:Dutch_expatriate_sportspeople_in_Monaco', (8, 0, 48)), ('https://en.wikipedia.org/wiki/Category:Max_Verstappen', (2, 0))]), 'Michael Jackson': OrderedDict([('https://en.wikipedia.org/wiki/Category:1958_births', (100, 0, 20968)), ('https://en.wikipedia.org/wiki/Category:2009_deaths', (100, 0, 14797)), ('https://en.wikipedia.org/wiki/Category:20th-century_American_businesspeople', (100, 0, 7750)), ('https://en.wikipedia.org/wiki/Category:20th-century_American_singers', (100, 0, 9318)), ('https://en.wikipedia.org/wiki/Category:21st-century_American_businesspeople', (100, 0, 6818)), ('https://en.wikipedia.org/wiki/Category:21st-century_American_singers', (100, 0, 12476)), ('https://en.wikipedia.org/wiki/Category:Accidental_deaths_in_California', (100, 0, 4250)), ('https://en.wikipedia.org/wiki/Category:African-American_businesspeople', (100, 0, 1909)), ('https://en.wikipedia.org/wiki/Category:African-American_male_dancers', (100, 0, 1870)), ('https://en.wikipedia.org/wiki/Category:African-American_male_singers', (100, 0, 20314)), ('https://en.wikipedia.org/wiki/Category:African-American_record_producers', (100, 0, 1656)), ('https://en.wikipedia.org/wiki/Category:African-American_songwriters', (100, 0, 1739)), ('https://en.wikipedia.org/wiki/Category:American_child_singers', (100, 0, 11895)), ('https://en.wikipedia.org/wiki/Category:American_choreographers', (100, 0, 1721)), ('https://en.wikipedia.org/wiki/Category:American_dance_musicians', (100, 0, 1689)), ('https://en.wikipedia.org/wiki/Category:American_funk_singers', (100, 0, 676)), ('https://en.wikipedia.org/wiki/Category:American_humanitarians', (100, 0, 1966)), ('https://en.wikipedia.org/wiki/Category:American_male_dancers', (100, 0, 2787)), ('https://en.wikipedia.org/wiki/Category:American_male_pop_singers', (100, 0, 17599)), ('https://en.wikipedia.org/wiki/Category:American_male_singers', (100, 0, 30303)), ('https://en.wikipedia.org/wiki/Category:American_male_songwriters', (100, 0, 4813)), ('https://en.wikipedia.org/wiki/Category:American_multi-instrumentalists', (100, 0, 1754)), ('https://en.wikipedia.org/wiki/Category:American_philanthropists', (100, 0, 10318)), ('https://en.wikipedia.org/wiki/Category:American_rhythm_and_blues_singers', (100, 0, 1693)), ('https://en.wikipedia.org/wiki/Category:American_rock_singers', (100, 0, 9261)), ('https://en.wikipedia.org/wiki/Category:American_rock_songwriters', (100, 0, 1242)), ('https://en.wikipedia.org/wiki/Category:American_soul_singers', (100, 0, 4675)), ('https://en.wikipedia.org/wiki/Category:American_tenors', (100, 0, 5900)), ('https://en.wikipedia.org/wiki/Category:Brit_Award_winners', (100, 0, 2508)), ('https://en.wikipedia.org/wiki/Category:Burials_at_Forest_Lawn_Memorial_Park_(Glendale)', (100, 0, 5061)), ('https://en.wikipedia.org/wiki/Category:Businesspeople_from_California', (100, 0, 970)), ('https://en.wikipedia.org/wiki/Category:Child_pop_musicians', (100, 0, 2467)), ('https://en.wikipedia.org/wiki/Category:Dance-pop_musicians', (100, 0, 861)), ('https://en.wikipedia.org/wiki/Category:Dancers_from_California', (100, 0, 224)), ('https://en.wikipedia.org/wiki/Category:Drug-related_deaths_in_California', (100, 0, 4985)), ('https://en.wikipedia.org/wiki/Category:Epic_Records_artists', (100, 0, 1306)), ('https://en.wikipedia.org/wiki/Category:Featured_articles', (100, 0, 11616)), ('https://en.wikipedia.org/wiki/Category:Grammy_Award_winners', (100, 0, 11968)), ('https://en.wikipedia.org/wiki/Category:Grammy_Lifetime_Achievement_Award_winners', (100, 0, 1934)), ('https://en.wikipedia.org/wiki/Category:MTV_Europe_Music_Award_winners', (100, 0, 1491)), ('https://en.wikipedia.org/wiki/Category:Modern_dancers', (100, 0, 426)), ('https://en.wikipedia.org/wiki/Category:Motown_artists', (100, 0, 2319)), ('https://en.wikipedia.org/wiki/Category:Record_producers_from_California', (100, 0, 1133)), ('https://en.wikipedia.org/wiki/Category:Singers_from_California', (100, 0, 4849)), ('https://en.wikipedia.org/wiki/Category:Songwriters_from_California', (100, 0, 1034)), ('https://en.wikipedia.org/wiki/Category:Spoken_articles', (100, 0, 14697)), ('https://en.wikipedia.org/wiki/Category:World_Music_Awards_winners', (100, 0, 1512)), ('https://en.wikipedia.org/wiki/Category:World_record_holders', (100, 0, 3022)), ('https://en.wikipedia.org/wiki/Category:Writers_from_California', (100, 0, 2715)), ('https://en.wikipedia.org/wiki/Category:Businesspeople_from_Indiana', (89, 0, 137)), ('https://en.wikipedia.org/wiki/Category:African-American_choreographers', (85, 0, 536)), ('https://en.wikipedia.org/wiki/Category:Songwriters_from_Indiana', (80, 0, 364)), ('https://en.wikipedia.org/wiki/Category:Singers_from_Indiana', (75, 0, 714)), ('https://en.wikipedia.org/wiki/Category:African-American_rock_singers', (69, 0, 1362)), ('https://en.wikipedia.org/wiki/Category:Michael_Jackson', (61, 0, 1868)), ('https://en.wikipedia.org/wiki/Category:People_acquitted_of_sex_crimes', (60, 0, 1614)), ('https://en.wikipedia.org/wiki/Category:American_expatriates_in_Ireland', (50, 0, 324)), (\"https://en.wikipedia.org/wiki/Category:Former_Jehovah's_Witnesses\", (50, 0, 5257)), ('https://en.wikipedia.org/wiki/Category:American_disco_singers', (48, 0, 518)), ('https://en.wikipedia.org/wiki/Category:People_from_Holmby_Hills,_Los_Angeles', (45, 0, 240)), ('https://en.wikipedia.org/wiki/Category:People_with_lupus', (39, 0, 972)), ('https://en.wikipedia.org/wiki/Category:American_nonprofit_businesspeople', (38, 0, 122)), ('https://en.wikipedia.org/wiki/Category:Musicians_from_Gary,_Indiana', (38, 0, 755)), ('https://en.wikipedia.org/wiki/Category:American_beatboxers', (37, 0, 400)), ('https://en.wikipedia.org/wiki/Category:American_manslaughter_victims', (35, 0, 581)), ('https://en.wikipedia.org/wiki/Category:People_with_vitiligo', (34, 0, 1304)), ('https://en.wikipedia.org/wiki/Category:Boy_sopranos', (32, 0, 625)), ('https://en.wikipedia.org/wiki/Category:Jackson_family_(show_business)', (31, 0, 1302)), ('https://en.wikipedia.org/wiki/Category:Record_producers_from_Indiana', (31, 0, 112)), ('https://en.wikipedia.org/wiki/Category:People_from_Santa_Barbara_County,_California', (29, 0, 119)), ('https://en.wikipedia.org/wiki/Category:New_jack_swing_musicians', (24, 0, 321)), ('https://en.wikipedia.org/wiki/Category:Writers_from_Gary,_Indiana', (23, 0, 176)), ('https://en.wikipedia.org/wiki/Category:Post-disco_musicians', (17, 0, 136)), ('https://en.wikipedia.org/wiki/Category:Grammy_Legend_Award_winners', (16, 0, 432)), ('https://en.wikipedia.org/wiki/Category:Music_video_codirectors', (13, 0, 120)), ('https://en.wikipedia.org/wiki/Category:History_of_Gary,_Indiana', (11, 0, 60)), ('https://en.wikipedia.org/wiki/Category:Presley_family', (11, 0)), ('https://en.wikipedia.org/wiki/Category:Culture_of_Gary,_Indiana', (7, 0, 105)), ('https://en.wikipedia.org/wiki/Category:The_Jackson_5_members', (7, 0, 341)), ('https://en.wikipedia.org/wiki/Category:Dancers_from_Indiana', (6, 0, 67))]), 'Joe Biden': OrderedDict([('https://en.wikipedia.org/wiki/Category:1942_births', (100, 0, 16155)), ('https://en.wikipedia.org/wiki/Category:20th-century_American_lawyers', (100, 0, 5755)), ('https://en.wikipedia.org/wiki/Category:20th-century_American_politicians', (100, 0, 8176)), ('https://en.wikipedia.org/wiki/Category:20th-century_Roman_Catholics', (100, 0, 1405)), ('https://en.wikipedia.org/wiki/Category:21st-century_American_memoirists', (100, 0, 769)), ('https://en.wikipedia.org/wiki/Category:21st-century_Roman_Catholics', (100, 0, 2832)), ('https://en.wikipedia.org/wiki/Category:American_Roman_Catholics', (100, 0, 14103)), ('https://en.wikipedia.org/wiki/Category:American_people_of_English_descent', (100, 0, 22035)), ('https://en.wikipedia.org/wiki/Category:American_people_of_French_descent', (100, 0, 7338)), ('https://en.wikipedia.org/wiki/Category:American_people_of_Irish_descent', (100, 0, 32705)), ('https://en.wikipedia.org/wiki/Category:Candidates_in_the_2020_United_States_presidential_election', (100, 0, 803)), ('https://en.wikipedia.org/wiki/Category:Catholics_from_Pennsylvania', (100, 0, 680)), ('https://en.wikipedia.org/wiki/Category:Delaware_lawyers', (100, 0, 214)), ('https://en.wikipedia.org/wiki/Category:Living_people', (100, 0, 509392)), ('https://en.wikipedia.org/wiki/Category:People_appearing_on_C-SPAN', (100, 0, 4536)), ('https://en.wikipedia.org/wiki/Category:People_from_Wilmington,_Delaware', (100, 0, 452)), ('https://en.wikipedia.org/wiki/Category:People_involved_in_plagiarism_controversies', (100, 0, 2801)), ('https://en.wikipedia.org/wiki/Category:Presidential_Medal_of_Freedom_recipients', (100, 0, 10987)), ('https://en.wikipedia.org/wiki/Category:Presidents_of_the_United_States', (100, 0, 18140)), ('https://en.wikipedia.org/wiki/Category:Public_defenders', (100, 0, 1468)), ('https://en.wikipedia.org/wiki/Category:Recipients_of_the_Order_of_the_Cross_of_Terra_Mariana,_1st_Class', (100, 0, 405)), ('https://en.wikipedia.org/wiki/Category:Transgender_rights_activists', (100, 0, 4510)), ('https://en.wikipedia.org/wiki/Category:University_of_Delaware_alumni', (100, 0, 440)), ('https://en.wikipedia.org/wiki/Category:University_of_Pennsylvania_faculty', (100, 0, 1198)), ('https://en.wikipedia.org/wiki/Category:Vague_or_ambiguous_time_from_October_2020', (100, 0, 221)), ('https://en.wikipedia.org/wiki/Category:Syracuse_University_College_of_Law_alumni', (98, 0, 667)), ('https://en.wikipedia.org/wiki/Category:Laetare_Medal_recipients', (95, 0, 181)), (\"https://en.wikipedia.org/wiki/Category:Delaware_Fightin'_Blue_Hens_football_players\", (87, 0, 182)), ('https://en.wikipedia.org/wiki/Category:Time_Person_of_the_Year', (85, 0, 2396)), ('https://en.wikipedia.org/wiki/Category:Vice_presidents_of_the_United_States', (81, 0, 840)), ('https://en.wikipedia.org/wiki/Category:Delaware_Democrats', (76, 0, 228)), ('https://en.wikipedia.org/wiki/Category:Obama_administration_cabinet_members', (75, 0, 618)), ('https://en.wikipedia.org/wiki/Category:Joe_Biden', (61, 0, 1202)), ('https://en.wikipedia.org/wiki/Category:Candidates_in_the_2008_United_States_presidential_election', (60, 0, 283)), ('https://en.wikipedia.org/wiki/Category:Chairmen_of_the_Senate_Committee_on_Foreign_Relations', (55, 0, 131)), ('https://en.wikipedia.org/wiki/Category:Democratic_Party_(United_States)_vice_presidential_nominees', (47, 0, 220)), ('https://en.wikipedia.org/wiki/Category:Writers_from_Wilmington,_Delaware', (47, 0, 141)), ('https://en.wikipedia.org/wiki/Category:Politicians_from_Scranton,_Pennsylvania', (46, 0, 537)), ('https://en.wikipedia.org/wiki/Category:Candidates_in_the_1988_United_States_presidential_election', (44, 0, 285)), ('https://en.wikipedia.org/wiki/Category:Centrism_in_the_United_States', (41, 0, 839)), ('https://en.wikipedia.org/wiki/Category:Democratic_Party_(United_States)_presidential_nominees', (38, 0, 256)), (\"https://en.wikipedia.org/wiki/Category:Recipients_of_St._George's_Order_of_Victory\", (33, 0, 123)), ('https://en.wikipedia.org/wiki/Category:Writers_from_Scranton,_Pennsylvania', (32, 0, 287)), ('https://en.wikipedia.org/wiki/Category:Biden_family', (25, 0, 1152)), ('https://en.wikipedia.org/wiki/Category:Widener_University_faculty', (25, 0, 64)), ('https://en.wikipedia.org/wiki/Category:Recipients_of_Hilal-i-Pakistan', (24, 0, 221)), ('https://en.wikipedia.org/wiki/Category:Candidates_in_the_2024_United_States_presidential_election', (23, 0, 114)), ('https://en.wikipedia.org/wiki/Category:Democratic_Party_presidents_of_the_United_States', (20, 0, 384)), ('https://en.wikipedia.org/wiki/Category:Democratic_Party_vice_presidents_of_the_United_States', (19, 0, 139)), ('https://en.wikipedia.org/wiki/Category:Democratic_Party_United_States_senators_from_Delaware', (18, 0, 63)), ('https://en.wikipedia.org/wiki/Category:Recipients_of_the_Presidential_Medal_of_Distinction_of_Israel', (18, 0, 140)), ('https://en.wikipedia.org/wiki/Category:People_from_Claymont,_Delaware', (16, 0, 65)), ('https://en.wikipedia.org/wiki/Category:2008_United_States_vice-presidential_candidates', (12, 0, 92)), ('https://en.wikipedia.org/wiki/Category:2012_United_States_vice-presidential_candidates', (8, 0, 74)), ('https://en.wikipedia.org/wiki/Category:County_council_members_and_commissioners_in_Delaware', (6, 0, 71)), ('https://en.wikipedia.org/wiki/Category:New_Castle_County,_Delaware_politicians', (6, 0, 80)), ('https://en.wikipedia.org/wiki/Category:21st-century_presidents_of_the_United_States', (5, 0, 5910)), ('https://en.wikipedia.org/wiki/Category:21st-century_vice_presidents_of_the_United_States', (5, 0, 299)), ('https://en.wikipedia.org/wiki/Category:Catholic_politicians_from_Delaware', (5, 0))])}\n",
            "{'Max Verstappen': ['Category:Belgian racing drivers', 'Category:Dutch racing drivers', 'Category:1997 births'], 'Michael Jackson': ['Category:2009 deaths', 'Category:1958 births', 'Category:American rhythm and blues singers'], 'Joe Biden': ['Category:Presidents of the United States', 'Category:Vice presidents of the United States', 'Category:21st-century presidents of the United States']}\n",
            "wk  {'Max Verstappen': 'Category:Belgian racing drivers', 'Michael Jackson': 'Category:American rhythm and blues singers', 'Joe Biden': 'Category:Presidents of the United States'}\n",
            "{'Max Verstappen': ['Belgian motorsport people', 'Racing drivers by nationality'], 'Michael Jackson': ['American rhythm and blues musicians by instrument', 'American singers by genre', 'Rhythm and blues singers by nationality'], 'Joe Biden': ['Candidates for President of the United States', 'Executive heads of state', 'Federal political office-holders in the United States', 'Heads of government by country', 'Heads of state by country', 'Heads of state of the United States', 'Presidency of the United States', 'Presidents by country']}\n",
            "{'Max Verstappen': ['Category:Belgian_motorsport_people', 'Category:Racing_drivers_by_nationality'], 'Michael Jackson': ['Category:American_rhythm_and_blues_musicians_by_instrument', 'Category:American_singers_by_genre', 'Category:Rhythm_and_blues_singers_by_nationality'], 'Joe Biden': ['Category:Candidates_for_President_of_the_United_States', 'Category:Executive_heads_of_state', 'Category:Federal_political_office-holders_in_the_United_States', 'Category:Heads_of_government_by_country', 'Category:Heads_of_state_by_country', 'Category:Heads_of_state_of_the_United_States', 'Category:Presidency_of_the_United_States', 'Category:Presidents_by_country']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#The wikipedia-api library does not provide a direct method to retrieve the infobox of a Wikipedia page. \n",
        "#However, we can use beautifulsoup4 to parse the HTML content of the Wikipedia page and extract the infobox.\n",
        "#function that retrieves the infobox using beautifulsoup4\n",
        "def get_infobox_from_wikipedia(page_title):\n",
        "    # Format the page title for the Wikipedia URL\n",
        "    formatted_title = page_title.replace(' ', '_')\n",
        "    # Construct the Wikipedia page URL\n",
        "    url = f\"https://en.wikipedia.org/wiki/{formatted_title}\"\n",
        "    # Send a GET request to the Wikipedia page\n",
        "    response = requests.get(url)\n",
        "    # Check if the page exists\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Page '{page_title}' does not exist.\")\n",
        "        return None\n",
        "    # Create a BeautifulSoup object to parse the page content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Find the infobox section of the page\n",
        "    infobox = soup.find(class_='infobox')\n",
        "    return infobox\n",
        "\n",
        "#function that retrieves the infobox from a Wikipedia page and specifically extracts the entries from the \"occupation\" or \"occupations\" field:\n",
        "def get_occupations_from_infobox(page_title):\n",
        "    # Retrieve the infobox from the Wikipedia page\n",
        "    infobox = get_infobox_from_wikipedia(page_title)\n",
        "    # Check if the infobox exists\n",
        "    if not infobox:\n",
        "        return []\n",
        "    # Search for the \"occupation\" or \"occupations\" field in the infobox\n",
        "    occupation_keywords = ['occupation', 'occupations', 'Occupation', 'Occupations']\n",
        "    occupations = []\n",
        "    for keyword in occupation_keywords:\n",
        "        field = infobox.find(string=keyword)\n",
        "        if field:\n",
        "            # Retrieve the occupation entries from the field\n",
        "            tmp_str = field.find_next(\"td\").find_next(\"div\").find_next(\"ul\")\n",
        "            from_table = extract_list_elements(tmp_str)\n",
        "            from_field = field.find_next(\"td\").text.strip()\n",
        "            from_field = from_field.split()\n",
        "            if len(from_table) > 0:\n",
        "              for i in from_table:\n",
        "                occupations.append(i)\n",
        "            elif len(from_field) > 0:\n",
        "              for i in from_field:\n",
        "                occupations.append(i)\n",
        "            else:\n",
        "              print(\"prpoblem\")\n",
        "    return occupations\n",
        "\n",
        "#extract the elements between the <li> tags\n",
        "def extract_list_elements(html_string):\n",
        "  occupations_list = []\n",
        "  li_entries_list = []\n",
        "  html_str = str(html_string)\n",
        "  html_str = html_str.replace(\"</ul>\", \"\")\n",
        "  html_str = html_str.replace(\"<ul>\", \"\")\n",
        "  html_str = html_str.replace(\"</li>\", \"\")\n",
        "  li_entries_list = html_str.split(\"<li>\")\n",
        "  for i in li_entries_list:\n",
        "    if len(i) > 0: #check if empty\n",
        "      if len(i) < 16: #check if entry is a link\n",
        "        occupations_list.append(i)\n",
        "  return occupations_list\n",
        "\n",
        "#searches the occupation for every entry in people list\n",
        "def get_occupations(people_list):\n",
        "  occupation_person_dict = {}\n",
        "  for person in people_list:\n",
        "    occupation_person_dict[person] = get_occupations_from_infobox(person) \n",
        "  return occupation_person_dict\n",
        "\n",
        "#TEST IT OUT?\n",
        "people_list=[]\n",
        "for l in dataPerson:\n",
        "  people_list.append(l[1])\n",
        "\n",
        "occupation_person_dict = get_occupations(people_list)\n",
        "print(occupation_person_dict)\n"
      ],
      "metadata": {
        "id": "eZN-S8yKdMmQ",
        "outputId": "d90d2f1f-1817-47b9-dadd-30a2a97ed22a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Max Verstappen': ['Racing', 'driver'], 'Michael Jackson': ['Singer', 'songwriter', 'dancer', 'record producer'], 'Joe Biden': ['Politician', 'lawyer', 'author']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. retrieve all of the related links of a wiki-persons-page (first 500);\n",
        "2. pre prune the list, such that only entries with 2 words in the title are left; (for performance reasons)\n",
        "3. analyse the links that are left via wikipedia APi and the \"instance of\" (P31) property set to \"human\" (Q5)\n",
        "4. now we have a list of related people to compare to our answer-person-entity\n",
        "\"\"\"\n",
        "import random\n",
        "\n",
        "#retrieves all of the relate links of a wiki page\n",
        "def get_related_links(wiki_link):\n",
        "    # Extract the page title from the Wikipedia link\n",
        "    title = wiki_link.split('/')[-1]\n",
        "    # Format the API URL to get the page content\n",
        "    api_url = f'https://en.wikipedia.org/w/api.php?action=query&titles={title}&prop=links&pllimit=max&format=json'\n",
        "    # Send a GET request to the API\n",
        "    response = requests.get(api_url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        # Extract the page ID from the API response\n",
        "        page_id = next(iter(data['query']['pages']))\n",
        "        # Check if the page exists and has links\n",
        "        if page_id != '-1' and 'links' in data['query']['pages'][page_id]:\n",
        "            # Retrieve the links from the API response\n",
        "            links = data['query']['pages'][page_id]['links']\n",
        "            # Extract the link titles and URLs\n",
        "            related_links = [{'url': f'https://en.wikipedia.org/wiki/{link[\"title\"]}', 'title': link['title']} for link in links]\n",
        "            return related_links\n",
        "    return []\n",
        "\n",
        "# function to check if the title consists of two words -> discrad a lot of entries for performance reasons\n",
        "def filter_two_word_titles(links):\n",
        "    filtered_links = []\n",
        "    url_concat = \"\"\n",
        "    for link in links:\n",
        "      url = link['url']\n",
        "      link['url'] = url.replace(' ', '_')\n",
        "      title = link['title']\n",
        "      words = title.split()\n",
        "      if len(words) == 2:\n",
        "        filtered_links.append(link)\n",
        "\n",
        "    return filtered_links\n",
        "\n",
        "#check if a given Wikipedia link corresponds to an entity with the \"instance of\" (P31) property set to \"human\" (Q5), indicating it represents a person\n",
        "def is_person_page(link):\n",
        "    # Extract the page title from the link\n",
        "    title = link['title']\n",
        "    # Query Wikidata API to check if the page corresponds to a person\n",
        "    wikidata_url = f\"https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&sites=enwiki&titles={title}\"\n",
        "    response = requests.get(wikidata_url).json()\n",
        "    # Check if the response contains any entities\n",
        "    if 'entities' in response:\n",
        "        entities = response['entities']\n",
        "        # Check if there is an entity with P31 (instance of) set to Q5 (human)\n",
        "        for entity_id, entity in entities.items():\n",
        "            if 'claims' in entity and 'P31' in entity['claims']:\n",
        "                for claim in entity['claims']['P31']:\n",
        "                    if claim['mainsnak']['datavalue']['value']['id'] == 'Q5':\n",
        "                        return True\n",
        "    return False\n",
        "\n",
        "#function that calls the is_perso_page() function for every link in the pre discraded list\n",
        "def check_if_person(links):\n",
        "  person_links= []\n",
        "  for link in links:\n",
        "    if is_person_page(link):\n",
        "       person_links.append(link)\n",
        "  return person_links\n",
        "\n",
        "#function that selects 5 entries at random from a list of related people:\n",
        "def select_random_entries(related_people_list, num_entries=5):\n",
        "    random_entries = random.sample(related_people_list, num_entries)\n",
        "    return random_entries\n",
        "#TEST\n",
        "#\n",
        "\n",
        "\n",
        "# takes a list of all the people and the list of category occurences where all the categories that were assigned to these wiki-pages \n",
        "# are listed and ranked after how often they occur; \n",
        "# output: a list where the person is the key and the entries show wich categories the entity shares with wich other entitities and how many they are\n",
        "def get_people_dict(people_list, occurences_list):\n",
        "    people_dict = {}\n",
        "    for person in people_list:\n",
        "        person_categories = []\n",
        "        for occurence in occurences_list:\n",
        "            if person in occurence[2]:\n",
        "                person_categories.append((occurence[0], occurence[1], occurence[2]))\n",
        "        people_dict[person] = person_categories\n",
        "    return people_dict\n",
        "##\n",
        "##\n",
        "\n",
        "#\n",
        "#\n",
        "wiki_link = 'https://en.wikipedia.org/wiki/Max_Verstappen'\n",
        "related_articles = get_related_links(wiki_link)\n",
        "print(\"related articles:\",  len(related_articles))\n",
        "\n",
        "filtered_links = filter_two_word_titles(related_articles)\n",
        "print(\"filtered articles:\",  len(filtered_links))\n",
        "#print(filtered_links)\n",
        "\n",
        "related_people_list = check_if_person(filtered_links)\n",
        "print(\"related_people_list:\",  len(related_people_list))\n",
        "#print(related_people_list)\n",
        "\n",
        "select_random_people = select_random_entries(related_people_list)\n",
        "print(\"select_random_people:\",  len(select_random_people))\n",
        "\n",
        "pprint.pprint(select_random_people)\n",
        "\n",
        "#TEST\n",
        "#prunedAndOrdered = prune_and_ordered_dict(copy_new_ordered_dict_person, 20)\n",
        "#pprint.pprint(prunedAndOrdered)\n",
        "\"\"\"\n",
        "#for person\n",
        "cat_ranking_person = get_categories(person_questions_dict)\n",
        "#pprint.pprint(cat_ranking_person, indent=1)\n",
        "cat_with_pv_person = get_pageviews_for_categories(cat_ranking_person)\n",
        "#pprint.pprint(cat_with_pv_person, indent=1)\n",
        "#for person: sorting the dict after pages per category\n",
        "categories_with_subs_and_pageviews_person = get_dict_for_every_location(cat_ranking_person, cat_with_pv_person)\n",
        "#pprint.pprint(categories_with_subs_and_pageviews_person,indent=1)\n",
        "new_ordered_dict_person = sorting_dict(categories_with_subs_and_pageviews_person)\n",
        "#pprint.pprint(new_ordered_dict_person,indent=1)\n",
        "\"\"\"\n",
        "\n",
        "#people_list=[]\n",
        "#for l in dataPerson:\n",
        "#  people_list.append(l[1])\n",
        "\n",
        "#shared_categories = get_people_dict(people_list, category_occurences)\n",
        "#pprint.pprint(shared_categories, indent=1, compact=True)"
      ],
      "metadata": {
        "id": "srvRakz78Jsn",
        "outputId": "08f746b3-4007-4b04-8e92-08995192eb51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "related articles: 500\n",
            "filtered articles: 132\n",
            "[{'url': 'https://en.wikipedia.org/wiki/Adrian_Newey', 'title': 'Adrian Newey'}, {'url': 'https://en.wikipedia.org/wiki/Aircraft_registration', 'title': 'Aircraft registration'}, {'url': 'https://en.wikipedia.org/wiki/Alain_Prost', 'title': 'Alain Prost'}, {'url': 'https://en.wikipedia.org/wiki/Alberto_Ascari', 'title': 'Alberto Ascari'}, {'url': 'https://en.wikipedia.org/wiki/Alex_Albon', 'title': 'Alex Albon'}, {'url': 'https://en.wikipedia.org/wiki/Alex_Hitzinger', 'title': 'Alex Hitzinger'}, {'url': 'https://en.wikipedia.org/wiki/Alex_Zanardi', 'title': 'Alex Zanardi'}, {'url': 'https://en.wikipedia.org/wiki/Alexander_Albon', 'title': 'Alexander Albon'}, {'url': 'https://en.wikipedia.org/wiki/Alexandre_Prémat', 'title': 'Alexandre Prémat'}, {'url': 'https://en.wikipedia.org/wiki/Andrew_Shovlin', 'title': 'Andrew Shovlin'}, {'url': 'https://en.wikipedia.org/wiki/Anthony_Kumpen', 'title': 'Anthony Kumpen'}, {'url': 'https://en.wikipedia.org/wiki/Antonio_Fuoco', 'title': 'Antonio Fuoco'}, {'url': 'https://en.wikipedia.org/wiki/Antonio_Giovinazzi', 'title': 'Antonio Giovinazzi'}, {'url': 'https://en.wikipedia.org/wiki/Auto_racing', 'title': 'Auto racing'}, {'url': 'https://en.wikipedia.org/wiki/Autosport_Awards', 'title': 'Autosport Awards'}, {'url': 'https://en.wikipedia.org/wiki/Ayrton_Senna', 'title': 'Ayrton Senna'}, {'url': 'https://en.wikipedia.org/wiki/Ayumu_Iwasa', 'title': 'Ayumu Iwasa'}, {'url': 'https://en.wikipedia.org/wiki/BBC_Sport', 'title': 'BBC Sport'}, {'url': 'https://en.wikipedia.org/wiki/Ben_Agathangelou', 'title': 'Ben Agathangelou'}, {'url': 'https://en.wikipedia.org/wiki/Ben_Pon', 'title': 'Ben Pon'}, {'url': 'https://en.wikipedia.org/wiki/Ben_Waterhouse', 'title': 'Ben Waterhouse'}, {'url': 'https://en.wikipedia.org/wiki/Boy_Hayje', 'title': 'Boy Hayje'}, {'url': 'https://en.wikipedia.org/wiki/Bree,_Belgium', 'title': 'Bree, Belgium'}, {'url': 'https://en.wikipedia.org/wiki/Brendon_Hartley', 'title': 'Brendon Hartley'}, {'url': 'https://en.wikipedia.org/wiki/Charles_Leclerc', 'title': 'Charles Leclerc'}, {'url': 'https://en.wikipedia.org/wiki/Charlie_Whiting', 'title': 'Charlie Whiting'}, {'url': 'https://en.wikipedia.org/wiki/Christian_Horner', 'title': 'Christian Horner'}, {'url': 'https://en.wikipedia.org/wiki/Christian_Klien', 'title': 'Christian Klien'}, {'url': 'https://en.wikipedia.org/wiki/Christijan_Albers', 'title': 'Christijan Albers'}, {'url': 'https://en.wikipedia.org/wiki/Ciaron_Pilbeam', 'title': 'Ciaron Pilbeam'}, {'url': 'https://en.wikipedia.org/wiki/Dallara_F312', 'title': 'Dallara F312'}, {'url': 'https://en.wikipedia.org/wiki/Damon_Hill', 'title': 'Damon Hill'}, {'url': 'https://en.wikipedia.org/wiki/Dan_Fallows', 'title': 'Dan Fallows'}, {'url': 'https://en.wikipedia.org/wiki/Daniel_Juncadella', 'title': 'Daniel Juncadella'}, {'url': 'https://en.wikipedia.org/wiki/Daniel_Ricciardo', 'title': 'Daniel Ricciardo'}, {'url': 'https://en.wikipedia.org/wiki/Daniil_Kvyat', 'title': 'Daniil Kvyat'}, {'url': 'https://en.wikipedia.org/wiki/Dave_Stubbs', 'title': 'Dave Stubbs'}, {'url': 'https://en.wikipedia.org/wiki/David_Coulthard', 'title': 'David Coulthard'}, {'url': 'https://en.wikipedia.org/wiki/David_Saelens', 'title': 'David Saelens'}, {'url': 'https://en.wikipedia.org/wiki/David_Tremayne', 'title': 'David Tremayne'}, {'url': 'https://en.wikipedia.org/wiki/Dennis_Hauger', 'title': 'Dennis Hauger'}, {'url': 'https://en.wikipedia.org/wiki/Denny_Hulme', 'title': 'Denny Hulme'}, {'url': 'https://en.wikipedia.org/wiki/Dietrich_Mateschitz', 'title': 'Dietrich Mateschitz'}, {'url': 'https://en.wikipedia.org/wiki/Eddie_Irvine', 'title': 'Eddie Irvine'}, {'url': 'https://en.wikipedia.org/wiki/Emerson_Fittipaldi', 'title': 'Emerson Fittipaldi'}, {'url': 'https://en.wikipedia.org/wiki/Enzo_Deligny', 'title': 'Enzo Deligny'}, {'url': 'https://en.wikipedia.org/wiki/Enzo_Fittipaldi', 'title': 'Enzo Fittipaldi'}, {'url': 'https://en.wikipedia.org/wiki/Esapekka_Lappi', 'title': 'Esapekka Lappi'}, {'url': 'https://en.wikipedia.org/wiki/Esteban_Ocon', 'title': 'Esteban Ocon'}, {'url': 'https://en.wikipedia.org/wiki/FC_Barcelona', 'title': 'FC Barcelona'}, {'url': 'https://en.wikipedia.org/wiki/Felipe_Massa', 'title': 'Felipe Massa'}, {'url': 'https://en.wikipedia.org/wiki/Felipe_Nasr', 'title': 'Felipe Nasr'}, {'url': 'https://en.wikipedia.org/wiki/Felix_Rosenqvist', 'title': 'Felix Rosenqvist'}, {'url': 'https://en.wikipedia.org/wiki/Fernando_Alonso', 'title': 'Fernando Alonso'}, {'url': 'https://en.wikipedia.org/wiki/Force_India', 'title': 'Force India'}, {'url': 'https://en.wikipedia.org/wiki/Formation_lap', 'title': 'Formation lap'}, {'url': 'https://en.wikipedia.org/wiki/Formula_One', 'title': 'Formula One'}, {'url': 'https://en.wikipedia.org/wiki/Formula_Renault', 'title': 'Formula Renault'}, {'url': 'https://en.wikipedia.org/wiki/Formula_Three', 'title': 'Formula Three'}, {'url': 'https://en.wikipedia.org/wiki/Franz_Tost', 'title': 'Franz Tost'}, {'url': 'https://en.wikipedia.org/wiki/Fábio_Carbone', 'title': 'Fábio Carbone'}, {'url': 'https://en.wikipedia.org/wiki/Gabriele_Tredozi', 'title': 'Gabriele Tredozi'}, {'url': 'https://en.wikipedia.org/wiki/Geoff_Willis', 'title': 'Geoff Willis'}, {'url': 'https://en.wikipedia.org/wiki/Gerhard_Berger', 'title': 'Gerhard Berger'}, {'url': 'https://en.wikipedia.org/wiki/Gianfranco_Fantuzzi', 'title': 'Gianfranco Fantuzzi'}, {'url': 'https://en.wikipedia.org/wiki/Gianpiero_Lambiase', 'title': 'Gianpiero Lambiase'}, {'url': 'https://en.wikipedia.org/wiki/Giorgio_Ascanelli', 'title': 'Giorgio Ascanelli'}, {'url': 'https://en.wikipedia.org/wiki/Giuseppe_Farina', 'title': 'Giuseppe Farina'}, {'url': 'https://en.wikipedia.org/wiki/Graham_Hill', 'title': 'Graham Hill'}, {'url': 'https://en.wikipedia.org/wiki/Guenther_Steiner', 'title': 'Guenther Steiner'}, {'url': 'https://en.wikipedia.org/wiki/Guillaume_Rocquelin', 'title': 'Guillaume Rocquelin'}, {'url': 'https://en.wikipedia.org/wiki/Hannah_Schmitz', 'title': 'Hannah Schmitz'}, {'url': 'https://en.wikipedia.org/wiki/Harvey_Postlethwaite', 'title': 'Harvey Postlethwaite'}, {'url': 'https://en.wikipedia.org/wiki/Helmut_Marko', 'title': 'Helmut Marko'}, {'url': 'https://en.wikipedia.org/wiki/Homestead–Miami_Speedway', 'title': 'Homestead–Miami Speedway'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA099', 'title': 'Honda RA099'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA106', 'title': 'Honda RA106'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA107', 'title': 'Honda RA107'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA108', 'title': 'Honda RA108'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA271', 'title': 'Honda RA271'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA272', 'title': 'Honda RA272'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA273', 'title': 'Honda RA273'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA300', 'title': 'Honda RA300'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA301', 'title': 'Honda RA301'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RA302', 'title': 'Honda RA302'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RBPT', 'title': 'Honda RBPT'}, {'url': 'https://en.wikipedia.org/wiki/Honda_RC100', 'title': 'Honda RC100'}, {'url': 'https://en.wikipedia.org/wiki/Hugh_Bird', 'title': 'Hugh Bird'}, {'url': 'https://en.wikipedia.org/wiki/Huub_Rothengatter', 'title': 'Huub Rothengatter'}, {'url': 'https://en.wikipedia.org/wiki/ISSN_(identifier)', 'title': 'ISSN (identifier)'}, {'url': 'https://en.wikipedia.org/wiki/IndyCar_Series', 'title': 'IndyCar Series'}, {'url': 'https://en.wikipedia.org/wiki/Isack_Hadjar', 'title': 'Isack Hadjar'}, {'url': 'https://en.wikipedia.org/wiki/Jack_Brabham', 'title': 'Jack Brabham'}, {'url': 'https://en.wikipedia.org/wiki/Jackie_Stewart', 'title': 'Jackie Stewart'}, {'url': 'https://en.wikipedia.org/wiki/Jacky_Eeckelaert', 'title': 'Jacky Eeckelaert'}, {'url': 'https://en.wikipedia.org/wiki/Jacques_Villeneuve', 'title': 'Jacques Villeneuve'}, {'url': 'https://en.wikipedia.org/wiki/Jaime_Alguersuari', 'title': 'Jaime Alguersuari'}, {'url': 'https://en.wikipedia.org/wiki/Jak_Crawford', 'title': 'Jak Crawford'}, {'url': 'https://en.wikipedia.org/wiki/James_Hunt', 'title': 'James Hunt'}, {'url': 'https://en.wikipedia.org/wiki/Jan_Flinterman', 'title': 'Jan Flinterman'}, {'url': 'https://en.wikipedia.org/wiki/Jan_Lammers', 'title': 'Jan Lammers'}, {'url': 'https://en.wikipedia.org/wiki/Jean-Éric_Vergne', 'title': 'Jean-Éric Vergne'}, {'url': 'https://en.wikipedia.org/wiki/Jean_Alesi', 'title': 'Jean Alesi'}, {'url': 'https://en.wikipedia.org/wiki/Jenson_Button', 'title': 'Jenson Button'}, {'url': 'https://en.wikipedia.org/wiki/Jim_Clark', 'title': 'Jim Clark'}, {'url': 'https://en.wikipedia.org/wiki/Jo_Schlesser', 'title': 'Jo Schlesser'}, {'url': 'https://en.wikipedia.org/wiki/Jochen_Rindt', 'title': 'Jochen Rindt'}, {'url': 'https://en.wikipedia.org/wiki/Jock_Clear', 'title': 'Jock Clear'}, {'url': 'https://en.wikipedia.org/wiki/Jody_Egginton', 'title': 'Jody Egginton'}, {'url': 'https://en.wikipedia.org/wiki/Jody_Scheckter', 'title': 'Jody Scheckter'}, {'url': 'https://en.wikipedia.org/wiki/John_Surtees', 'title': 'John Surtees'}, {'url': 'https://en.wikipedia.org/wiki/Jolyon_Palmer', 'title': 'Jolyon Palmer'}, {'url': 'https://en.wikipedia.org/wiki/Jonathan_Cochet', 'title': 'Jonathan Cochet'}, {'url': 'https://en.wikipedia.org/wiki/Jonathan_Eddolls', 'title': 'Jonathan Eddolls'}, {'url': 'https://en.wikipedia.org/wiki/Jonathan_Wheatley', 'title': 'Jonathan Wheatley'}, {'url': 'https://en.wikipedia.org/wiki/Jos_Verstappen', 'title': 'Jos Verstappen'}, {'url': 'https://en.wikipedia.org/wiki/Jules_Bianchi', 'title': 'Jules Bianchi'}, {'url': 'https://en.wikipedia.org/wiki/Jörg_Zander', 'title': 'Jörg Zander'}, {'url': 'https://en.wikipedia.org/wiki/KZ1_(karting)', 'title': 'KZ1 (karting)'}, {'url': 'https://en.wikipedia.org/wiki/Kart_racing', 'title': 'Kart racing'}, {'url': 'https://en.wikipedia.org/wiki/Karun_Chandhok', 'title': 'Karun Chandhok'}, {'url': 'https://en.wikipedia.org/wiki/Keke_Rosberg', 'title': 'Keke Rosberg'}, {'url': 'https://en.wikipedia.org/wiki/Kelly_Piquet', 'title': 'Kelly Piquet'}, {'url': 'https://en.wikipedia.org/wiki/Kevin_Magnussen', 'title': 'Kevin Magnussen'}, {'url': 'https://en.wikipedia.org/wiki/Kimi_Räikkönen', 'title': 'Kimi Räikkönen'}, {'url': 'https://en.wikipedia.org/wiki/Kurt_Mollekens', 'title': 'Kurt Mollekens'}, {'url': 'https://en.wikipedia.org/wiki/Lance_Armstrong', 'title': 'Lance Armstrong'}, {'url': 'https://en.wikipedia.org/wiki/Lance_Stroll', 'title': 'Lance Stroll'}, {'url': 'https://en.wikipedia.org/wiki/Lando_Norris', 'title': 'Lando Norris'}, {'url': 'https://en.wikipedia.org/wiki/Laurent_Mekies', 'title': 'Laurent Mekies'}, {'url': 'https://en.wikipedia.org/wiki/Lewis_Hamilton', 'title': 'Lewis Hamilton'}, {'url': 'https://en.wikipedia.org/wiki/Liam_Lawson', 'title': 'Liam Lawson'}]\n",
            "related_people_list: 101\n",
            "[{'url': 'https://en.wikipedia.org/wiki/Adrian_Newey', 'title': 'Adrian Newey'}, {'url': 'https://en.wikipedia.org/wiki/Alain_Prost', 'title': 'Alain Prost'}, {'url': 'https://en.wikipedia.org/wiki/Alberto_Ascari', 'title': 'Alberto Ascari'}, {'url': 'https://en.wikipedia.org/wiki/Alex_Albon', 'title': 'Alex Albon'}, {'url': 'https://en.wikipedia.org/wiki/Alex_Hitzinger', 'title': 'Alex Hitzinger'}, {'url': 'https://en.wikipedia.org/wiki/Alex_Zanardi', 'title': 'Alex Zanardi'}, {'url': 'https://en.wikipedia.org/wiki/Alexandre_Prémat', 'title': 'Alexandre Prémat'}, {'url': 'https://en.wikipedia.org/wiki/Andrew_Shovlin', 'title': 'Andrew Shovlin'}, {'url': 'https://en.wikipedia.org/wiki/Anthony_Kumpen', 'title': 'Anthony Kumpen'}, {'url': 'https://en.wikipedia.org/wiki/Antonio_Fuoco', 'title': 'Antonio Fuoco'}, {'url': 'https://en.wikipedia.org/wiki/Antonio_Giovinazzi', 'title': 'Antonio Giovinazzi'}, {'url': 'https://en.wikipedia.org/wiki/Ayrton_Senna', 'title': 'Ayrton Senna'}, {'url': 'https://en.wikipedia.org/wiki/Ayumu_Iwasa', 'title': 'Ayumu Iwasa'}, {'url': 'https://en.wikipedia.org/wiki/Ben_Agathangelou', 'title': 'Ben Agathangelou'}, {'url': 'https://en.wikipedia.org/wiki/Ben_Pon', 'title': 'Ben Pon'}, {'url': 'https://en.wikipedia.org/wiki/Ben_Waterhouse', 'title': 'Ben Waterhouse'}, {'url': 'https://en.wikipedia.org/wiki/Boy_Hayje', 'title': 'Boy Hayje'}, {'url': 'https://en.wikipedia.org/wiki/Brendon_Hartley', 'title': 'Brendon Hartley'}, {'url': 'https://en.wikipedia.org/wiki/Charles_Leclerc', 'title': 'Charles Leclerc'}, {'url': 'https://en.wikipedia.org/wiki/Charlie_Whiting', 'title': 'Charlie Whiting'}, {'url': 'https://en.wikipedia.org/wiki/Christian_Horner', 'title': 'Christian Horner'}, {'url': 'https://en.wikipedia.org/wiki/Christian_Klien', 'title': 'Christian Klien'}, {'url': 'https://en.wikipedia.org/wiki/Christijan_Albers', 'title': 'Christijan Albers'}, {'url': 'https://en.wikipedia.org/wiki/Ciaron_Pilbeam', 'title': 'Ciaron Pilbeam'}, {'url': 'https://en.wikipedia.org/wiki/Damon_Hill', 'title': 'Damon Hill'}, {'url': 'https://en.wikipedia.org/wiki/Dan_Fallows', 'title': 'Dan Fallows'}, {'url': 'https://en.wikipedia.org/wiki/Daniel_Juncadella', 'title': 'Daniel Juncadella'}, {'url': 'https://en.wikipedia.org/wiki/Daniel_Ricciardo', 'title': 'Daniel Ricciardo'}, {'url': 'https://en.wikipedia.org/wiki/Daniil_Kvyat', 'title': 'Daniil Kvyat'}, {'url': 'https://en.wikipedia.org/wiki/Dave_Stubbs', 'title': 'Dave Stubbs'}, {'url': 'https://en.wikipedia.org/wiki/David_Coulthard', 'title': 'David Coulthard'}, {'url': 'https://en.wikipedia.org/wiki/David_Saelens', 'title': 'David Saelens'}, {'url': 'https://en.wikipedia.org/wiki/David_Tremayne', 'title': 'David Tremayne'}, {'url': 'https://en.wikipedia.org/wiki/Dennis_Hauger', 'title': 'Dennis Hauger'}, {'url': 'https://en.wikipedia.org/wiki/Denny_Hulme', 'title': 'Denny Hulme'}, {'url': 'https://en.wikipedia.org/wiki/Dietrich_Mateschitz', 'title': 'Dietrich Mateschitz'}, {'url': 'https://en.wikipedia.org/wiki/Eddie_Irvine', 'title': 'Eddie Irvine'}, {'url': 'https://en.wikipedia.org/wiki/Emerson_Fittipaldi', 'title': 'Emerson Fittipaldi'}, {'url': 'https://en.wikipedia.org/wiki/Enzo_Deligny', 'title': 'Enzo Deligny'}, {'url': 'https://en.wikipedia.org/wiki/Enzo_Fittipaldi', 'title': 'Enzo Fittipaldi'}, {'url': 'https://en.wikipedia.org/wiki/Esapekka_Lappi', 'title': 'Esapekka Lappi'}, {'url': 'https://en.wikipedia.org/wiki/Esteban_Ocon', 'title': 'Esteban Ocon'}, {'url': 'https://en.wikipedia.org/wiki/Felipe_Massa', 'title': 'Felipe Massa'}, {'url': 'https://en.wikipedia.org/wiki/Felipe_Nasr', 'title': 'Felipe Nasr'}, {'url': 'https://en.wikipedia.org/wiki/Felix_Rosenqvist', 'title': 'Felix Rosenqvist'}, {'url': 'https://en.wikipedia.org/wiki/Fernando_Alonso', 'title': 'Fernando Alonso'}, {'url': 'https://en.wikipedia.org/wiki/Franz_Tost', 'title': 'Franz Tost'}, {'url': 'https://en.wikipedia.org/wiki/Fábio_Carbone', 'title': 'Fábio Carbone'}, {'url': 'https://en.wikipedia.org/wiki/Gabriele_Tredozi', 'title': 'Gabriele Tredozi'}, {'url': 'https://en.wikipedia.org/wiki/Geoff_Willis', 'title': 'Geoff Willis'}, {'url': 'https://en.wikipedia.org/wiki/Gerhard_Berger', 'title': 'Gerhard Berger'}, {'url': 'https://en.wikipedia.org/wiki/Gianpiero_Lambiase', 'title': 'Gianpiero Lambiase'}, {'url': 'https://en.wikipedia.org/wiki/Giorgio_Ascanelli', 'title': 'Giorgio Ascanelli'}, {'url': 'https://en.wikipedia.org/wiki/Giuseppe_Farina', 'title': 'Giuseppe Farina'}, {'url': 'https://en.wikipedia.org/wiki/Graham_Hill', 'title': 'Graham Hill'}, {'url': 'https://en.wikipedia.org/wiki/Guenther_Steiner', 'title': 'Guenther Steiner'}, {'url': 'https://en.wikipedia.org/wiki/Guillaume_Rocquelin', 'title': 'Guillaume Rocquelin'}, {'url': 'https://en.wikipedia.org/wiki/Hannah_Schmitz', 'title': 'Hannah Schmitz'}, {'url': 'https://en.wikipedia.org/wiki/Harvey_Postlethwaite', 'title': 'Harvey Postlethwaite'}, {'url': 'https://en.wikipedia.org/wiki/Helmut_Marko', 'title': 'Helmut Marko'}, {'url': 'https://en.wikipedia.org/wiki/Hugh_Bird', 'title': 'Hugh Bird'}, {'url': 'https://en.wikipedia.org/wiki/Huub_Rothengatter', 'title': 'Huub Rothengatter'}, {'url': 'https://en.wikipedia.org/wiki/Isack_Hadjar', 'title': 'Isack Hadjar'}, {'url': 'https://en.wikipedia.org/wiki/Jack_Brabham', 'title': 'Jack Brabham'}, {'url': 'https://en.wikipedia.org/wiki/Jackie_Stewart', 'title': 'Jackie Stewart'}, {'url': 'https://en.wikipedia.org/wiki/Jacky_Eeckelaert', 'title': 'Jacky Eeckelaert'}, {'url': 'https://en.wikipedia.org/wiki/Jacques_Villeneuve', 'title': 'Jacques Villeneuve'}, {'url': 'https://en.wikipedia.org/wiki/Jaime_Alguersuari', 'title': 'Jaime Alguersuari'}, {'url': 'https://en.wikipedia.org/wiki/Jak_Crawford', 'title': 'Jak Crawford'}, {'url': 'https://en.wikipedia.org/wiki/James_Hunt', 'title': 'James Hunt'}, {'url': 'https://en.wikipedia.org/wiki/Jan_Flinterman', 'title': 'Jan Flinterman'}, {'url': 'https://en.wikipedia.org/wiki/Jan_Lammers', 'title': 'Jan Lammers'}, {'url': 'https://en.wikipedia.org/wiki/Jean-Éric_Vergne', 'title': 'Jean-Éric Vergne'}, {'url': 'https://en.wikipedia.org/wiki/Jean_Alesi', 'title': 'Jean Alesi'}, {'url': 'https://en.wikipedia.org/wiki/Jenson_Button', 'title': 'Jenson Button'}, {'url': 'https://en.wikipedia.org/wiki/Jim_Clark', 'title': 'Jim Clark'}, {'url': 'https://en.wikipedia.org/wiki/Jo_Schlesser', 'title': 'Jo Schlesser'}, {'url': 'https://en.wikipedia.org/wiki/Jochen_Rindt', 'title': 'Jochen Rindt'}, {'url': 'https://en.wikipedia.org/wiki/Jock_Clear', 'title': 'Jock Clear'}, {'url': 'https://en.wikipedia.org/wiki/Jody_Egginton', 'title': 'Jody Egginton'}, {'url': 'https://en.wikipedia.org/wiki/Jody_Scheckter', 'title': 'Jody Scheckter'}, {'url': 'https://en.wikipedia.org/wiki/John_Surtees', 'title': 'John Surtees'}, {'url': 'https://en.wikipedia.org/wiki/Jolyon_Palmer', 'title': 'Jolyon Palmer'}, {'url': 'https://en.wikipedia.org/wiki/Jonathan_Cochet', 'title': 'Jonathan Cochet'}, {'url': 'https://en.wikipedia.org/wiki/Jonathan_Eddolls', 'title': 'Jonathan Eddolls'}, {'url': 'https://en.wikipedia.org/wiki/Jonathan_Wheatley', 'title': 'Jonathan Wheatley'}, {'url': 'https://en.wikipedia.org/wiki/Jos_Verstappen', 'title': 'Jos Verstappen'}, {'url': 'https://en.wikipedia.org/wiki/Jules_Bianchi', 'title': 'Jules Bianchi'}, {'url': 'https://en.wikipedia.org/wiki/Jörg_Zander', 'title': 'Jörg Zander'}, {'url': 'https://en.wikipedia.org/wiki/Karun_Chandhok', 'title': 'Karun Chandhok'}, {'url': 'https://en.wikipedia.org/wiki/Keke_Rosberg', 'title': 'Keke Rosberg'}, {'url': 'https://en.wikipedia.org/wiki/Kelly_Piquet', 'title': 'Kelly Piquet'}, {'url': 'https://en.wikipedia.org/wiki/Kevin_Magnussen', 'title': 'Kevin Magnussen'}, {'url': 'https://en.wikipedia.org/wiki/Kimi_Räikkönen', 'title': 'Kimi Räikkönen'}, {'url': 'https://en.wikipedia.org/wiki/Kurt_Mollekens', 'title': 'Kurt Mollekens'}, {'url': 'https://en.wikipedia.org/wiki/Lance_Armstrong', 'title': 'Lance Armstrong'}, {'url': 'https://en.wikipedia.org/wiki/Lance_Stroll', 'title': 'Lance Stroll'}, {'url': 'https://en.wikipedia.org/wiki/Lando_Norris', 'title': 'Lando Norris'}, {'url': 'https://en.wikipedia.org/wiki/Laurent_Mekies', 'title': 'Laurent Mekies'}, {'url': 'https://en.wikipedia.org/wiki/Lewis_Hamilton', 'title': 'Lewis Hamilton'}, {'url': 'https://en.wikipedia.org/wiki/Liam_Lawson', 'title': 'Liam Lawson'}]\n",
            "select_random_people: 5\n",
            "[{'title': 'Jenson Button',\n",
            "  'url': 'https://en.wikipedia.org/wiki/Jenson_Button'},\n",
            " {'title': 'Ciaron Pilbeam',\n",
            "  'url': 'https://en.wikipedia.org/wiki/Ciaron_Pilbeam'},\n",
            " {'title': 'Kurt Mollekens',\n",
            "  'url': 'https://en.wikipedia.org/wiki/Kurt_Mollekens'},\n",
            " {'title': 'Jonathan Wheatley',\n",
            "  'url': 'https://en.wikipedia.org/wiki/Jonathan_Wheatley'},\n",
            " {'title': 'Lance Stroll', 'url': 'https://en.wikipedia.org/wiki/Lance_Stroll'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#for person\\ncat_ranking_person = get_categories(person_questions_dict)\\n#pprint.pprint(cat_ranking_person, indent=1)\\ncat_with_pv_person = get_pageviews_for_categories(cat_ranking_person)\\n#pprint.pprint(cat_with_pv_person, indent=1)\\n#for person: sorting the dict after pages per category\\ncategories_with_subs_and_pageviews_person = get_dict_for_every_location(cat_ranking_person, cat_with_pv_person)\\n#pprint.pprint(categories_with_subs_and_pageviews_person,indent=1)\\nnew_ordered_dict_person = sorting_dict(categories_with_subs_and_pageviews_person)\\n#pprint.pprint(new_ordered_dict_person,indent=1)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Function to :\n",
        "\n",
        "1. retrieve all of the related links of a wiki-persons-page (first 500);\n",
        "2. pre prune the list, such that only entries with 2 words in the title are left; (for performance reasons)\n",
        "3. analyse the links that are left via wikipedia APi and the \"instance of\" (P31) property set to \"human\" (Q5)\n",
        "4. now we have a list of related people to compare to our answer-person-entity\n",
        "\n",
        "5. retrieve the categories of those related people as done above with the answer_entities\n",
        "6. compare the categories and list the ones that appear in most often\n",
        "7. look for the \"unexpected\"\n",
        "\"\"\"\n",
        "\n",
        "wiki_link = 'https://en.wikipedia.org/wiki/'\n",
        "\n",
        "\n",
        "def unexpected_categories(person_answer_entity_list):\n",
        "  wiki_link_list={}\n",
        "  for val in person_answer_entity_list:\n",
        "    names_underscores = val.replace(' ', '_')\n",
        "    answer_entity_wiki_link = wiki_link + names_underscores\n",
        "    wiki_link_list[val] =  answer_entity_wiki_link\n",
        "  \n",
        "  categories = get_categories(wiki_link_list)\n",
        "  categories_with_pv = get_pageviews_for_categories(categories)\n",
        "  categories_with_subs_pvs = get_dict_for_every_location(categories, categories_with_pv)\n",
        "\n",
        "  test1 = check_inner_tuple_length(categories_with_subs_pvs )\n",
        "  test2 = prune_and_ordered_dict(test1, 20)\n",
        "  ordered_categories_dict_AnswerPeopleEntities = sorting_dict(test2)\n",
        "  #up to this point, the function retrieves,pre-prunes and orderes the most popular categories from the person-answer-entities\n",
        "  #now wee need to do the same for each of the selected_related_people_list, to then compare the categories and rank them from most to least occuring\n",
        "\n",
        "  return(ordered_categories_dict_AnswerPeopleEntities)\n",
        "\n",
        "def related_people_with_categories(categs_list):\n",
        "  selected_people = {}\n",
        "  selected_people_with_categories = {}\n",
        "  for key, value in categs_list.items():\n",
        "    names_underscores = key.replace(' ', '_')\n",
        "    related_articles = get_related_links(wiki_link + names_underscores)\n",
        "    filtered_links = filter_two_word_titles(related_articles)\n",
        "    related_people_list = check_if_person(filtered_links)\n",
        "    select_random_people = select_random_entries(related_people_list)\n",
        "\n",
        "    selected_people[key] = select_random_people\n",
        "\n",
        "  for key, value in selected_people.items():\n",
        "    for title, url in value.items():\n",
        "\n",
        "      selected_people_with_categories[key] = get_categories\n",
        "\n",
        "  return selected_people\n",
        "    # now calculate the most popukar categories of the selected_people and compare them\n",
        "\n",
        "  # print(wiki_link_list)  \n",
        "\n",
        "person_answer_entity_list = list(person_df['Answer'])\n",
        "#print(person_answer_entity_list)\n",
        "#unexpected_categories(person_answer_entity_list)\n",
        "#print(unexpected_categories(person_answer_entity_list))\n",
        "a = unexpected_categories(person_answer_entity_list)\n",
        "pprint.pprint(unexpected_categories(person_answer_entity_list))\n",
        "b = related_people_with_categories(a)\n",
        "pprint.pprint(b)\n",
        "#print(person_questions_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd4AeTR_KPir",
        "outputId": "373773e6-53cf-44e8-e6ce-61517b900040"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Joe Biden': OrderedDict([('https://en.wikipedia.org/wiki/Category:American_people_of_Irish_descent',\n",
            "                            (100, 0, 32705)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:American_people_of_English_descent',\n",
            "                            (100, 0, 22035)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Presidents_of_the_United_States',\n",
            "                            (100, 0, 18140)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:American_Roman_Catholics',\n",
            "                            (100, 0, 14103)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Presidential_Medal_of_Freedom_recipients',\n",
            "                            (100, 0, 10987)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:20th-century_American_politicians',\n",
            "                            (100, 0, 8176)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:American_people_of_French_descent',\n",
            "                            (100, 0, 7338)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:20th-century_American_lawyers',\n",
            "                            (100, 0, 5755)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:People_appearing_on_C-SPAN',\n",
            "                            (100, 0, 4536)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Transgender_rights_activists',\n",
            "                            (100, 0, 4510)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:21st-century_Roman_Catholics',\n",
            "                            (100, 0, 2832)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:People_involved_in_plagiarism_controversies',\n",
            "                            (100, 0, 2801)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Public_defenders',\n",
            "                            (100, 0, 1468)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:20th-century_Roman_Catholics',\n",
            "                            (100, 0, 1405)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Candidates_in_the_2020_United_States_presidential_election',\n",
            "                            (100, 0, 803)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:21st-century_American_memoirists',\n",
            "                            (100, 0, 769)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Catholics_from_Pennsylvania',\n",
            "                            (100, 0, 680)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:People_from_Wilmington,_Delaware',\n",
            "                            (100, 0, 452)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Recipients_of_the_Order_of_the_Cross_of_Terra_Mariana,_1st_Class',\n",
            "                            (100, 0, 405)),\n",
            "                           ('https://en.wikipedia.org/wiki/Category:Delaware_lawyers',\n",
            "                            (100, 0, 214))]),\n",
            " 'Max Verstappen': OrderedDict([('https://en.wikipedia.org/wiki/Category:Twitch_(service)_streamers',\n",
            "                                 (100, 0, 14054)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Officers_of_the_Order_of_Orange-Nassau',\n",
            "                                 (100, 0, 3055)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Dutch_Formula_One_drivers',\n",
            "                                 (20, 0, 1715)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Dutch_racing_drivers',\n",
            "                                 (100, 0, 1714)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Belgian_racing_drivers',\n",
            "                                 (100, 0, 1271)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Formula_One_race_winners',\n",
            "                                 (100, 0, 1111)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Red_Bull_Formula_One_drivers',\n",
            "                                 (12, 0, 1012)),\n",
            "                                (\"https://en.wikipedia.org/wiki/Category:Formula_One_World_Drivers'_Champions\",\n",
            "                                 (35, 0, 950)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Karting_World_Championship_drivers',\n",
            "                                 (100, 0, 808)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Dutch_people_of_Belgian_descent',\n",
            "                                 (18, 0, 255)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Toro_Rosso_Formula_One_drivers',\n",
            "                                 (14, 0, 244)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Belgian_people_of_Dutch_descent',\n",
            "                                 (15, 0, 220)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Belgian_expatriates_in_Monaco',\n",
            "                                 (10, 0, 197)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:FIA_Formula_3_European_Championship_drivers',\n",
            "                                 (100, 0, 163)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Motopark_Academy_drivers',\n",
            "                                 (100, 0, 140)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Van_Amersfoort_Racing_drivers',\n",
            "                                 (97, 0, 119)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Sportspeople_from_Hasselt',\n",
            "                                 (64, 0, 66)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Dutch_expatriate_sportspeople_in_Monaco',\n",
            "                                 (8, 0, 48)),\n",
            "                                ('https://en.wikipedia.org/wiki/Category:Max_Verstappen',\n",
            "                                 (2, 0, 0))]),\n",
            " 'Michael Jackson': OrderedDict([('https://en.wikipedia.org/wiki/Category:American_male_singers',\n",
            "                                  (100, 0, 30303)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_male_singers',\n",
            "                                  (100, 0, 20314)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_male_pop_singers',\n",
            "                                  (100, 0, 17599)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:21st-century_American_singers',\n",
            "                                  (100, 0, 12476)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_child_singers',\n",
            "                                  (100, 0, 11895)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_philanthropists',\n",
            "                                  (100, 0, 10318)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:20th-century_American_singers',\n",
            "                                  (100, 0, 9318)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:20th-century_American_businesspeople',\n",
            "                                  (100, 0, 7750)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:21st-century_American_businesspeople',\n",
            "                                  (100, 0, 6818)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_male_songwriters',\n",
            "                                  (100, 0, 4813)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_male_dancers',\n",
            "                                  (100, 0, 2787)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_humanitarians',\n",
            "                                  (100, 0, 1966)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_businesspeople',\n",
            "                                  (100, 0, 1909)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_male_dancers',\n",
            "                                  (100, 0, 1870)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_multi-instrumentalists',\n",
            "                                  (100, 0, 1754)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_songwriters',\n",
            "                                  (100, 0, 1739)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_choreographers',\n",
            "                                  (100, 0, 1721)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_dance_musicians',\n",
            "                                  (100, 0, 1689)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:African-American_record_producers',\n",
            "                                  (100, 0, 1656)),\n",
            "                                 ('https://en.wikipedia.org/wiki/Category:American_funk_singers',\n",
            "                                  (100, 0, 676))])}\n",
            "{'Joe Biden': [{'title': 'Alexander Haig',\n",
            "                'url': 'https://en.wikipedia.org/wiki/Alexander_Haig'},\n",
            "               {'title': 'Anita Hill',\n",
            "                'url': 'https://en.wikipedia.org/wiki/Anita_Hill'},\n",
            "               {'title': 'Bob Corker',\n",
            "                'url': 'https://en.wikipedia.org/wiki/Bob_Corker'},\n",
            "               {'title': 'Bashar al-Assad',\n",
            "                'url': 'https://en.wikipedia.org/wiki/Bashar_al-Assad'},\n",
            "               {'title': 'Adolf Hitler',\n",
            "                'url': 'https://en.wikipedia.org/wiki/Adolf_Hitler'}],\n",
            " 'Max Verstappen': [{'title': 'Anthony Kumpen',\n",
            "                     'url': 'https://en.wikipedia.org/wiki/Anthony_Kumpen'},\n",
            "                    {'title': 'Christijan Albers',\n",
            "                     'url': 'https://en.wikipedia.org/wiki/Christijan_Albers'},\n",
            "                    {'title': 'Jenson Button',\n",
            "                     'url': 'https://en.wikipedia.org/wiki/Jenson_Button'},\n",
            "                    {'title': 'Fernando Alonso',\n",
            "                     'url': 'https://en.wikipedia.org/wiki/Fernando_Alonso'},\n",
            "                    {'title': 'Giuseppe Farina',\n",
            "                     'url': 'https://en.wikipedia.org/wiki/Giuseppe_Farina'}],\n",
            " 'Michael Jackson': [{'title': 'Christopher Walken',\n",
            "                      'url': 'https://en.wikipedia.org/wiki/Christopher_Walken'},\n",
            "                     {'title': 'Chester Thompson',\n",
            "                      'url': 'https://en.wikipedia.org/wiki/Chester_Thompson'},\n",
            "                     {'title': 'David Foster',\n",
            "                      'url': 'https://en.wikipedia.org/wiki/David_Foster'},\n",
            "                     {'title': 'David Bowie',\n",
            "                      'url': 'https://en.wikipedia.org/wiki/David_Bowie'},\n",
            "                     {'title': 'Brody Brown',\n",
            "                      'url': 'https://en.wikipedia.org/wiki/Brody_Brown'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_inner_tuple_length(pv_and_pages_dict):\n",
        "  # Iterate over the dictionary\n",
        "  for key, value in pv_and_pages_dict.items():\n",
        "    # Iterate over the ordered dict values\n",
        "    for inner_key, inner_value in value.items():\n",
        "      # Check if the inner tuple has two elements\n",
        "      if len(inner_value) == 2:\n",
        "        # Update the value by adding a zero at the end\n",
        "        value[inner_key] = inner_value + (0,)\n",
        "  return pv_and_pages_dict\n",
        "\n",
        "#test1 = check_inner_tuple_length(copy_categories_with_subs_and_pageviews_person )\n",
        "#test2 = prune_and_ordered_dict(test1, 20)\n",
        "#test3 = sorting_dict(test2)\n",
        "#pprint.pprint(test3)\n",
        "\n"
      ],
      "metadata": {
        "id": "Myn24eiZlHv5"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Old predictions methods**"
      ],
      "metadata": {
        "id": "bp5WmYAKw6Mn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du5Un8VufnlG"
      },
      "source": [
        "## Functions for reuse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o8t6UzdAaKj"
      },
      "source": [
        "#get Wikidata ID\n",
        "def getQitemOfName(entity):\n",
        "  \n",
        "  searched = \"'\"+entity+\"'\"\n",
        "  sparql.setQuery('''\n",
        "  SELECT ?item ?itemLabel WHERE {\n",
        "    ?item rdfs:label '''+searched+'''@en.\n",
        "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
        "\n",
        "  }\n",
        "  ''')\n",
        "  \n",
        "  sparql.setReturnFormat(JSON)\n",
        "  entities = sparql.query().convert()\n",
        "  entities_df = pd.json_normalize(entities['results']['bindings'])\n",
        "  words = entities_df[[\"item.value\"]].iloc[0].str.split(\"/\")[0]\n",
        "  return words[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4tNPxs6Cp8f"
      },
      "source": [
        "#get name of entity from Wikidata ID\n",
        "\n",
        "def getLabelOfQitems(entities):\n",
        "\n",
        "  finalLabels = []\n",
        "  for item in entities:\n",
        "    #searched = \"'\"+item+\"'\"\n",
        "    sparql.setQuery('''\n",
        "    SELECT * WHERE {\n",
        "        wd:'''+item+ ''' rdfs:label ?label .\n",
        "        FILTER (langMatches( lang(?label), \"EN\" ) )\n",
        "    } LIMIT 1\n",
        "    ''')\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    entities = sparql.query().convert()\n",
        "    entities_df = pd.json_normalize(entities['results']['bindings'])\n",
        "    label = entities_df[\"label.value\"].iloc[0]\n",
        "    finalLabels.append(label)\n",
        "\n",
        "  return finalLabels  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK0zkvbXxRpU"
      },
      "source": [
        "#function to get all backlinks to wikipage and saves backlinks >= 1000 in array\n",
        "#source: https://www.mediawiki.org/wiki/API:Backlinks#Response\n",
        "\n",
        "import requests\n",
        "\n",
        "def getBacklinks(entities):\n",
        "  S = requests.Session()\n",
        "\n",
        "  URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "  listWithBacklink500 = []\n",
        "  dictWithAllEntries = {}\n",
        "\n",
        "  for val in entities:\n",
        "    #print(row[\"itemLabel.value\"])\n",
        "    PARAMS = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"list\": \"backlinks\",\n",
        "        \"bltitle\": val,\n",
        "        \"bllimit\": \"max\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "      R = S.get(url=URL, params=PARAMS)\n",
        "      DATA = R.json()\n",
        "   \n",
        "\n",
        "      BACKLINKS = DATA[\"query\"][\"backlinks\"]\n",
        "\n",
        "      count = 0\n",
        "      for links in BACKLINKS:\n",
        "        count +=1\n",
        "\n",
        "      \n",
        "      while \"continue\" in DATA:\n",
        "        if (count >= 1000):\n",
        "          break;\n",
        "        blcontinue = DATA[\"continue\"][\"blcontinue\"]\n",
        "        PARAMS[\"blcontinue\"] = blcontinue\n",
        "\n",
        "        R = S.get(url=URL, params=PARAMS)\n",
        "        DATA = R.json()\n",
        "        BACKLINKS = DATA[\"query\"][\"backlinks\"]\n",
        "\n",
        "        for links in BACKLINKS:\n",
        "          count += 1\n",
        "      \n",
        "      dictWithAllEntries[val] = count\n",
        "      #print(val + \": \" + str(count))\n",
        "\n",
        "    except ValueError:\n",
        "      print(\"Value Error\")\n",
        "\n",
        "    if (count >= 1000):\n",
        "      listWithBacklink500.append(val) \n",
        "\n",
        "  if (len(listWithBacklink500) > 0):\n",
        "    #return getPageViews(listWithBacklink500)\n",
        "    return listWithBacklink500\n",
        "\n",
        "  else:\n",
        "    listMostBacklinks = []\n",
        "    sortedDict = dict(sorted(dictWithAllEntries.items(), key=lambda item:item[1]))\n",
        "\n",
        "    for k, v in sortedDict.items():\n",
        "      listMostBacklinks.append(k)\n",
        "    \n",
        "    numberToPass = len(listMostBacklinks)//3\n",
        "        \n",
        "    return listMostBacklinks[-numberToPass:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-0fPfmxUZSW"
      },
      "source": [
        "#function to get all backlinks to wikipage and saves backlink == 500 in array\n",
        "#source: https://www.mediawiki.org/wiki/API:Backlinks#Response\n",
        "\n",
        "import requests\n",
        "\n",
        "def getBacklinksDict(entities):\n",
        "  S = requests.Session()\n",
        "\n",
        "  URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "  dictWithBacklink500 = {}\n",
        "  dictWithAllEntries = {}\n",
        "\n",
        "  for key, val in entities.items():\n",
        "    print(key, val)\n",
        "\n",
        "    PARAMS = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"list\": \"backlinks\",\n",
        "        \"bltitle\": key,\n",
        "        \"bllimit\": \"max\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "      R = S.get(url=URL, params=PARAMS)\n",
        "      DATA = R.json()\n",
        "   \n",
        "\n",
        "      BACKLINKS = DATA[\"query\"][\"backlinks\"]\n",
        "\n",
        "      count = 0\n",
        "      for links in BACKLINKS:\n",
        "        count +=1\n",
        "\n",
        "      \n",
        "      while \"continue\" in DATA:\n",
        "        if (count >= 1000):\n",
        "          break;\n",
        "        blcontinue = DATA[\"continue\"][\"blcontinue\"]\n",
        "        PARAMS[\"blcontinue\"] = blcontinue\n",
        "\n",
        "        R = S.get(url=URL, params=PARAMS)\n",
        "        DATA = R.json()\n",
        "        BACKLINKS = DATA[\"query\"][\"backlinks\"]\n",
        "\n",
        "        for links in BACKLINKS:\n",
        "          count += 1\n",
        "      \n",
        "      dictWithAllEntries[key] = count\n",
        "      #print(val + \": \" + str(count))\n",
        "\n",
        "    except ValueError:\n",
        "      print(\"Value Error\")\n",
        "    except KeyError:\n",
        "      print(\"Key Error\")\n",
        "\n",
        "    if (count >= 1000):\n",
        "      dictWithBacklink500.update({key: val}) \n",
        "\n",
        "  if (len(dictWithBacklink500) > 0):\n",
        "    #return getPageViews(listWithBacklink500)\n",
        "    return dictWithBacklink500\n",
        "\n",
        "    #print(listMostBacklinks[-numberToPass:])\n",
        "\n",
        "    \n",
        "    return listMostBacklinks[-numberToPass:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz4SZXwl1j7d"
      },
      "source": [
        "#get avg pageViews of entities\n",
        "\n",
        "def getPageViewsList(listEntities):\n",
        "  avgDict = {}\n",
        "  \n",
        "  for val in listEntities:\n",
        "    try:\n",
        "      resp = pageviewapi.per_article('en.wikipedia', val, '20191106', '20201120', access='all-access', agent='all-agents', granularity='monthly')\n",
        "    #print(resp)\n",
        "      avgViews = 0\n",
        "      count = 0\n",
        "      for i in resp.get(\"items\"):\n",
        "        #print(i.get(\"views\"))\n",
        "        avgViews += i.get(\"views\")\n",
        "        count += 1\n",
        "      avgDict.update({val: avgViews//count})\n",
        "    except:\n",
        "      print(\"Page not found to check pageViews for page: \" + val)\n",
        "      \n",
        "  #return (max(avgDict, key=avgDict.get))\n",
        "  return avgDict\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhL5jdCN-NdY"
      },
      "source": [
        "#get avg pageViews of entity\n",
        "import pageviewapi\n",
        "\n",
        "\n",
        "def getPageViews(entity):\n",
        "  avgDict = {}\n",
        "  \n",
        "  try:\n",
        "    resp = pageviewapi.per_article('en.wikipedia', entity, '20191106', '20201120', access='all-access', agent='all-agents', granularity='monthly')\n",
        "\n",
        "    avgViews = 0\n",
        "    count = 0\n",
        "    for i in resp.get(\"items\"):\n",
        "      #print(i.get(\"views\"))\n",
        "      avgViews += i.get(\"views\")\n",
        "      count += 1\n",
        "\n",
        "    pageViews = avgViews//count\n",
        "    #avgDict.update({val: avgViews//count})\n",
        "\n",
        "    #return (max(avgDict, key=avgDict.get))\n",
        "    return pageViews\n",
        "  #print(resp)\n",
        "  except:\n",
        "    print(\"Page not found to check pageViews for page: \" + entity)\n",
        "    return -1\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if entity is a person\n",
        "#return list of persons\n",
        "\n",
        "def checkIfHuman(entity):\n",
        "\n",
        "  #listHumans = []\n",
        "\n",
        "  #for test in entity:\n",
        "    #print(item)\n",
        "  searched = \"'\"+entity+\"'\"\n",
        "\n",
        "  #print(searched)\n",
        "\n",
        "  try:\n",
        "\n",
        "    sparql.setQuery('''\n",
        "        SELECT distinct ?item ?itemLabel \n",
        "        WHERE{\n",
        "          ?item ?label '''+searched+'''.  \n",
        "          ?item wdt:P31 wd:Q5.\n",
        "          ?article schema:about ?item .\n",
        "          ?article schema:inLanguage \"en\" .\n",
        "          ?article schema:isPartOf <https://en.wikipedia.org/>.\t\n",
        "          SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }    \n",
        "        }\n",
        "    ''')\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    entities = sparql.query().convert()\n",
        "    entities_df = pd.json_normalize(entities['results']['bindings'])\n",
        "\n",
        "    #print(entities)\n",
        "    #print(entities_df[\"itemLabel.value\"].item())\n",
        "\n",
        "    #for index, row in entities_df.iterrows():\n",
        "    return entities_df[\"itemLabel.value\"].item()\n",
        "    \n",
        "    \n",
        "  except:\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "QHdp21OCwtgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOJJtksOgQYk"
      },
      "source": [
        "#if parantheses in entity -> remove\n",
        "\n",
        "def removeParanthesesDict(inputDict):\n",
        "\n",
        "  newDict = {}\n",
        "  for key, val in inputDict.items():\n",
        "    if ('(' in key):\n",
        "      newElem = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", key).rstrip()\n",
        "      newDict.update({newElem: val})\n",
        "    else:\n",
        "      newDict.update({key: val})\n",
        "\n",
        "  return newDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lhmuuUNQ__8"
      },
      "source": [
        "##Hints if answer is a Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-T2fLcTRD54"
      },
      "source": [
        "#Query with all properties to get data\n",
        "\n",
        "def allHintsLocation(entity):\n",
        "  sparql.setQuery('''\n",
        "  SELECT ?itemLabel ?property\n",
        "  WHERE\n",
        "  {  \n",
        "    VALUES ?property {wdt:P35 wdt:P30 wdt:P36 wdt:P610 wdt:P1082 wdt:P421 wdt:P38 wdt:P17 wdt:P1376 wdt:P131 wdt:P6 wdt:P1830 wdt:P47 wdt:P206 wdt:P37 wdt:P463 wdt:793}\n",
        "    wd:'''+entity+''' ?property ?item.\n",
        "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
        "  }\n",
        "  ''')\n",
        "  sparql.setReturnFormat(JSON)\n",
        "  hintsLocation = sparql.query().convert()\n",
        "\n",
        "  hintsLocation_df = pd.json_normalize(hintsLocation['results']['bindings'])\n",
        "\n",
        "  return hintsLocation_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co1A0iK-sery"
      },
      "source": [
        "#create template based hints\n",
        "\n",
        "def getFormatedHintsLocation(queryResults_df):\n",
        "  timeZone = []\n",
        "  isLocatedIn = []\n",
        "  ownerOf = []\n",
        "  shareBorder = []\n",
        "  bodyOfWater = []\n",
        "  languages = []\n",
        "  memberOf = []\n",
        "  significantEvents = []\n",
        "\n",
        "  listHintsLocation = []\n",
        "\n",
        "  searchString = \"http://www.wikidata.org/prop/direct/\"\n",
        "  \n",
        "  for index, row in queryResults_df.iterrows():\n",
        "    if(not location in row[\"itemLabel.value\"]):\n",
        "      if(row[\"property.value\"] == searchString + \"P35\"):\n",
        "        listHintsLocation.append(\"Head of state of searched country is \" + row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P30\"):\n",
        "        listHintsLocation.append(\"The searched location is on continent \" + row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P36\"):\n",
        "        listHintsLocation.append(\"The capital of searched country is \" + row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"\"):\n",
        "        listHintsLocation.append(\"The highest point in searched location is \" + row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P1082\"):\n",
        "        listHintsLocation.append(\"The searched location has a population of \" + row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P38\"):\n",
        "        listHintsLocation.append(\"Currency in searched location is \" + row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P17\"):\n",
        "        if(not location in row[\"itemLabel.value\"]):\n",
        "          listHintsLocation.append(\"The searched location is in country \"+ row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P1376\"):\n",
        "        listHintsLocation.append(\"The searched city is capital of \" + row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P131\"):\n",
        "        listHintsLocation.append(\"The searched location is located in \" + row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P6\"):\n",
        "        listHintsLocation.append(\"Head of government of searched location is \" + row[\"itemLabel.value\"])\n",
        "      \n",
        "      #if get multiple values save all in list and pick one afterwards\n",
        "      elif(row[\"property.value\"] == searchString + \"P1830\"):\n",
        "        if(not location in row[\"itemLabel.value\"]):\n",
        "          ownerOf.append(row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P47\"):\n",
        "        shareBorder.append(row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P206\"):\n",
        "        bodyOfWater.append(row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P37\"):\n",
        "        if(not location in row[\"itemLabel.value\"]):\n",
        "          languages.append(row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P421\"):\n",
        "        timeZone.append(row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P463\"):\n",
        "        memberOf.append(row[\"itemLabel.value\"])\n",
        "      elif(row[\"property.value\"] == searchString + \"P793\"):\n",
        "        if(not location in row[\"itemLabel.value\"]):\n",
        "          significantEvents.append(row[\"itemLabel.value\"])\n",
        "\n",
        "  #getting more than one result with one query, pick one for output\n",
        "  if(len(ownerOf) > 0):\n",
        "    listHintsLocation.append(\"The searched location is owner of \" + ownerOf[0])\n",
        "  if(len(shareBorder) > 0):\n",
        "    listHintsLocation.append(\"The searched location shares border with \" + shareBorder[0])\n",
        "  if(len(bodyOfWater) > 0):\n",
        "    listHintsLocation.append(\"The next body of water of searched location is \" + bodyOfWater[0])\n",
        "  if(len(memberOf) > 0):\n",
        "    listBacklinks = getBacklinks(memberOf)\n",
        "    dictPageViews = getPageViewsList(listBacklinks)\n",
        "    listHintsLocation.append(\"Searched location is member of \" + (max(dictPageViews, key=dictPageViews.get)))\n",
        "  if(len(significantEvents) > 0):\n",
        "    listBacklinks = getBacklinks(significantEvents)\n",
        "    dictPageViews = getPageViewsList(listBacklinks)\n",
        "    listHintsLocation.append(\"A significant event happened in this location was \" + (max(dictPageViews, key=dictPageViews.get)))\n",
        "\n",
        "  #if getting more than one language concatenate all\n",
        "  commaCounter = len(languages)-1\n",
        "  stringLanguages = \"\"\n",
        "  for language in languages:\n",
        "    if(commaCounter > 0):\n",
        "      stringLanguages += language + \", \"\n",
        "      commaCounter -= 1\n",
        "    else:\n",
        "      stringLanguages += language\n",
        "  if(stringLanguages != \"\"):\n",
        "    listHintsLocation.append(\"Spoken language(s) in searched location is/are \" + stringLanguages)\n",
        "  if(len(timeZone) > 0):\n",
        "    listHintsLocation.append(\"The searched location is in time Zone \" + timeZone[0])\n",
        "\n",
        "  \n",
        "  return listHintsLocation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g65hUdVTRbXU"
      },
      "source": [
        "def writeLocationHintsInFile(listHintsLocation):\n",
        "  randomHintsList = random.sample(listHintsLocation, len(listHintsLocation))\n",
        "  \n",
        "  for item in randomHintsList:\n",
        "    with open(\"hintsLocation.txt\", 'a') as writefile:\n",
        "      writefile.write(item + \"\\n\")\n",
        "      writefile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yf6Fi_34ye5"
      },
      "source": [
        "##Hints if answer is a Person"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Query with all properties to get data\n",
        "\n",
        "def allHintsPerson(entity):\n",
        "  sparql.setQuery('''\n",
        "  SELECT ?itemLabel ?property\n",
        "  WHERE\n",
        "  {  \n",
        "    VALUES ?property {wdt:P21 wdt:P27 wdt:P569 wdt:P19 wdt:P1971 wdt:P106 wdt:P1340 wdt:P1884 wdt:P2048 wdt:P39 wdt:P69 wdt:P512 wdt:P102 wdt:P3602 wdt:P800 wdt:P166 wdt:P3373 wdt:P1412 wdt:P413 wdt:P118 wdt:P54}\n",
        "    wd:'''+entity+''' ?property ?item.\n",
        "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
        "  }\n",
        "  ''')\n",
        "  sparql.setReturnFormat(JSON)\n",
        "  hintsPerson = sparql.query().convert()\n",
        "\n",
        "  hintsPerson_df = pd.json_normalize(hintsPerson['results']['bindings'])\n",
        "  \n",
        "  return hintsPerson_df"
      ],
      "metadata": {
        "id": "Lm8zYu5C3xSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS1ZtKwL5hM-"
      },
      "source": [
        "#create temolate based hints\n",
        "\n",
        "def getFormatedHintsPerson(queryResults_df):\n",
        "\n",
        "  listOccupation = [\"Searched person was occuupied as \"]\n",
        "  listPositionHeld = [\"Searched person held the position(s) \"]\n",
        "  listEducatedAt = [\"Searched person was educated at \"]\n",
        "  listAcademicDegrees = [\"Searched person has academic degrees \"]\n",
        "  listPoliticParty = [\"Searched was/is member of politic party \"]\n",
        "  listCandidacyElection = [\"Searched person was candidacy at election(s) \"]\n",
        "  listNotableWork = [\"Searched person did notable work \"]\n",
        "  listAwardsReceived = [\"Searched person received awards \"]\n",
        "  listLanguages = [\"Searched person speaks language(s) \"]\n",
        "  listPlayedPositions = [\"Searched person played position \"]\n",
        "  listLeague = [\"Searched person played in leagues \"]\n",
        "  listTeams = [\"Searched person played in teams \"]\n",
        "  listCitizenship = [\"Searched person has following citizenships \"]\n",
        "  listSiblings = []\n",
        "  listHair = []\n",
        "\n",
        "  listHintsPerson = []\n",
        "\n",
        "  for index, row in queryResults_df.iterrows():\n",
        "    if(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P21\"):\n",
        "      listHintsPerson.append(\"Gender of searched person is \" + row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P569\"):\n",
        "      listHintsPerson.append(\"Searched person was born in \" + row[\"itemLabel.value\"][:4])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P19\"):\n",
        "      listHintsPerson.append(\"Searched person was born in \" + row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P1971\"):\n",
        "      listHintsPerson.append(\"Number of children of seared person is \" + row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P1340\"):\n",
        "      listHintsPerson.append(\"Searched person has \" + row[\"itemLabel.value\"] + \" eyes\")    \n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P2048\"):\n",
        "      listHintsPerson.append(\"Searched persons height is \" + row[\"itemLabel.value\"])    \n",
        "\n",
        "    \n",
        "    #if get multiple values save all in list and pick one afterwards\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P27\"):\n",
        "      listCitizenship.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P106\"):\n",
        "      listOccupation.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P39\"):\n",
        "      listPositionHeld.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P69\"):\n",
        "      listEducatedAt.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P512\"):\n",
        "      listAcademicDegrees.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P102\"):\n",
        "      listPoliticParty.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P3602\"):\n",
        "      listCandidacyElection.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P800\"):\n",
        "      listNotableWork.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P166\"):\n",
        "      listAwardsReceived.append(row[\"itemLabel.value\"])\n",
        "\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P1412\"):\n",
        "      listLanguages.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P413\"):\n",
        "      listPlayedPositions.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P118\"):\n",
        "      listLeague.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P54\"):\n",
        "      listTeams.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P3373\"):\n",
        "      listSiblings.append(row[\"itemLabel.value\"])\n",
        "    elif(row[\"property.value\"] == \"http://www.wikidata.org/prop/direct/P1884\"):\n",
        "      listHair.append(row[\"itemLabel.value\"])\n",
        "\n",
        "  #if too many results could be return check\n",
        "  #if more thane 3 -> cut\n",
        "  listResultsCut = [listPositionHeld, listAcademicDegrees, listPoliticParty, \n",
        "                 listCandidacyElection, listNotableWork, listLanguages, \n",
        "                 listPlayedPositions, listLeague, listTeams, listCitizenship, listAwardsReceived, listEducatedAt, listOccupation]\n",
        "  for singleList in listResultsCut:\n",
        "    cutResults(singleList, listHintsPerson)\n",
        "\n",
        "  #just get one hair color\n",
        "  if(len(listHair) > 0):\n",
        "    listHintsPerson.append(\"The searched person has \" + listHair[0])\n",
        "\n",
        "  #get number of siblings\n",
        "  if(len(listSiblings) > 0):\n",
        "    listHintsPerson.append(\"The searched person has \" + str(len(listSiblings)) + \" siblings\")  \n",
        "  \n",
        "  return listHintsPerson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if more results than 3 -> print 3 results + \"and x others\"\n",
        "\n",
        "def cutResults(listResults, listHintsPerson):\n",
        "  \n",
        "  numResults = len(listResults)-1\n",
        "  resultsLeft = numResults-3\n",
        "\n",
        "  if (len(listResults) > 1):\n",
        "    if(resultsLeft > 0):\n",
        "      listHintsPerson.append(getConcatenationMultipleResults(listResults[0:4])+ \" and \" + str(resultsLeft) + \" others\")\n",
        "    else:\n",
        "      listHintsPerson.append(getConcatenationMultipleResults(listResults))"
      ],
      "metadata": {
        "id": "KDP4yoRpB_Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIOq3XcwIr2a"
      },
      "source": [
        "#concatenate multiple results with comma\n",
        "\n",
        "def getConcatenationMultipleResults(resultList):\n",
        "  concatenation = \"\"\n",
        "  commaCounter = len(resultList)-1\n",
        "  for item in resultList:\n",
        "    if(commaCounter == len(resultList)-1):\n",
        "      concatenation += item\n",
        "      commaCounter-=1\n",
        "    elif(commaCounter > 0):\n",
        "      concatenation += item + \", \"\n",
        "      commaCounter-=1\n",
        "    elif(commaCounter == 0):\n",
        "      concatenation += item\n",
        "  \n",
        "  return concatenation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B74PSzscAzl8"
      },
      "source": [
        "def writePersonHintsInFile(listHintsPerson):\n",
        "  with open(\"hintsPerson.txt\", 'a') as writefile:\n",
        "    #writefile.write(\"\\n\\n---Hints for Person \" + person + \"---\\n\\n\")\n",
        "    randomHintsList = random.sample(listHintsPerson, len(listHintsPerson))\n",
        "    for item in randomHintsList:\n",
        "      writefile.write(item + \"\\n\")\n",
        "    writefile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LORwHLog-t_"
      },
      "source": [
        "## Hints if answer is a Year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dil5f183hhHJ"
      },
      "source": [
        "**Get all outlinks of wikipedia year page and pass to getBacklinks. Than look for return values on page.content and print line**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQFplu-7AF1L"
      },
      "source": [
        "import spacy\n",
        "def hintsYear(year):\n",
        "\n",
        "  page = wikipedia.page(year, auto_suggest=False)\n",
        "  pageContent = page.content\n",
        "\n",
        "  #get all links from year page\n",
        "  dictPageLinks = getOutlinks2(year)\n",
        "  #print(dictPageLinks)\n",
        "\n",
        "  #get rid of unnesercery links\n",
        "  filteredPageLinks = filterDict(dictPageLinks)\n",
        "\n",
        "  \n",
        "  #get backlinks of all links\n",
        "  dictBacklink = getBacklinksDict(filteredPageLinks)\n",
        "  #first200 = {k: filteredPageLinks[k] for k in list(filteredPageLinks)[:200]}\n",
        "  #dictBacklink = getBacklinksDict(first200)\n",
        "\n",
        "  #remove parantheses of links\n",
        "  dictAdjusted = removeParanthesesDict(dictBacklink)\n",
        "\n",
        "  #get all possible hint (all lines with a entity #backlinks > 1000)\n",
        "  dictPossibleHints = findLineInTextEvent(dictAdjusted, year)\n",
        "\n",
        "  with open('./resultsEvents.txt', 'a') as writefile:\n",
        "    writefile.write(\"Question: \" + questionYear + \"(\"+ str(year) + \")---\\n\")\n",
        "\n",
        "  #check if entity because of which line was found is subject\n",
        "  #if it is not the subject -> drop\n",
        "  dictFinalHints = getFinalHints(dictPossibleHints)\n",
        "\n",
        "  #get rid of number of foundevents at end of line\n",
        "  #need to put number at the and because it is dict and would be overwritten\n",
        "  dictFinalHintsAdjusted = {}\n",
        "  for key, val in dictFinalHints.items():\n",
        "    dictFinalHintsAdjusted.update({key.split('///', 1)[0]: val})  \n",
        "\n",
        "  #returns dict sorted after PageViews\n",
        "  dictSortedPV = sortHintsNumberPVSubject(dictFinalHintsAdjusted)\n",
        "\n",
        "  #get highest PageView\n",
        "  maxPV = list(dictSortedPV.values())[0]\n",
        "\n",
        "  #sort hints PageViews and Simscore combined\n",
        "  sortHintsUtilityScore(questionYear, dictSortedPV, maxPV)\n",
        "\n",
        "  listHumansNames = []\n",
        "\n",
        "  for key, val in dictAdjusted.items():\n",
        "    result = checkIfHuman(key)\n",
        "    if(result != None):\n",
        "      listHumansNames.append(result)\n",
        "\n",
        "  #findLineInTextBirthDeath(listHumansNames, year)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-dJk5vrhq6M"
      },
      "source": [
        "**Function to find line of most important link in year content**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0GonOTeikJm"
      },
      "source": [
        "import re\n",
        "\n",
        "def findLineInTextEvent(entitiesEvent, year):\n",
        "\n",
        "  page = wikipedia.page(year, auto_suggest=False)\n",
        "  pageText = page.content\n",
        "  splitText = []\n",
        "\n",
        "  splitText = (re.split(\"== Events ==|== Births ==\", pageText ))\n",
        "\n",
        "  contentEvents = splitText[1]\n",
        "\n",
        "  foundEvent = 0\n",
        "\n",
        "  dictHintsEntity = {}\n",
        "\n",
        "  for key, val in entitiesEvent.items():\n",
        "    #if (foundEvent == 20):\n",
        "      #break;\n",
        "\n",
        "    for line in contentEvents.split(\"\\n\"):\n",
        "      #if (foundEvent == 20):\n",
        "        #break;\n",
        "\n",
        "      if val in line:\n",
        "        words = line.split()\n",
        "        #counterEntitiesInLine = 0\n",
        "        if(len(words) < 15):\n",
        "          dictHintsEntity.update({line + \"///\" + str(foundEvent): val})\n",
        "          #listHints.append(line)\n",
        "          foundEvent += 1\n",
        "          #break;\n",
        "  return dictHintsEntity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZAM4MxB-8By"
      },
      "source": [
        "def findLineInTextBirthDeath(entitiesHuman, year):\n",
        "\n",
        "  page = wikipedia.page(year, auto_suggest=False)\n",
        "  pageText = page.content\n",
        "  splitText = []\n",
        "\n",
        "  splitText = (re.split(\"== Births ==|== Deaths ==\", pageText ))\n",
        "\n",
        "  print(splitText)\n",
        "\n",
        "  contentBirths = splitText[1]\n",
        "  contentDeaths = splitText[2]\n",
        "\n",
        "  foundBirth = 0\n",
        "  foundDeath = 0\n",
        "\n",
        "  #open file and append results\n",
        "  with open('./resultsBirthDeath.txt', 'a') as writefile:\n",
        "    writefile.write(\"---Birth/Death in year \" + str(year) + \"---\")\n",
        "\n",
        "    for entity in entitiesHuman:\n",
        "      #if (foundBirth == 3 and foundDeath == 3):\n",
        "        #writefile.write(\"\\n\")\n",
        "        #break;\n",
        "\n",
        "      for line in contentBirths.split(\"\\n\"):\n",
        "        #if (foundBirth == 3):\n",
        "          #break;\n",
        "\n",
        "        if entity in line:\n",
        "          writefile.write(\"Found with entity \" + entity + \"\\n\")\n",
        "          writefile.write(\"Birth: \" + line + \"\\n\")\n",
        "          writefile.write(\"\\n\")\n",
        "          foundBirth +=1\n",
        "          break;\n",
        "\n",
        "      for line in contentDeaths.split(\"\\n\"):\n",
        "        #if (foundDeath == 3):\n",
        "          #break;\n",
        "        if entity in line:\n",
        "          writefile.write(\"Found with entity \" + entity + \"\\n\")\n",
        "          writefile.write(\"Death: \" + line + \"\\n\")\n",
        "          writefile.write(\"\\n\")\n",
        "          foundDeath += 1\n",
        "          break;\n",
        "    writefile.write(\"\\n\")\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUy44eeb0EKg"
      },
      "source": [
        "def sortHintsNumberPVSubject(dictHints):\n",
        "\n",
        "  with open('./resultsEvents.txt', 'a') as writefile: \n",
        "\n",
        "    dictFinalHintsPV = {}\n",
        "\n",
        "    for key, val in dictHints.items():\n",
        "      dictFinalHintsPV.update({key: getPageViews(val)})\n",
        "\n",
        "    dictFinalHintsSortedPV = dict(sorted(dictFinalHintsPV.items(), key=lambda item: item[1], reverse=True))\n",
        "    \"\"\"writefile.write(\"\\n--Final Hints sorted #PV---\\n\")\n",
        "    for key, val in dictFinalHintsSortedPV.items():\n",
        "      writefile.write(key + \"(\" + str(val) + \" PageViews)\\n\")\"\"\"\n",
        "\n",
        "  return dictFinalHintsSortedPV\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4YpAjm5B6CM"
      },
      "source": [
        "\n",
        "\n",
        "def sortHintsUtilityScore(question, dictFinalHintsSortedPV, maxPV):\n",
        "  model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "  question_embedding = model.encode(question)\n",
        "\n",
        "  alpha = 0.5\n",
        "\n",
        "  #sentence_embeddings = model.encode(hints)\n",
        "\n",
        "  dictHintsBERT = {}\n",
        "\n",
        "  for key, val in dictFinalHintsSortedPV.items():\n",
        "    sentence_embedding = model.encode(key)\n",
        "    simScore = cosine_similarity([question_embedding], [sentence_embedding]).item()\n",
        "    impScore = alpha * (val/maxPV) + (1-alpha) * simScore\n",
        "    dictHintsBERT.update({key: impScore})\n",
        "\n",
        "  with open('./resultsEvents.txt', 'a') as writefile:\n",
        "\n",
        "    dictHintsBERT = dict(sorted(dictHintsBERT.items(), key=lambda item: item[1], reverse=True))\n",
        "    writefile.write(\"\\n--Final Hints sorted Utility Score---\\n\")\n",
        "    for key, val in dictHintsBERT.items():\n",
        "      writefile.write(key + \"(\" + str(val) + \" Utility Score)\\n\")\n",
        "\n",
        "  return dictHintsBERT\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxuRQ-FsZdQ_"
      },
      "source": [
        "def get_subject_phrase(doc):\n",
        "    for token in doc:\n",
        "        if (\"subj\" in token.dep_):\n",
        "            subtree = list(token.subtree)\n",
        "            start = subtree[0].i\n",
        "            end = subtree[-1].i + 1\n",
        "            return doc[start:end]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBif9Lc8_sg3"
      },
      "source": [
        "def getFinalHints(dictPossibleHints):\n",
        "\n",
        "  #nlp = spacy.load(\"en\")\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  dictFinalHintsSubject = {}\n",
        "  \n",
        "  for key, val in dictPossibleHints.items():\n",
        "    doc = nlp(key)\n",
        "    subject = get_subject_phrase(doc)\n",
        "    if (val in str(subject)):\n",
        "      dictFinalHintsSubject.update({key: val})\n",
        "      #listFinalHints.append(key)\n",
        "\n",
        "  return dictFinalHintsSubject"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JUt_0x6jD-x"
      },
      "source": [
        "\n",
        "def getOutlinks2(year):\n",
        "\n",
        "  URL = 'https://en.wikipedia.org/wiki/' + str(year)\n",
        "\n",
        "  # Fetch all the HTML source from the url\n",
        "  response = requests.get(URL)\n",
        "\n",
        "\n",
        "  soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "  listTextOfLinks = []\n",
        "  listLinks = []\n",
        "\n",
        "  dictLinkName = {}\n",
        "\n",
        "\n",
        "  for link in soup.find_all(\"a\"):\n",
        "    listTextOfLinks.append(link.get_text())\n",
        "    dictLinkName.update({str(link.get(\"href\")).split('/')[-1].replace('_', ' '): link.get_text()})\n",
        "\n",
        "  #newDict = filterDict(dictLinkName)\n",
        "\n",
        "  #print(len(dictLinkName))\n",
        "  #print(len(newDict))\n",
        "  #print(newDict)\n",
        "\n",
        "  return dictLinkName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAuFgVXomCdf"
      },
      "source": [
        "def filterDict(dictNameLink):\n",
        "\n",
        "  patternYear = r\"[1-3][0-9]{3}\"\n",
        "  patternCentury = r\"[1-2][0-9]\\w+.century\"\n",
        "  patternAd = r\"AD.\\d\\d\\d\\d\"\n",
        "  patternMonth = r\"[a-zA-Z]+\\s\\d+\"\n",
        "  patternMillennium = r\".+millennium\"\n",
        "  patternHashtag = r\"#\"\n",
        "  patternCalendar = r\"calendar\"\n",
        "  patternCategory = r\"category\"\n",
        "  patternList = r\"list\"\n",
        "  patternTemplate = r\"template\"\n",
        "  patternWikipedia = r\"wikipedia\"\n",
        "  patternIndex = r\"index\"\n",
        "  patternHtml = r\"html\"\n",
        "  patternPercent = r\"%\"\n",
        "\n",
        "  newDict = {}\n",
        "\n",
        "  for key, val in dictNameLink.items():\n",
        "    if(not re.match(patternYear, key) and\n",
        "       not re.match(patternCentury, key) and \n",
        "       not re.match(patternAd, key) and \n",
        "       not re.match(patternMonth, key) and\n",
        "       not re.search(patternHashtag, key) and\n",
        "       not re.search(patternCalendar, key, re.IGNORECASE) and\n",
        "       not re.search(patternCategory, key, re.IGNORECASE) and\n",
        "       not re.search(patternList, key, re.IGNORECASE) and\n",
        "       not re.search(patternTemplate, key, re.IGNORECASE) and\n",
        "       not re.search(patternWikipedia, key, re.IGNORECASE) and\n",
        "       not re.search(patternIndex, key, re.IGNORECASE) and\n",
        "       not re.search(patternHtml, key, re.IGNORECASE) and\n",
        "       not re.search(patternPercent, key) and\n",
        "       not re.match(patternMillennium, key) and\n",
        "       not val == \"\" and not val == \" \"):\n",
        "      \n",
        "\n",
        "      newDict.update({key: val})\n",
        "\n",
        "\n",
        "  print(newDict)\n",
        "\n",
        "  return newDict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call Functions\n"
      ],
      "metadata": {
        "id": "cxaEE5DFfr_v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA1ZDHtbAkJJ"
      },
      "source": [
        "**Call hint function for all questions where answer is Location**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kHh8TAEt6OS"
      },
      "source": [
        "for index, row in location_df.iterrows():\n",
        "  location = row[\"Answer\"]\n",
        "  questionLocation = row[\"Question\"]\n",
        "  with open(\"hintsLocation.txt\", 'a') as writefile:\n",
        "    writefile.write(\"\\n\\n\" + questionLocation + \" (\" + location + \")\\n\\n\")\n",
        "    writefile.close()\n",
        "\n",
        "\n",
        "  #get Wikidata ID for SPARQL-Query\n",
        "  locationQitem = getQitemOfName(location)\n",
        "\n",
        "  #execute SPARQL-Query\n",
        "  queryResults_df = allHintsLocation(locationQitem)\n",
        "\n",
        "  #getFinalHints\n",
        "  listHintsLocation = getFormatedHintsLocation(queryResults_df)    \n",
        "\n",
        "  #write hints in file in random order\n",
        "  writeLocationHintsInFile(listHintsLocation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYzskrP0AtKs"
      },
      "source": [
        "**Call hint function for all questions where answer is Person**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B__QLqKMAX51"
      },
      "source": [
        "\n",
        "for index, row in person_df.iterrows():\n",
        "  person = row[\"Answer\"]\n",
        "  questionPerson = row[\"Question\"]\n",
        "\n",
        "  with open(\"hintsPerson.txt\", 'a') as writefile:\n",
        "    writefile.write(\"\\n\\n\" + questionPerson + \" (\"+ person +\")\\n\\n\")\n",
        "    writefile.close()\n",
        "  \n",
        "  #get Wikipedia ID for SPARQL-Query\n",
        "  personQitem = getQitemOfName(person)\n",
        "\n",
        "  #execute SPARQL-Query\n",
        "  queryResults_df = allHintsPerson(personQitem)\n",
        "  \n",
        "  #get Final Hints\n",
        "  listHintsPerson = getFormatedHintsPerson(queryResults_df)\n",
        "\n",
        "  #write hints in file in random order\n",
        "  writePersonHintsInFile(listHintsPerson)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjsplvG5DUJn"
      },
      "source": [
        "**Call hint function for all question where answer is Year**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z5x7mjMDY-b"
      },
      "source": [
        "for index, row in year_df.iterrows():\n",
        "  year = row[\"Answer\"]\n",
        "  questionYear = row[\"Question\"]\n",
        "  hintsYear(row[\"Answer\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pageview Test Functions\n"
      ],
      "metadata": {
        "id": "GXcHCM1dcbai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import requests\n",
        "\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_table_info(url):\n",
        "    \"\"\"\n",
        "    Given a URL, this function opens the url and retrieves the information stored in a table.\n",
        "    \"\"\"\n",
        "    options = webdriver.FirefoxOptions()\n",
        "    #options.headless = True\n",
        "    options.add_argument('--headless')\n",
        "\n",
        "    driver = webdriver.Firefox(options=options)\n",
        "    driver.get(url)\n",
        "    time.sleep(3) # Wait for the page to load completely\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    driver.quit()\n",
        "    table = soup.find('table')\n",
        "    rows = table.find_all('tr')\n",
        "    headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
        "    data = []\n",
        "    for row in rows[1:]:\n",
        "        data.append([cell.text.strip() for cell in row.find_all('td')])\n",
        "    return (headers, data)\n",
        "\n",
        "def get_table_info_requests(url):\n",
        "    \"\"\"\n",
        "    Given a URL, this function opens the url and retrieves the information stored in a table.\n",
        "    \"\"\"\n",
        "    headers = []\n",
        "    data = []\n",
        "\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    table = soup.find('table')\n",
        "    rows = table.find_all('tr')\n",
        "    headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
        "    data = []\n",
        "    for row in rows[1:]:\n",
        "        data.append([cell.text.strip() for cell in row.find_all('td')])\n",
        "\n",
        "    return (headers, data)\n",
        "\n",
        "def get_links_in_section(wikipedia_url, section_heading):\n",
        "    \"\"\"\n",
        "    Given a Wikipedia URL, and a section of this article, returns an array of dictionaries containing the href, title, and description of each link on that section of the page.\n",
        "    \"\"\"\n",
        "    response = requests.get(wikipedia_url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    section = soup.find('span', {'id': section_heading})\n",
        "    if section is None:\n",
        "        return None\n",
        "    section_content = section.parent.find_next_sibling('ul')\n",
        "    if section_content is None:\n",
        "        return None\n",
        "    links = []\n",
        "    for item in section_content.find_all('li'):\n",
        "        link = item.find('a')\n",
        "        if link is not None and link.has_attr('href') and link['href'].startswith('/wiki/'):\n",
        "            #title = link.get('title', '')\n",
        "            title = link.get('title')\n",
        "            description = item.text.strip()\n",
        "            url = f\"https://en.wikipedia.org{link['href']}\"\n",
        "            links.append({'title': title, 'description': description, 'url': url})\n",
        "    #print(links)\n",
        "    return links\n",
        "\n",
        "def get_links_in_section_with_sublinks(wikipedia_url, section_title):\n",
        "    \"\"\"\n",
        "    Given a Wikipedia URL, and a section of this article, returns an array of dictionaries containing the href, title, and description of each link  with its sublinks as well.\n",
        "    \"\"\"\n",
        "    response = requests.get(wikipedia_url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        section_heading = soup.find('span', {'id': section_title})\n",
        "        if section_heading is None:\n",
        "            return None\n",
        "        section = section_heading.parent\n",
        "        section_content = section.find_next_sibling('ul')\n",
        "        if section_content is None:\n",
        "            return None\n",
        "        links = []\n",
        "        for item in section_content.find_all('li'):\n",
        "            link = item.find('a')\n",
        "            if link is not None:\n",
        "                link_title = link.get('title')\n",
        "                link_url = 'https://en.wikipedia.org' + link.get('href')\n",
        "                link_description = item.text.replace(link_title, '').strip()\n",
        "                links.append({'title': link_title, 'url': link_url, 'description': link_description})\n",
        "                for sublink in item.find_all('a', href=True, recursive=False):\n",
        "                    sublink_title = sublink.get('title')\n",
        "                    sublink_url = 'https://en.wikipedia.org' + sublink.get('href')\n",
        "                    sublink_description = sublink.parent.text.replace(sublink_title, '').replace(link_title, '').strip()\n",
        "                    links.append({'title': sublink_title, 'url': sublink_url, 'description': sublink_description})\n",
        "        return links\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def get_events_links(title):\n",
        "    \"\"\"\n",
        "    Gets all the links in the \"Events\" section of a Wikipedia page.\n",
        "    Returns a list of strings containing the URLs of each event.\n",
        "    \"\"\"\n",
        "    url = f\"https://en.wikipedia.org/w/api.php?action=parse&format=json&page={title}&prop=text\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    soup = BeautifulSoup(data['parse']['text']['*'], 'html.parser')\n",
        "    events_section = soup.find('span', {'class': 'mw-headline', 'id': 'Events'})\n",
        "    if events_section:\n",
        "        events_list = events_section.find_next('ul')\n",
        "        if events_list:\n",
        "            events = events_list.find_all('a')\n",
        "            event_links = [f\"https://en.wikipedia.org{event['href']}\" for event in events]\n",
        "            return event_links\n",
        "    return None\n",
        "\n",
        "def create_url_from_title(title):\n",
        "    \"\"\"\n",
        "    Given a list of dictionaries containing href, title, and description for each entry, extracts the title from each link and constructs a new URL using the title.\n",
        "    \"\"\"\n",
        "    urls = []\n",
        "    if title != None: \n",
        "      # Replace spaces with underscores in the title\n",
        "      title = title.replace(' ', '_')\n",
        "\n",
        "      # Construct a new URL using the title\n",
        "      url = 'https://pageviews.wmcloud.org/redirectviews/?project=en.wikipedia.org&platform=all-access&agent=user&range=all-time&sort=views&direction=1&view=list&page=' + title\n",
        "    return url\n",
        "\n",
        "def extract_visitorNumber_from_link(link):\n",
        "    \"\"\"\n",
        "    extract the first entry of the table\n",
        "    \"\"\"\n",
        "    headers, data = get_table_info(link)\n",
        "\n",
        "    try:\n",
        "      if data[1]: \n",
        "        return data[1][2]\n",
        "      else:\n",
        "        return 0\n",
        "    except IndexError:\n",
        "      print(\"Index out of range\")\n",
        "\n",
        "def get_visitor_numbers(pageviews_url):\n",
        "    \"\"\"\n",
        "    returns visitor numbers of the page\n",
        "    \"\"\"\n",
        "    response = requests.get(pageviews_url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()['items']\n",
        "        visitors = {}\n",
        "        for item in data:\n",
        "            visitors[item['timestamp']] = item['views']\n",
        "        return visitors\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "5VwT46tA0CZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST\n",
        "\n",
        "#Seitenaufrufe\n",
        "#url = 'https://pageviews.toolforge.org/?project=en.wikipedia.org&pages=Formula1|Michael_Schumacher'\n",
        "#headers, data = get_table_info(url)\n",
        "#print(headers)\n",
        "#print(data)\n",
        "\n",
        "#get all wiki links on a page -> discard the one we dont need -> analyse the ones that could be usefull -> sort them after the backlinks\n",
        "#print(get_events_links(2004))\n",
        "\n",
        "# Search the most popular births and deaths in that year and then order them \n",
        "url1 = 'https://en.wikipedia.org/wiki/Category:1994_births'\n",
        "url2 = 'https://en.wikipedia.org/wiki/Category:1994_deaths'\n",
        "url3 = 'https://en.wikipedia.org/wiki/1994#Events'\n",
        "\n",
        "#links_events_section = get_links_in_section_with_sublinks(url3, 'Events')\n",
        "#print(len(links_events_section))\n",
        "#print(links_events_section)\n",
        "#print(get_births(1994))\n",
        "\n",
        "#visitor number test\n",
        "link = 'https://pageviews.wmcloud.org/redirectviews/?project=en.wikipedia.org&platform=all-access&agent=user&range=all-time&sort=views&direction=1&view=list&page=North_American_Free_Trade_Agreement'\n",
        "#print(extract_visitorNumber_from_link(link))"
      ],
      "metadata": {
        "id": "dYFPOhzAVotw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#When did Michael Schumacher win his first F1 World Drivers Title? -> 1994\n",
        "#First 1994 is searched on wikipedia, then all the links from the event sections of that page are filtered and written into a dict together with their pageviews.\n",
        "#Now order these lists such that the entry with most pageviews is on top\n",
        "#THIS SHOULD WORK\n",
        "\n",
        "year=2004\n",
        "url = 'https://en.wikipedia.org/wiki/2004'\n",
        "\n",
        "links_events_section = get_links_in_section_with_sublinks(url, 'Events')\n",
        "print(len(links_events_section))\n",
        "\n",
        "for link in links_events_section:\n",
        "    t_title =  link.get('title') \n",
        "    t_url = create_url_from_title(t_title)\n",
        "    link[\"pageview_url\"] = t_url\n",
        "    link[\"pageviews\"] = extract_visitorNumber_from_link(t_url)\n",
        "\n",
        "#sort the list links_event_section after the pageviews such that the entity with the highest pageviews is first\n",
        "sorted_list = sorted(links_events_section, key=lambda x: int(x['pageviews'].replace(',', '')), reverse=True)"
      ],
      "metadata": {
        "id": "8hZTwIILMaNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pageview_test_generated_hints_for_years = sorted_list\n",
        "\n",
        "pprint.pprint(pageview_test_generated_hints_for_years, indent=4)"
      ],
      "metadata": {
        "id": "IGiGzaMzbF-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R87Y1LPF55PL"
      },
      "source": [
        "# Clean GitHub directory\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%rm -r optimizationOfHintGeneration\n",
        "%cd /content/\n",
        "%rm hintsLocation.txt\n",
        "%rm hintsPerson.txt\n",
        "%rm resultsEvents.txt"
      ],
      "metadata": {
        "id": "2cREJk4T5v7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b128899-c53b-48d3-abee-c718fa1eee98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n",
            "rm: cannot remove 'hintsLocation.txt': No such file or directory\n",
            "rm: cannot remove 'hintsPerson.txt': No such file or directory\n",
            "rm: cannot remove 'resultsEvents.txt': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}