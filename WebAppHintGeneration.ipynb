{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "de25mCzzkO3Z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexWalcher/automaticHintGeneration/blob/Test/WebAppHintGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##How to start the automatic hint generation - Streamlit WebApp:\n",
        "\n",
        "1. Run Deployment\n",
        "2. Follow the instructions to open the Streamlit-WebApp\n"
      ],
      "metadata": {
        "id": "sdufKBvPeQbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment**"
      ],
      "metadata": {
        "id": "z7i2AKZrkDO8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5rwSDisuN9s"
      },
      "source": [
        "## **All imports**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# This cell will not display any output\n",
        "%cd /content/\n",
        "%rm -r automaticHintGeneration\n",
        "!git clone https://github.com/AlexWalcher/automaticHintGeneration.git\n",
        "%cd /content/\n",
        "%cd /content/automaticHintGeneration\n",
        "%mkdir tmp\n",
        "%cd /content/automaticHintGeneration/"
      ],
      "metadata": {
        "id": "b_jGbTrbz8x2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# This cell will not display any output\n",
        "\n",
        "%cd /content/automaticHintGeneration/\n",
        "from automaticHintGenerationWebapp import *"
      ],
      "metadata": {
        "id": "8TMc-NqnwtsA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WebApp deployment"
      ],
      "metadata": {
        "id": "de25mCzzkO3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run both cells below. From the second cell you should get back a IP-address (like 123.456.789.101) and a URL (like https://cool-files-wonder.loca.lt/). Open the URL in your browser and enter the corresponding IP-address.\n",
        "After that, wait for a short bit until the page is loaded, which takes some time because of the large number of imports.\n",
        "\n",
        "---\n",
        "\n",
        "*Disclaimer: the functions from the Webapp take some time to load and execute; they are not stuck they just take a little bit longer*"
      ],
      "metadata": {
        "id": "72ZkFljISn5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run ./automaticHintGenerationWebapp.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "R4LXcgtlkO3g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "outputId": "5c04d34c-5dfb-4543-bcfd-33a3454e14ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAAsgXl9kO3g"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.172.41.217\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.934s\n",
            "your url is: https://cuddly-flies-wait.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "ApGJr6MBSJjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# countries_list = ['Afghan', 'Albanian', 'Algerian', 'Andorran', 'Angolan', 'Argentinian', 'Armenian', 'Australian', 'Austrian', 'Azerbaijani', 'Bahamian', 'Bahraini', 'Bangladeshi', 'Barbadian', 'Belarusian', 'Belgian', 'Belizean', 'Beninese', 'Bhutanese', 'Bolivian', 'Bosnian', 'Motswana', 'Brazilian', 'Bruneian', 'Bulgarian', 'Burkinabe', 'Burundian', 'Cambodian', 'Cameroonian', 'Canadian', 'Cape Verdean', 'Central African', 'Chadian', 'Chilean', 'Chinese', 'Colombian', 'Comorian', 'Congolese', 'Congolese', 'Costa Rican', 'Croatian', 'Cuban', 'Cypriot', 'Czech', 'Danish', 'Djiboutian', 'Dominican', 'Dominican', 'East Timorese', 'Ecuadorian', 'Egyptian', 'Salvadoran', 'Equatorial Guinean', 'Eritrean', 'Estonian', 'Swazi', 'Ethiopian', 'Fijian', 'Finnish', 'French', 'Gabonese', 'Gambian', 'Georgian', 'German', 'Ghanaian', 'Greek', 'Grenadian', 'Guatemalan', 'Guinean', 'Guinea-Bissauan', 'Guyanese', 'Haitian', 'Honduran', 'Hungarian', 'Icelander', 'Indian', 'Indonesian', 'Iranian', 'Iraqi', 'Irish', 'Israeli', 'Italian', 'Jamaican', 'Japanese', 'Jordanian', 'Kazakhstani', 'Kenyan', 'I-Kiribati', 'North Korean', 'South Korean', 'Kuwaiti', 'Kyrgyzstani', 'Laotian', 'Latvian', 'Lebanese', 'Basotho', 'Liberian', 'Libyan', 'Liechtensteiner', 'Lithuanian']\n",
        "countries_list = []\n",
        "#input searched location and returns a dict with number of pages and number of subcategories\n",
        "def get_categories_rankingg(searched_location):\n",
        "  categories = get_wikipedia_categories(searched_location)\n",
        "  categories_links = []\n",
        "  cat_without_articles = []\n",
        "  bad_list = ['Articles with', 'CS1', 'Wikipedia', 'Webarchive', 'Short', 'Biography', 'Commons', 'Pages', 'Use', 'All', 'Articles', 'Coordinates', 'Engvar', 'Lang', 'Official']\n",
        "  for c in categories:\n",
        "    if not any(c.startswith(word) for word in bad_list) and not any(c.startswith(word) for word in countries_list) :\n",
        "      cat_without_articles.append(c)\n",
        "  try:\n",
        "    categories_links = get_category_links(cat_without_articles)\n",
        "  except Exception as e:\n",
        "      pass\n",
        "  cat_with_amount = {}\n",
        "\n",
        "  for category in categories_links:\n",
        "    cat_with_amount[category] =  (0, 0)\n",
        "  sorted_dict = dict(sorted(cat_with_amount.items(), key=lambda x: x[1], reverse=True))\n",
        "  return sorted_dict"
      ],
      "metadata": {
        "id": "q7yfLqIkcK1l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# countries_list = ['Afghan', 'Albanian', 'Algerian', 'Andorran', 'Angolan', 'Argentinian', 'Armenian', 'Australian', 'Austrian', 'Azerbaijani', 'Bahamian', 'Bahraini', 'Bangladeshi', 'Barbadian', 'Belarusian', 'Belgian', 'Belizean', 'Beninese', 'Bhutanese', 'Bolivian', 'Bosnian', 'Motswana', 'Brazilian', 'Bruneian', 'Bulgarian', 'Burkinabe', 'Burundian', 'Cambodian', 'Cameroonian', 'Canadian', 'Cape Verdean', 'Central African', 'Chadian', 'Chilean', 'Chinese', 'Colombian', 'Comorian', 'Congolese', 'Congolese', 'Costa Rican', 'Croatian', 'Cuban', 'Cypriot', 'Czech', 'Danish', 'Djiboutian', 'Dominican', 'Dominican', 'East Timorese', 'Ecuadorian', 'Egyptian', 'Salvadoran', 'Equatorial Guinean', 'Eritrean', 'Estonian', 'Swazi', 'Ethiopian', 'Fijian', 'Finnish', 'French', 'Gabonese', 'Gambian', 'Georgian', 'German', 'Ghanaian', 'Greek', 'Grenadian', 'Guatemalan', 'Guinean', 'Guinea-Bissauan', 'Guyanese', 'Haitian', 'Honduran', 'Hungarian', 'Icelander', 'Indian', 'Indonesian', 'Iranian', 'Iraqi', 'Irish', 'Israeli', 'Italian', 'Jamaican', 'Japanese', 'Jordanian', 'Kazakhstani', 'Kenyan', 'I-Kiribati', 'North Korean', 'South Korean', 'Kuwaiti', 'Kyrgyzstani', 'Laotian', 'Latvian', 'Lebanese', 'Basotho', 'Liberian', 'Libyan', 'Liechtensteiner', 'Lithuanian']\n",
        "\n",
        "countries_list = []\n",
        "# function that takes a dictionary with an ordered dictionary as the value and prunes the ordered dictionary to keep only the first n entries and deltes certain categories:\n",
        "def prune_and_ordered_dict(dictionary, n):\n",
        "  pruned_dict = OrderedDict()\n",
        "  inter1_dict= OrderedDict()\n",
        "  # bad_categories_list = ['Living_people', 'Living people', '_births', 'births', '_deaths', 'deaths', 'Good_articles', 'Good articles', 'Members','19th', '20th', '21st', 'Capitals in Europe', 'state capitals']\n",
        "  bad_categories_list = ['Living_people', 'Living people', '_births', 'births', '_deaths', 'deaths', 'Good_articles', 'Good articles', 'Members','19th', 'Capitals in Europe', 'state capitals']\n",
        "\n",
        "  people_occupations = get_occupations(person_answers_dict)\n",
        "  print(\"occu\", people_occupations)\n",
        "  for key, value in dictionary.items():\n",
        "    inter3_dict= OrderedDict()\n",
        "    for link, tuplee in value.items():\n",
        "      link_str = str(link)\n",
        "      contains_bad_word = False\n",
        "      try:\n",
        "        for word in bad_categories_list:\n",
        "          if word in link_str:\n",
        "            contains_bad_word = True\n",
        "            continue\n",
        "        for word in countries_list:\n",
        "          if word in link_str:\n",
        "            contains_bad_word = True\n",
        "            continue\n",
        "        for name, val in people_occupations:\n",
        "          if key == name:\n",
        "            if val in link_str:\n",
        "              contains_bad_word = True\n",
        "              continue\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "      if contains_bad_word == False:\n",
        "        inter3_dict[link] = tuplee\n",
        "    pruned_dict[key] = inter3_dict\n",
        "  for key, value in pruned_dict.items():\n",
        "    inter1_dict[key] = OrderedDict(list(value.items())[:n])\n",
        "  return inter1_dict"
      ],
      "metadata": {
        "id": "SnXy540z3-kg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_sentence_person_list = ['The person you are looking for is/was occupied as 0 and a member of the category 1.']\n",
        "\n",
        "#takes the categories scores dict and chooses the category with the highest score\n",
        "def create_hint_sentences_unexCategs(categories_scores_dict, person_answers_dict):\n",
        "  people_occupations = get_occupations(person_answers_dict)\n",
        "  most_unexpected_categories_dict = {}\n",
        "  hint_sentence_unexCateg_dict = {}\n",
        "  try:\n",
        "    for key,value in categories_scores_dict.items():\n",
        "      categories_scores_dict[key] = OrderedDict(sorted(value.items(), key=lambda x: x[1], reverse=True))\n",
        "      most_unexpected_categories_dict[key] = (next(iter(value.items())), people_occupations[key])\n",
        "    occu_str = 'television_presenter'\n",
        "    pprint.pprint(categories_scores_dict)\n",
        "    pprint.pprint(most_unexpected_categories_dict)\n",
        "    for key,value in most_unexpected_categories_dict.items():\n",
        "      hint_sentence_unexCateg_dict[key] = []\n",
        "      try:\n",
        "        if people_occupations[key] == 'Racing':\n",
        "          occu_str = people_occupations[key]\n",
        "        else:\n",
        "          occu_str = people_occupations[key]\n",
        "      except Exception as e:\n",
        "        pass\n",
        "      for sentence in template_sentence_person_list:\n",
        "        hint_sentence_unexCateg_dict[key].append( sentence.replace('0', occu_str).replace('1', get_category_title(most_unexpected_categories_dict[key][0][0]).split(':')[-1].replace('_', ' ') ))\n",
        "  except Exception as e: print(e)\n",
        "  return hint_sentence_unexCateg_dict"
      ],
      "metadata": {
        "id": "n6TMd9G1TovU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/automaticHintGeneration/tmp/questionPerson.txt\"\n",
        "\n",
        "generated_hint_sentences = {}\n",
        "inter = read_properties_from_file(file_path)\n",
        "\n",
        "question = inter[0]\n",
        "answer = inter[1]\n",
        "\n",
        "print(\"question: \", question)\n",
        "print(\"answer: \", answer)\n",
        "# pprint.pprint(answer, question)\n",
        "\n",
        "person_answers_dict ={}\n",
        "person_answers_dict[answer] = question\n",
        "# dataPerson.append(person_questions_dict)\n",
        "# pprint.pprint(person_questions_dict)\n",
        "# people_hints_unexpected_categories = get_person_hints_unexpected_categories(person_questions_dict)\n",
        "\n",
        "related_people_dict = {}\n",
        "related_people_link_dict= {}\n",
        "related_people_pageviews_dict = {}\n",
        "most_popular_related_people_with_categories = {}\n",
        "#time saving for first part (related people recovery) 2m\n",
        "for key,value in person_answers_dict.items():\n",
        "  related_people_dict[key] = get_related_people_from_person_name(key)\n",
        "#time saving for second part (related peoples with pageviews and ordering) - 16m (6-7m)\n",
        "for key,value in related_people_dict.items():\n",
        "  inter_link_list = []\n",
        "  for item in value:\n",
        "    inter_link_list.append(item['url'])\n",
        "  related_people_link_dict[key] = inter_link_list\n",
        "  related_people_pageviews_dict = get_pageviews_from_links(related_people_link_dict)\n",
        "#time saving for third part (related peoples categories recovery and ordering) - 43m+ (14m-24m)\n",
        "most_popular_related_people_with_categories = get_categories_of_people_list(related_people_pageviews_dict)\n",
        "#time saving for third part retrieves the categories of the answer-entities - 9m+ (6m)\n",
        "answer_entities_with_categories = get_categories_with_pv_answerEntities(person_answers_dict)\n",
        "#time saving for fourth part counts the categories of the answer-entities - 3s\n",
        "counted_category_apperances = count_categories(most_popular_related_people_with_categories, answer_entities_with_categories)\n",
        "#just for the ordering of the inner list\n",
        "ordered_data = {}\n",
        "for key,value in counted_category_apperances.items():\n",
        "  tmp = OrderedDict(value)\n",
        "  ordered_data[key] = OrderedDict(sorted(tmp.items(), key=lambda x: x[1][0], reverse=True) )\n",
        "counted_category_apperances = ordered_data\n",
        "#1. calculate the IoU between max and every other person - (M,C) = 5/20; (M,L) = 2/20; (M,D) = 2/20; (M,A) = 2/20; (M,F) = 2/20;\n",
        "intersection_between_people_with_ae = calculate_IoU_from_countedCategoryDict(counted_category_apperances)\n",
        "#2. calculate the average diversity between the 6 drivers - (20-5) + (20-2) + (20-2) + (20-2) + (20-2) = 87; (#avg_diversity/#pairwise_comparison) = 87/5 = 17,4\n",
        "avg_diversity_from_IoU = calculate_avg_diversity_from_IoU(intersection_between_people_with_ae)\n",
        "#3. calculate a type of categoreis_score - categories_score = cat_diversity * cat_popularity(pvs)\n",
        "categories_scores_dict = calculate_categories_score(counted_category_apperances, avg_diversity_from_IoU)\n",
        "for key,value in categories_scores_dict.items():\n",
        "  categories_scores_dict[key] = OrderedDict(sorted(value.items(), key=lambda x: x[1], reverse=True))\n",
        "mucd = create_hint_sentences_unexCategs(categories_scores_dict, person_answers_dict)\n",
        "inter = {}\n",
        "for key, value in mucd.items():\n",
        "  for answer,question in person_answers_dict.items():\n",
        "    if key == answer:\n",
        "      sim_score = get_similarity_score(question,value[0])\n",
        "      inter[key]  = {value[0] : sim_score}\n",
        "\n",
        "\n",
        "pprint.pprint(inter)\n",
        "\n",
        "\n",
        "# create_hint_sentences_unexCategs\n"
      ],
      "metadata": {
        "id": "I6v8adWUSKst",
        "outputId": "760fb608-0a8e-44cb-a138-a361631ce277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who played the main role of the ‘Terminator’ in the film of the same name? Arnold Schwarzenegger\n",
            "question:  Who played the main role of the ‘Terminator’ in the film of the same name?\n",
            "answer:  Arnold Schwarzenegger\n",
            "{'Arnold Schwarzenegger': OrderedDict([('Category:People appearing on C-SPAN',\n",
            "                                        83916.0),\n",
            "                                       ('Category:Male actors from California',\n",
            "                                        42494.5),\n",
            "                                       ('Category:Film producers from '\n",
            "                                        'California',\n",
            "                                        26399.5)])}\n",
            "{'Arnold Schwarzenegger': (('Category:People appearing on C-SPAN', 83916.0),\n",
            "                           'actor')}\n",
            "{'Arnold Schwarzenegger': {'The person you are looking for is/was occupied as actor and a member of the category People appearing on C-SPAN.': 0.6497857570648193}}\n"
          ]
        }
      ]
    }
  ]
}